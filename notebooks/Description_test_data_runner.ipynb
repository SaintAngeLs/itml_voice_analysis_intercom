{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f841431-cefd-4b48-b72e-7130e85687c4",
   "metadata": {},
   "source": [
    "# Voice-Based Door Access Recognition System\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "This project is part of the course **Introduction to Machine Learning (2024/2025)** by **Dr. Agnieszka JastrzÄ™bska**. The aim of this project is to develop a **voice recognition system** for an automated intercom, capable of distinguishing between allowed and disallowed persons using voice recordings. The core idea is to convert voice recordings into spectrograms and apply **Convolutional Neural Networks (CNNs)** for classification.\n",
    "\n",
    "This is a binary classification problem, where:\n",
    "- **Class 1 (allowed)**: People allowed to open the door.\n",
    "- **Class 0 (disallowed)**: People not allowed to open the door.\n",
    "\n",
    "The data used for the project is derived from the **DAPS (Device and Produced Speech) Dataset**.\n",
    "\n",
    "## Data Preprocessing\n",
    "\n",
    "The input to our machine learning model is not the raw audio file but the **Mel-spectrogram**, a visual representation of the frequency spectrum. The steps involved in preprocessing are:\n",
    "\n",
    "1. **Load Audio**: Each `.mp3` or `.wav` file is loaded using the `librosa` library.\n",
    "2. **Generate Spectrograms**: Mel-spectrograms are generated using `librosa.feature.melspectrogram`. These spectrograms are saved as images (`.png`) for both classes (allowed and disallowed).\n",
    "3. **Output Structure**: The spectrograms are saved in directories labeled according to their respective classes (`allowed`, `disallowed`).\n",
    "\n",
    "---\n",
    "\n",
    "## Model Architecture\n",
    "\n",
    "We use a **Convolutional Neural Network (CNN)** to classify the spectrogram images into two categories: allowed or disallowed. The architecture is simple but effective, consisting of:\n",
    "\n",
    "1. **Three Convolutional Layers**: These layers extract spatial features from the spectrograms.\n",
    "2. **Max Pooling Layers**: Reduces the spatial dimensions to focus on the most critical parts of the image.\n",
    "3. **Dense Layer**: Fully connected layer for classification.\n",
    "4. **Dropout Layer**: Helps reduce overfitting by randomly dropping units during training.\n",
    "5. **Output Layer**: A single neuron activated by the sigmoid function to predict whether a person is allowed or not.\n",
    "\n",
    "---\n",
    "\n",
    "## Model Training\n",
    "\n",
    "The training process involves:\n",
    "\n",
    "- **Data Augmentation**: We use techniques such as rotation and zoom to artificially increase the size of our dataset and introduce variability.\n",
    "- **Train/Test Split**: The dataset is split into 80% training and 20% validation using `train_test_split`.\n",
    "- **Epochs**: The model is trained over 20 epochs using augmented data.\n",
    "\n",
    "---\n",
    "\n",
    "## Model Evaluation\n",
    "\n",
    "### Key Metrics\n",
    "\n",
    "1. **False Acceptance Ratio (FAR)**: Measures how often a disallowed person is incorrectly accepted.\n",
    "2. **False Rejection Ratio (FRR)**: Measures how often an allowed person is incorrectly rejected.\n",
    "\n",
    "The evaluation process includes:\n",
    "\n",
    "- **Predicting on Test Set**: The model's performance is evaluated on unseen test data.\n",
    "- **Calculating FAR/FRR**: Using a confusion matrix to calculate these critical metrics.\n",
    "\n",
    "## Future Improvements\n",
    "\n",
    "Some ideas for further improvements:\n",
    "\n",
    "1. **Enhance Data Augmentation**: Apply more sophisticated augmentations to increase model robustness.\n",
    "2. **Advanced CNN Architectures**: Implement more advanced architectures like ResNet or VGG to improve performance.\n",
    "3. **Noise Handling**: Explore techniques for handling background noise more effectively, such as noise reduction or filtering.\n",
    "4. **Hyperparameter Tuning**: Experiment with different optimizers, learning rates, and batch sizes to improve model accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5d5cc8-0fd1-48fc-a816-5f7ce4417510",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
