{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model exploration - kaggle dataset\n",
    "\n",
    "Since DAPS dataset is too easy for a Neural Network (hard to overfit, very high accuracy even with small subset of dataset), I move with the exploration to new dataset - [Tensorflow speech recognition](https://www.kaggle.com/c/tensorflow-speech-recognition-challenge/overview). Contains more classes and bigger dataset overall. Let's see how much can we learn from this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 14:59:20.070546: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-12-05 14:59:20.082607: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733407160.096760   16772 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733407160.100925   16772 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 14:59:20.115855: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.api.utils import image_dataset_from_directory\n",
    "from keras.api.optimizers import SGD\n",
    "from keras.api.losses import CategoricalCrossentropy\n",
    "from keras.api.metrics import CategoricalAccuracy\n",
    "from keras.api.callbacks import EarlyStopping\n",
    "from keras.api.optimizers.schedules import ExponentialDecay\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from datetime import datetime\n",
    "\n",
    "DATA_PATH = os.path.join(os.getcwd(), \"..\", \"data\")\n",
    "LOG_DIR = os.path.join(os.getcwd(), \"..\", \"logs\")\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 51088 files belonging to 30 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1733407171.911686   16772 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3586 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6798 files belonging to 30 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset_path = os.path.join(DATA_PATH, \"kaggle-speech-recognition\")\n",
    "batch_size = 128\n",
    "class_names = next(os.walk(os.path.join(dataset_path, \"train\")))[1]\n",
    "\n",
    "ds_train: tf.data.Dataset = image_dataset_from_directory(os.path.join(dataset_path, \"train\"), color_mode=\"grayscale\",\n",
    "                                        label_mode=\"categorical\", batch_size=batch_size, class_names=class_names,\n",
    "                                        seed=42, validation_split=0.0)\n",
    "ds_valid: tf.data.Dataset  = image_dataset_from_directory(os.path.join(dataset_path, \"validation\"), color_mode=\"grayscale\",\n",
    "                                        label_mode=\"categorical\", batch_size=batch_size, class_names=class_names,\n",
    "                                        seed=42, validation_split=0.0)\n",
    "\n",
    "ds_train = ds_train.prefetch(tf.data.AUTOTUNE)\n",
    "ds_valid = ds_valid.prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [CategoricalAccuracy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get a closer look to a random sample from training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((128, 256, 256, 1), (128, 30))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = next(ds_train.as_numpy_iterator())\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7ff6cbbbac00>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plt.title(class_names[np.argmax(y[1])])\n",
    "plt.imshow(X[1], aspect=8.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SimpleNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"SimpleNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65536</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,777,472</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,710</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_3 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling_3 (\u001b[38;5;33mRescaling\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_3 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65536\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │    \u001b[38;5;34m16,777,472\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │         \u001b[38;5;34m7,710\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,785,182</span> (64.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m16,785,182\u001b[0m (64.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">16,785,182</span> (64.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m16,785,182\u001b[0m (64.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def simple_ann(input_shape = (256, 256)) -> keras.Model:\n",
    "    inputs = keras.Input((*input_shape, 1), dtype=np.float32)\n",
    "    x = keras.layers.Rescaling(scale=1./255)(inputs)\n",
    "    x = keras.layers.Flatten(\"channels_last\")(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    outputs = keras.layers.Dense(30, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"SimpleNN\")\n",
    "    return model\n",
    "\n",
    "\n",
    "model = simple_ann()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732380441.279942    3142 service.cc:148] XLA service 0x7f55d0003880 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732380441.280417    3142 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-11-23 17:47:21.353563: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1732380441.433529    3142 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-11-23 17:47:22.585833: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_138', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "2024-11-23 17:47:23.203147: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_138_0', 208 bytes spill stores, 208 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  13/1597\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.0217 - auc: 0.0332 - categorical_accuracy: 0.0217 - false_negatives: 220.5385 - false_positives: 76.9231 - loss: 8.6782 - true_negatives: 6419.0771 - true_positives: 3.4615               "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732380445.053284    3142 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1590/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0442 - auc: 0.0400 - categorical_accuracy: 0.0442 - false_negatives: 25452.0039 - false_positives: 92.8686 - loss: 3.5500 - true_negatives: 738131.1250 - true_positives: 3.9956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 17:47:40.067461: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_138_0', 208 bytes spill stores, 208 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0443 - auc: 0.0400 - categorical_accuracy: 0.0443 - false_negatives: 25563.9941 - false_positives: 92.8691 - loss: 3.5492 - true_negatives: 741378.8125 - true_positives: 3.9956"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 17:47:45.013703: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_134_0', 232 bytes spill stores, 232 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 15ms/step - accuracy: 0.0443 - auc: 0.0400 - categorical_accuracy: 0.0443 - false_negatives: 25579.9648 - false_positives: 92.8692 - loss: 3.5491 - true_negatives: 741842.0000 - true_positives: 3.9956 - val_accuracy: 0.0933 - val_auc: 0.0713 - val_categorical_accuracy: 0.0933 - val_false_negatives: 6798.0000 - val_false_positives: 0.0000e+00 - val_loss: 3.2189 - val_true_negatives: 197142.0000 - val_true_positives: 0.0000e+00\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.0819 - auc: 0.0674 - categorical_accuracy: 0.0819 - false_negatives: 25583.0898 - false_positives: 0.6496 - loss: 3.2385 - true_negatives: 741934.1875 - true_positives: 0.8692 - val_accuracy: 0.0958 - val_auc: 0.0771 - val_categorical_accuracy: 0.0958 - val_false_negatives: 6798.0000 - val_false_positives: 0.0000e+00 - val_loss: 3.1786 - val_true_negatives: 197142.0000 - val_true_positives: 0.0000e+00\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.0869 - auc: 0.0764 - categorical_accuracy: 0.0869 - false_negatives: 25574.7012 - false_positives: 6.9212 - loss: 3.1899 - true_negatives: 741927.9375 - true_positives: 9.2591 - val_accuracy: 0.0902 - val_auc: 0.0855 - val_categorical_accuracy: 0.0902 - val_false_negatives: 6777.0000 - val_false_positives: 43.0000 - val_loss: 3.1495 - val_true_negatives: 197099.0000 - val_true_positives: 21.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.0994 - auc: 0.0970 - categorical_accuracy: 0.0994 - false_negatives: 25511.5664 - false_positives: 43.4337 - loss: 3.0976 - true_negatives: 741891.3750 - true_positives: 72.3942 - val_accuracy: 0.1068 - val_auc: 0.1109 - val_categorical_accuracy: 0.1068 - val_false_negatives: 6773.0000 - val_false_positives: 11.0000 - val_loss: 3.0172 - val_true_negatives: 197131.0000 - val_true_positives: 25.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.1071 - auc: 0.1039 - categorical_accuracy: 0.1071 - false_negatives: 25478.7734 - false_positives: 60.9775 - loss: 3.0658 - true_negatives: 741873.8750 - true_positives: 105.1859 - val_accuracy: 0.1230 - val_auc: 0.1236 - val_categorical_accuracy: 0.1230 - val_false_negatives: 6718.0000 - val_false_positives: 67.0000 - val_loss: 2.9524 - val_true_negatives: 197075.0000 - val_true_positives: 80.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.1355 - auc: 0.1258 - categorical_accuracy: 0.1355 - false_negatives: 25369.6562 - false_positives: 148.1978 - loss: 2.9672 - true_negatives: 741786.6250 - true_positives: 214.3035 - val_accuracy: 0.1275 - val_auc: 0.1185 - val_categorical_accuracy: 0.1275 - val_false_negatives: 6691.0000 - val_false_positives: 134.0000 - val_loss: 3.0215 - val_true_negatives: 197008.0000 - val_true_positives: 107.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.1527 - auc: 0.1440 - categorical_accuracy: 0.1527 - false_negatives: 25249.1211 - false_positives: 211.4900 - loss: 2.8862 - true_negatives: 741723.3750 - true_positives: 334.8398 - val_accuracy: 0.1294 - val_auc: 0.1130 - val_categorical_accuracy: 0.1294 - val_false_negatives: 6692.0000 - val_false_positives: 100.0000 - val_loss: 3.1991 - val_true_negatives: 197042.0000 - val_true_positives: 106.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.1617 - auc: 0.1539 - categorical_accuracy: 0.1617 - false_negatives: 25149.0059 - false_positives: 306.4962 - loss: 2.8376 - true_negatives: 741628.3125 - true_positives: 434.9537 - val_accuracy: 0.1521 - val_auc: 0.1485 - val_categorical_accuracy: 0.1521 - val_false_negatives: 6713.0000 - val_false_positives: 75.0000 - val_loss: 2.8322 - val_true_negatives: 197067.0000 - val_true_positives: 85.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.1747 - auc: 0.1631 - categorical_accuracy: 0.1747 - false_negatives: 25072.3672 - false_positives: 357.0526 - loss: 2.8018 - true_negatives: 741577.8125 - true_positives: 511.5932 - val_accuracy: 0.1767 - val_auc: 0.1685 - val_categorical_accuracy: 0.1767 - val_false_negatives: 6585.0000 - val_false_positives: 198.0000 - val_loss: 2.7612 - val_true_negatives: 196944.0000 - val_true_positives: 213.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.1773 - auc: 0.1704 - categorical_accuracy: 0.1773 - false_negatives: 24952.7090 - false_positives: 411.9474 - loss: 2.7771 - true_negatives: 741522.8750 - true_positives: 631.2516 - val_accuracy: 0.1292 - val_auc: 0.1164 - val_categorical_accuracy: 0.1292 - val_false_negatives: 6536.0000 - val_false_positives: 637.0000 - val_loss: 3.0401 - val_true_negatives: 196505.0000 - val_true_positives: 262.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.1875 - auc: 0.1763 - categorical_accuracy: 0.1875 - false_negatives: 24869.1855 - false_positives: 487.2653 - loss: 2.7572 - true_negatives: 741447.5625 - true_positives: 714.7741 - val_accuracy: 0.1777 - val_auc: 0.1652 - val_categorical_accuracy: 0.1777 - val_false_negatives: 6642.0000 - val_false_positives: 102.0000 - val_loss: 2.8020 - val_true_negatives: 197040.0000 - val_true_positives: 156.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.1904 - auc: 0.1792 - categorical_accuracy: 0.1904 - false_negatives: 24824.3984 - false_positives: 535.2903 - loss: 2.7436 - true_negatives: 741399.5625 - true_positives: 759.5607 - val_accuracy: 0.1814 - val_auc: 0.1732 - val_categorical_accuracy: 0.1814 - val_false_negatives: 6551.0000 - val_false_positives: 256.0000 - val_loss: 2.7385 - val_true_negatives: 196886.0000 - val_true_positives: 247.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.1952 - auc: 0.1843 - categorical_accuracy: 0.1952 - false_negatives: 24785.2402 - false_positives: 573.0181 - loss: 2.7260 - true_negatives: 741361.8125 - true_positives: 798.7197 - val_accuracy: 0.2112 - val_auc: 0.1959 - val_categorical_accuracy: 0.2112 - val_false_negatives: 6564.0000 - val_false_positives: 163.0000 - val_loss: 2.6480 - val_true_negatives: 196979.0000 - val_true_positives: 234.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.1966 - auc: 0.1854 - categorical_accuracy: 0.1966 - false_negatives: 24708.7305 - false_positives: 600.1620 - loss: 2.7203 - true_negatives: 741334.6875 - true_positives: 875.2297 - val_accuracy: 0.2052 - val_auc: 0.1976 - val_categorical_accuracy: 0.2052 - val_false_negatives: 6484.0000 - val_false_positives: 212.0000 - val_loss: 2.6528 - val_true_negatives: 196930.0000 - val_true_positives: 314.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2076 - auc: 0.1992 - categorical_accuracy: 0.2076 - false_negatives: 24572.6582 - false_positives: 645.8561 - loss: 2.6683 - true_negatives: 741289.0000 - true_positives: 1011.3010 - val_accuracy: 0.2136 - val_auc: 0.2001 - val_categorical_accuracy: 0.2136 - val_false_negatives: 6513.0000 - val_false_positives: 243.0000 - val_loss: 2.6017 - val_true_negatives: 196899.0000 - val_true_positives: 285.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2131 - auc: 0.2055 - categorical_accuracy: 0.2131 - false_negatives: 24465.7773 - false_positives: 711.8361 - loss: 2.6392 - true_negatives: 741223.0000 - true_positives: 1118.1833 - val_accuracy: 0.2115 - val_auc: 0.2107 - val_categorical_accuracy: 0.2115 - val_false_negatives: 6424.0000 - val_false_positives: 268.0000 - val_loss: 2.6176 - val_true_negatives: 196874.0000 - val_true_positives: 374.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2128 - auc: 0.2066 - categorical_accuracy: 0.2128 - false_negatives: 24447.2988 - false_positives: 795.3110 - loss: 2.6319 - true_negatives: 741139.5000 - true_positives: 1136.6608 - val_accuracy: 0.1937 - val_auc: 0.1796 - val_categorical_accuracy: 0.1937 - val_false_negatives: 6389.0000 - val_false_positives: 501.0000 - val_loss: 2.7614 - val_true_negatives: 196641.0000 - val_true_positives: 409.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2176 - auc: 0.2114 - categorical_accuracy: 0.2176 - false_negatives: 24369.9336 - false_positives: 810.2366 - loss: 2.6172 - true_negatives: 741124.6250 - true_positives: 1214.0269 - val_accuracy: 0.2095 - val_auc: 0.2093 - val_categorical_accuracy: 0.2095 - val_false_negatives: 6362.0000 - val_false_positives: 334.0000 - val_loss: 2.6328 - val_true_negatives: 196808.0000 - val_true_positives: 436.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2221 - auc: 0.2152 - categorical_accuracy: 0.2221 - false_negatives: 24327.3730 - false_positives: 859.4894 - loss: 2.6043 - true_negatives: 741075.3750 - true_positives: 1256.5863 - val_accuracy: 0.2182 - val_auc: 0.2218 - val_categorical_accuracy: 0.2182 - val_false_negatives: 6443.0000 - val_false_positives: 222.0000 - val_loss: 2.5611 - val_true_negatives: 196920.0000 - val_true_positives: 355.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2223 - auc: 0.2167 - categorical_accuracy: 0.2223 - false_negatives: 24297.8613 - false_positives: 876.0670 - loss: 2.5927 - true_negatives: 741058.7500 - true_positives: 1286.0989 - val_accuracy: 0.2415 - val_auc: 0.2407 - val_categorical_accuracy: 0.2415 - val_false_negatives: 6416.0000 - val_false_positives: 227.0000 - val_loss: 2.4960 - val_true_negatives: 196915.0000 - val_true_positives: 382.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.2257 - auc: 0.2166 - categorical_accuracy: 0.2257 - false_negatives: 24285.3105 - false_positives: 935.1552 - loss: 2.5908 - true_negatives: 740999.6875 - true_positives: 1298.6489 - val_accuracy: 0.1987 - val_auc: 0.1947 - val_categorical_accuracy: 0.1987 - val_false_negatives: 6350.0000 - val_false_positives: 524.0000 - val_loss: 2.6618 - val_true_negatives: 196618.0000 - val_true_positives: 448.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2284 - auc: 0.2199 - categorical_accuracy: 0.2284 - false_negatives: 24214.8047 - false_positives: 902.4806 - loss: 2.5795 - true_negatives: 741032.3750 - true_positives: 1369.1558 - val_accuracy: 0.2090 - val_auc: 0.2085 - val_categorical_accuracy: 0.2090 - val_false_negatives: 6337.0000 - val_false_positives: 492.0000 - val_loss: 2.6167 - val_true_negatives: 196650.0000 - val_true_positives: 461.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2286 - auc: 0.2192 - categorical_accuracy: 0.2286 - false_negatives: 24245.7656 - false_positives: 931.2266 - loss: 2.5801 - true_negatives: 741003.6250 - true_positives: 1338.1946 - val_accuracy: 0.2258 - val_auc: 0.2251 - val_categorical_accuracy: 0.2258 - val_false_negatives: 6410.0000 - val_false_positives: 280.0000 - val_loss: 2.5734 - val_true_negatives: 196862.0000 - val_true_positives: 388.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2293 - auc: 0.2210 - categorical_accuracy: 0.2293 - false_negatives: 24204.6641 - false_positives: 1002.0363 - loss: 2.5663 - true_negatives: 740932.8125 - true_positives: 1379.2966 - val_accuracy: 0.1836 - val_auc: 0.1757 - val_categorical_accuracy: 0.1836 - val_false_negatives: 6519.0000 - val_false_positives: 252.0000 - val_loss: 2.7891 - val_true_negatives: 196890.0000 - val_true_positives: 279.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2334 - auc: 0.2245 - categorical_accuracy: 0.2334 - false_negatives: 24195.8926 - false_positives: 970.5901 - loss: 2.5620 - true_negatives: 740964.2500 - true_positives: 1388.0676 - val_accuracy: 0.2329 - val_auc: 0.2292 - val_categorical_accuracy: 0.2329 - val_false_negatives: 6352.0000 - val_false_positives: 319.0000 - val_loss: 2.5817 - val_true_negatives: 196823.0000 - val_true_positives: 446.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2361 - auc: 0.2280 - categorical_accuracy: 0.2361 - false_negatives: 24179.4121 - false_positives: 1019.0038 - loss: 2.5528 - true_negatives: 740915.8125 - true_positives: 1404.5469 - val_accuracy: 0.2329 - val_auc: 0.2285 - val_categorical_accuracy: 0.2329 - val_false_negatives: 6369.0000 - val_false_positives: 313.0000 - val_loss: 2.5336 - val_true_negatives: 196829.0000 - val_true_positives: 429.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 10ms/step - accuracy: 0.2359 - auc: 0.2302 - categorical_accuracy: 0.2359 - false_negatives: 24076.0156 - false_positives: 1019.4449 - loss: 2.5383 - true_negatives: 740915.3750 - true_positives: 1507.9443 - val_accuracy: 0.2105 - val_auc: 0.2000 - val_categorical_accuracy: 0.2105 - val_false_negatives: 6448.0000 - val_false_positives: 302.0000 - val_loss: 2.6413 - val_true_negatives: 196840.0000 - val_true_positives: 350.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2422 - auc: 0.2350 - categorical_accuracy: 0.2422 - false_negatives: 24018.0020 - false_positives: 1090.9650 - loss: 2.5280 - true_negatives: 740843.8750 - true_positives: 1565.9574 - val_accuracy: 0.2311 - val_auc: 0.2273 - val_categorical_accuracy: 0.2311 - val_false_negatives: 6247.0000 - val_false_positives: 505.0000 - val_loss: 2.5681 - val_true_negatives: 196637.0000 - val_true_positives: 551.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2469 - auc: 0.2391 - categorical_accuracy: 0.2469 - false_negatives: 23941.5566 - false_positives: 1125.8679 - loss: 2.5069 - true_negatives: 740809.0000 - true_positives: 1642.4037 - val_accuracy: 0.2342 - val_auc: 0.2258 - val_categorical_accuracy: 0.2342 - val_false_negatives: 6344.0000 - val_false_positives: 444.0000 - val_loss: 2.5303 - val_true_negatives: 196698.0000 - val_true_positives: 454.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2514 - auc: 0.2445 - categorical_accuracy: 0.2514 - false_negatives: 23845.5410 - false_positives: 1196.7778 - loss: 2.4942 - true_negatives: 740738.0625 - true_positives: 1738.4187 - val_accuracy: 0.2270 - val_auc: 0.2177 - val_categorical_accuracy: 0.2270 - val_false_negatives: 6382.0000 - val_false_positives: 330.0000 - val_loss: 2.6006 - val_true_negatives: 196812.0000 - val_true_positives: 416.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2518 - auc: 0.2486 - categorical_accuracy: 0.2518 - false_negatives: 23766.7617 - false_positives: 1199.9694 - loss: 2.4876 - true_negatives: 740734.8750 - true_positives: 1817.1978 - val_accuracy: 0.2068 - val_auc: 0.1880 - val_categorical_accuracy: 0.2068 - val_false_negatives: 6368.0000 - val_false_positives: 562.0000 - val_loss: 2.7083 - val_true_negatives: 196580.0000 - val_true_positives: 430.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.2591 - auc: 0.2502 - categorical_accuracy: 0.2591 - false_negatives: 23747.0000 - false_positives: 1252.0106 - loss: 2.4798 - true_negatives: 740682.8125 - true_positives: 1836.9594 - val_accuracy: 0.2374 - val_auc: 0.2391 - val_categorical_accuracy: 0.2374 - val_false_negatives: 6183.0000 - val_false_positives: 452.0000 - val_loss: 2.5456 - val_true_negatives: 196690.0000 - val_true_positives: 615.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 9ms/step - accuracy: 0.2574 - auc: 0.2534 - categorical_accuracy: 0.2574 - false_negatives: 23664.2754 - false_positives: 1271.5563 - loss: 2.4708 - true_negatives: 740663.3125 - true_positives: 1919.6840 - val_accuracy: 0.2385 - val_auc: 0.2380 - val_categorical_accuracy: 0.2385 - val_false_negatives: 6166.0000 - val_false_positives: 522.0000 - val_loss: 2.5674 - val_true_negatives: 196620.0000 - val_true_positives: 632.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.2643 - auc: 0.2592 - categorical_accuracy: 0.2643 - false_negatives: 23577.5410 - false_positives: 1282.4932 - loss: 2.4549 - true_negatives: 740652.3750 - true_positives: 2006.4193 - val_accuracy: 0.2523 - val_auc: 0.2568 - val_categorical_accuracy: 0.2523 - val_false_negatives: 6276.0000 - val_false_positives: 336.0000 - val_loss: 2.4477 - val_true_negatives: 196806.0000 - val_true_positives: 522.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2648 - auc: 0.2592 - categorical_accuracy: 0.2648 - false_negatives: 23580.6875 - false_positives: 1322.1139 - loss: 2.4552 - true_negatives: 740612.7500 - true_positives: 2003.2722 - val_accuracy: 0.1817 - val_auc: 0.1767 - val_categorical_accuracy: 0.1817 - val_false_negatives: 6271.0000 - val_false_positives: 701.0000 - val_loss: 2.8678 - val_true_negatives: 196441.0000 - val_true_positives: 527.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 10ms/step - accuracy: 0.2630 - auc: 0.2607 - categorical_accuracy: 0.2630 - false_negatives: 23550.5566 - false_positives: 1342.2052 - loss: 2.4508 - true_negatives: 740592.6250 - true_positives: 2033.4043 - val_accuracy: 0.2421 - val_auc: 0.2468 - val_categorical_accuracy: 0.2421 - val_false_negatives: 6272.0000 - val_false_positives: 323.0000 - val_loss: 2.5469 - val_true_negatives: 196819.0000 - val_true_positives: 526.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2674 - auc: 0.2638 - categorical_accuracy: 0.2674 - false_negatives: 23504.3203 - false_positives: 1360.8579 - loss: 2.4404 - true_negatives: 740574.0000 - true_positives: 2079.6396 - val_accuracy: 0.2766 - val_auc: 0.2817 - val_categorical_accuracy: 0.2766 - val_false_negatives: 6029.0000 - val_false_positives: 493.0000 - val_loss: 2.4097 - val_true_negatives: 196649.0000 - val_true_positives: 769.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2727 - auc: 0.2639 - categorical_accuracy: 0.2727 - false_negatives: 23458.0312 - false_positives: 1434.3317 - loss: 2.4386 - true_negatives: 740500.5000 - true_positives: 2125.9292 - val_accuracy: 0.2633 - val_auc: 0.2672 - val_categorical_accuracy: 0.2633 - val_false_negatives: 6203.0000 - val_false_positives: 423.0000 - val_loss: 2.4244 - val_true_negatives: 196719.0000 - val_true_positives: 595.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2741 - auc: 0.2680 - categorical_accuracy: 0.2741 - false_negatives: 23434.2637 - false_positives: 1425.4700 - loss: 2.4244 - true_negatives: 740509.3750 - true_positives: 2149.6958 - val_accuracy: 0.2518 - val_auc: 0.2502 - val_categorical_accuracy: 0.2518 - val_false_negatives: 6132.0000 - val_false_positives: 556.0000 - val_loss: 2.4822 - val_true_negatives: 196586.0000 - val_true_positives: 666.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2680 - auc: 0.2664 - categorical_accuracy: 0.2680 - false_negatives: 23432.5098 - false_positives: 1430.9456 - loss: 2.4326 - true_negatives: 740503.8750 - true_positives: 2151.4492 - val_accuracy: 0.2515 - val_auc: 0.2463 - val_categorical_accuracy: 0.2515 - val_false_negatives: 6243.0000 - val_false_positives: 451.0000 - val_loss: 2.4946 - val_true_negatives: 196691.0000 - val_true_positives: 555.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2757 - auc: 0.2703 - categorical_accuracy: 0.2757 - false_negatives: 23402.5645 - false_positives: 1473.6902 - loss: 2.4194 - true_negatives: 740461.1250 - true_positives: 2181.3955 - val_accuracy: 0.2674 - val_auc: 0.2658 - val_categorical_accuracy: 0.2674 - val_false_negatives: 6213.0000 - val_false_positives: 394.0000 - val_loss: 2.4320 - val_true_negatives: 196748.0000 - val_true_positives: 585.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2732 - auc: 0.2684 - categorical_accuracy: 0.2732 - false_negatives: 23373.3809 - false_positives: 1450.8793 - loss: 2.4215 - true_negatives: 740483.9375 - true_positives: 2210.5781 - val_accuracy: 0.2786 - val_auc: 0.2760 - val_categorical_accuracy: 0.2786 - val_false_negatives: 6162.0000 - val_false_positives: 452.0000 - val_loss: 2.3782 - val_true_negatives: 196690.0000 - val_true_positives: 636.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2788 - auc: 0.2730 - categorical_accuracy: 0.2788 - false_negatives: 23362.1797 - false_positives: 1418.2034 - loss: 2.4073 - true_negatives: 740516.6250 - true_positives: 2221.7803 - val_accuracy: 0.2386 - val_auc: 0.2355 - val_categorical_accuracy: 0.2386 - val_false_negatives: 6109.0000 - val_false_positives: 672.0000 - val_loss: 2.5741 - val_true_negatives: 196470.0000 - val_true_positives: 689.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2735 - auc: 0.2709 - categorical_accuracy: 0.2735 - false_negatives: 23361.8164 - false_positives: 1519.9318 - loss: 2.4054 - true_negatives: 740414.9375 - true_positives: 2222.1433 - val_accuracy: 0.2674 - val_auc: 0.2563 - val_categorical_accuracy: 0.2674 - val_false_negatives: 6166.0000 - val_false_positives: 498.0000 - val_loss: 2.4827 - val_true_negatives: 196644.0000 - val_true_positives: 632.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.2788 - auc: 0.2728 - categorical_accuracy: 0.2788 - false_negatives: 23354.8496 - false_positives: 1509.4393 - loss: 2.4037 - true_negatives: 740425.3750 - true_positives: 2229.1108 - val_accuracy: 0.2546 - val_auc: 0.2620 - val_categorical_accuracy: 0.2546 - val_false_negatives: 6105.0000 - val_false_positives: 486.0000 - val_loss: 2.4710 - val_true_negatives: 196656.0000 - val_true_positives: 693.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.2765 - auc: 0.2744 - categorical_accuracy: 0.2765 - false_negatives: 23297.0020 - false_positives: 1508.4073 - loss: 2.3992 - true_negatives: 740426.4375 - true_positives: 2286.9580 - val_accuracy: 0.2648 - val_auc: 0.2637 - val_categorical_accuracy: 0.2648 - val_false_negatives: 6112.0000 - val_false_positives: 514.0000 - val_loss: 2.4365 - val_true_negatives: 196628.0000 - val_true_positives: 686.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2818 - auc: 0.2757 - categorical_accuracy: 0.2818 - false_negatives: 23278.5840 - false_positives: 1522.4237 - loss: 2.3947 - true_negatives: 740412.4375 - true_positives: 2305.3767 - val_accuracy: 0.2323 - val_auc: 0.2225 - val_categorical_accuracy: 0.2323 - val_false_negatives: 6174.0000 - val_false_positives: 735.0000 - val_loss: 2.5921 - val_true_negatives: 196407.0000 - val_true_positives: 624.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2801 - auc: 0.2778 - categorical_accuracy: 0.2801 - false_negatives: 23259.2441 - false_positives: 1499.4023 - loss: 2.3882 - true_negatives: 740435.4375 - true_positives: 2324.7153 - val_accuracy: 0.2582 - val_auc: 0.2528 - val_categorical_accuracy: 0.2582 - val_false_negatives: 6118.0000 - val_false_positives: 633.0000 - val_loss: 2.4714 - val_true_negatives: 196509.0000 - val_true_positives: 680.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2799 - auc: 0.2765 - categorical_accuracy: 0.2799 - false_negatives: 23225.8047 - false_positives: 1548.6257 - loss: 2.3893 - true_negatives: 740386.1875 - true_positives: 2358.1558 - val_accuracy: 0.2054 - val_auc: 0.1926 - val_categorical_accuracy: 0.2054 - val_false_negatives: 6235.0000 - val_false_positives: 713.0000 - val_loss: 2.8381 - val_true_negatives: 196429.0000 - val_true_positives: 563.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 10ms/step - accuracy: 0.2812 - auc: 0.2777 - categorical_accuracy: 0.2812 - false_negatives: 23235.0527 - false_positives: 1569.8911 - loss: 2.3858 - true_negatives: 740364.9375 - true_positives: 2348.9075 - val_accuracy: 0.2367 - val_auc: 0.2185 - val_categorical_accuracy: 0.2367 - val_false_negatives: 6229.0000 - val_false_positives: 576.0000 - val_loss: 2.6531 - val_true_negatives: 196566.0000 - val_true_positives: 569.0000\n"
     ]
    }
   ],
   "source": [
    "optimizer = SGD()\n",
    "loss = CategoricalCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "log_dir = os.path.join(LOG_DIR, \"kaggle-speech-recognition\")\n",
    "model_log_dir = os.path.join(log_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S-{model.name}\"))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1)\n",
    "history = model.fit(x=ds_train, validation_data=ds_valid, batch_size=batch_size, epochs=50,\n",
    "            callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No overfitting visible, but haven't achieved a ~90% accuracy first try with one hidden layer! Let's try\n",
    "a bigger ann and see if it overfits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"DeepNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"DeepNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">65536</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">33,554,944</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,656</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">15,390</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling_1 (\u001b[38;5;33mRescaling\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m65536\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m33,554,944\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m262,656\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)             │        \u001b[38;5;34m15,390\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,095,646</span> (130.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m34,095,646\u001b[0m (130.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">34,095,646</span> (130.06 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m34,095,646\u001b[0m (130.06 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732401644.659098   22777 service.cc:148] XLA service 0x7fd564008ac0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732401644.659923   22777 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-11-23 23:40:44.858294: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1732401644.946042   22777 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-11-23 23:40:46.340152: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_138_0', 208 bytes spill stores, 208 bytes spill loads\n",
      "\n",
      "2024-11-23 23:40:46.423112: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_138', 188 bytes spill stores, 188 bytes spill loads\n",
      "\n",
      "2024-11-23 23:40:47.788513: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_180', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   7/1597\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m14s\u001b[0m 9ms/step - accuracy: 0.0327 - auc: 0.0327 - categorical_accuracy: 0.0327 - false_negatives: 128.0000 - false_positives: 0.0000e+00 - loss: 3.5808 - true_negatives: 3712.0000 - true_positives: 0.0000e+00         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732401650.746370   22777 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1594/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0734 - auc: 0.0632 - categorical_accuracy: 0.0734 - false_negatives: 25473.2227 - false_positives: 33.1543 - loss: 3.2860 - true_negatives: 740046.8750 - true_positives: 46.7773"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 23:41:08.678730: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_138_0', 208 bytes spill stores, 208 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0735 - auc: 0.0632 - categorical_accuracy: 0.0735 - false_negatives: 25520.8770 - false_positives: 33.3757 - loss: 3.2857 - true_negatives: 741438.3125 - true_positives: 47.1121"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-23 23:41:17.342647: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_136_0', 232 bytes spill stores, 232 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 19ms/step - accuracy: 0.0735 - auc: 0.0632 - categorical_accuracy: 0.0735 - false_negatives: 25536.7363 - false_positives: 33.4493 - loss: 3.2856 - true_negatives: 741901.3750 - true_positives: 47.2240 - val_accuracy: 0.0940 - val_auc: 0.0846 - val_categorical_accuracy: 0.0940 - val_false_negatives: 6685.0000 - val_false_positives: 229.0000 - val_loss: 3.2767 - val_true_negatives: 196913.0000 - val_true_positives: 113.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 14ms/step - accuracy: 0.1767 - auc: 0.1647 - categorical_accuracy: 0.1767 - false_negatives: 24980.0117 - false_positives: 357.8361 - loss: 2.8069 - true_negatives: 741577.0000 - true_positives: 603.9487 - val_accuracy: 0.1533 - val_auc: 0.1243 - val_categorical_accuracy: 0.1533 - val_false_negatives: 6433.0000 - val_false_positives: 585.0000 - val_loss: 3.3136 - val_true_negatives: 196557.0000 - val_true_positives: 365.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.2582 - auc: 0.2498 - categorical_accuracy: 0.2582 - false_negatives: 23776.5762 - false_positives: 921.5369 - loss: 2.5188 - true_negatives: 741013.3125 - true_positives: 1807.3843 - val_accuracy: 0.2783 - val_auc: 0.2810 - val_categorical_accuracy: 0.2783 - val_false_negatives: 5992.0000 - val_false_positives: 523.0000 - val_loss: 2.4385 - val_true_negatives: 196619.0000 - val_true_positives: 806.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.3167 - auc: 0.3242 - categorical_accuracy: 0.3167 - false_negatives: 22480.7168 - false_positives: 1428.9149 - loss: 2.2970 - true_negatives: 740505.9375 - true_positives: 3103.2422 - val_accuracy: 0.2930 - val_auc: 0.3076 - val_categorical_accuracy: 0.2930 - val_false_negatives: 5679.0000 - val_false_positives: 831.0000 - val_loss: 2.4131 - val_true_negatives: 196311.0000 - val_true_positives: 1119.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.3702 - auc: 0.3874 - categorical_accuracy: 0.3702 - false_negatives: 21172.7969 - false_positives: 1815.9731 - loss: 2.1196 - true_negatives: 740118.8750 - true_positives: 4411.1626 - val_accuracy: 0.3669 - val_auc: 0.3825 - val_categorical_accuracy: 0.3669 - val_false_negatives: 5472.0000 - val_false_positives: 691.0000 - val_loss: 2.1148 - val_true_negatives: 196451.0000 - val_true_positives: 1326.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.4142 - auc: 0.4408 - categorical_accuracy: 0.4142 - false_negatives: 19945.1074 - false_positives: 2245.2385 - loss: 1.9644 - true_negatives: 739689.6250 - true_positives: 5638.8516 - val_accuracy: 0.3864 - val_auc: 0.4163 - val_categorical_accuracy: 0.3864 - val_false_negatives: 5149.0000 - val_false_positives: 937.0000 - val_loss: 2.0769 - val_true_negatives: 196205.0000 - val_true_positives: 1649.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.4474 - auc: 0.4872 - categorical_accuracy: 0.4474 - false_negatives: 18787.3223 - false_positives: 2447.3323 - loss: 1.8379 - true_negatives: 739487.5000 - true_positives: 6796.6377 - val_accuracy: 0.4597 - val_auc: 0.5020 - val_categorical_accuracy: 0.4597 - val_false_negatives: 4888.0000 - val_false_positives: 678.0000 - val_loss: 1.7935 - val_true_negatives: 196464.0000 - val_true_positives: 1910.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.4804 - auc: 0.5287 - categorical_accuracy: 0.4804 - false_negatives: 17847.3574 - false_positives: 2593.1997 - loss: 1.7281 - true_negatives: 739341.6250 - true_positives: 7736.6021 - val_accuracy: 0.4588 - val_auc: 0.5086 - val_categorical_accuracy: 0.4588 - val_false_negatives: 4630.0000 - val_false_positives: 861.0000 - val_loss: 1.8102 - val_true_negatives: 196281.0000 - val_true_positives: 2168.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5053 - auc: 0.5583 - categorical_accuracy: 0.5053 - false_negatives: 17002.8926 - false_positives: 2746.5957 - loss: 1.6431 - true_negatives: 739188.2500 - true_positives: 8581.0684 - val_accuracy: 0.3922 - val_auc: 0.3979 - val_categorical_accuracy: 0.3922 - val_false_negatives: 4890.0000 - val_false_positives: 1526.0000 - val_loss: 2.1780 - val_true_negatives: 195616.0000 - val_true_positives: 1908.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 14ms/step - accuracy: 0.5299 - auc: 0.5898 - categorical_accuracy: 0.5299 - false_negatives: 16183.4844 - false_positives: 2855.3467 - loss: 1.5564 - true_negatives: 739079.5000 - true_positives: 9400.4756 - val_accuracy: 0.4679 - val_auc: 0.5128 - val_categorical_accuracy: 0.4679 - val_false_negatives: 4355.0000 - val_false_positives: 1318.0000 - val_loss: 1.8237 - val_true_negatives: 195824.0000 - val_true_positives: 2443.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5484 - auc: 0.6173 - categorical_accuracy: 0.5484 - false_negatives: 15435.9658 - false_positives: 2951.9104 - loss: 1.4750 - true_negatives: 738982.9375 - true_positives: 10147.9941 - val_accuracy: 0.4851 - val_auc: 0.5405 - val_categorical_accuracy: 0.4851 - val_false_negatives: 4330.0000 - val_false_positives: 1053.0000 - val_loss: 1.7367 - val_true_negatives: 196089.0000 - val_true_positives: 2468.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.5734 - auc: 0.6424 - categorical_accuracy: 0.5734 - false_negatives: 14751.6172 - false_positives: 2983.3955 - loss: 1.4088 - true_negatives: 738951.4375 - true_positives: 10832.3428 - val_accuracy: 0.5021 - val_auc: 0.5513 - val_categorical_accuracy: 0.5021 - val_false_negatives: 4220.0000 - val_false_positives: 1138.0000 - val_loss: 1.7011 - val_true_negatives: 196004.0000 - val_true_positives: 2578.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.5889 - auc: 0.6644 - categorical_accuracy: 0.5889 - false_negatives: 14186.7412 - false_positives: 3008.2585 - loss: 1.3453 - true_negatives: 738926.5625 - true_positives: 11397.2188 - val_accuracy: 0.5049 - val_auc: 0.5610 - val_categorical_accuracy: 0.5049 - val_false_negatives: 4071.0000 - val_false_positives: 1261.0000 - val_loss: 1.6810 - val_true_negatives: 195881.0000 - val_true_positives: 2727.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6050 - auc: 0.6850 - categorical_accuracy: 0.6050 - false_negatives: 13541.3867 - false_positives: 3014.4980 - loss: 1.2860 - true_negatives: 738920.3125 - true_positives: 12042.5732 - val_accuracy: 0.5215 - val_auc: 0.5812 - val_categorical_accuracy: 0.5215 - val_false_negatives: 3916.0000 - val_false_positives: 1249.0000 - val_loss: 1.6337 - val_true_negatives: 195893.0000 - val_true_positives: 2882.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.6228 - auc: 0.7040 - categorical_accuracy: 0.6228 - false_negatives: 12976.7256 - false_positives: 3012.7571 - loss: 1.2326 - true_negatives: 738922.0625 - true_positives: 12607.2344 - val_accuracy: 0.5427 - val_auc: 0.5955 - val_categorical_accuracy: 0.5427 - val_false_negatives: 3875.0000 - val_false_positives: 1131.0000 - val_loss: 1.5733 - val_true_negatives: 196011.0000 - val_true_positives: 2923.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.6337 - auc: 0.7181 - categorical_accuracy: 0.6337 - false_negatives: 12464.7900 - false_positives: 3112.4075 - loss: 1.1859 - true_negatives: 738822.4375 - true_positives: 13119.1699 - val_accuracy: 0.5224 - val_auc: 0.5738 - val_categorical_accuracy: 0.5224 - val_false_negatives: 3806.0000 - val_false_positives: 1475.0000 - val_loss: 1.6744 - val_true_negatives: 195667.0000 - val_true_positives: 2992.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.6515 - auc: 0.7361 - categorical_accuracy: 0.6515 - false_negatives: 11955.6934 - false_positives: 2968.0488 - loss: 1.1380 - true_negatives: 738966.8125 - true_positives: 13628.2666 - val_accuracy: 0.5380 - val_auc: 0.5960 - val_categorical_accuracy: 0.5380 - val_false_negatives: 3771.0000 - val_false_positives: 1273.0000 - val_loss: 1.5987 - val_true_negatives: 195869.0000 - val_true_positives: 3027.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.6642 - auc: 0.7528 - categorical_accuracy: 0.6642 - false_negatives: 11480.0518 - false_positives: 3041.3386 - loss: 1.0840 - true_negatives: 738893.5000 - true_positives: 14103.9082 - val_accuracy: 0.5309 - val_auc: 0.5897 - val_categorical_accuracy: 0.5309 - val_false_negatives: 3710.0000 - val_false_positives: 1464.0000 - val_loss: 1.6649 - val_true_negatives: 195678.0000 - val_true_positives: 3088.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.6766 - auc: 0.7677 - categorical_accuracy: 0.6766 - false_negatives: 11064.3203 - false_positives: 2971.7441 - loss: 1.0408 - true_negatives: 738963.1250 - true_positives: 14519.6396 - val_accuracy: 0.5502 - val_auc: 0.6079 - val_categorical_accuracy: 0.5502 - val_false_negatives: 3618.0000 - val_false_positives: 1437.0000 - val_loss: 1.6075 - val_true_negatives: 195705.0000 - val_true_positives: 3180.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.6913 - auc: 0.7822 - categorical_accuracy: 0.6913 - false_negatives: 10499.8965 - false_positives: 2926.5637 - loss: 0.9981 - true_negatives: 739008.2500 - true_positives: 15084.0635 - val_accuracy: 0.5353 - val_auc: 0.5917 - val_categorical_accuracy: 0.5353 - val_false_negatives: 3683.0000 - val_false_positives: 1497.0000 - val_loss: 1.6873 - val_true_negatives: 195645.0000 - val_true_positives: 3115.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.7013 - auc: 0.7934 - categorical_accuracy: 0.7013 - false_negatives: 10187.7354 - false_positives: 2940.4656 - loss: 0.9585 - true_negatives: 738994.3750 - true_positives: 15396.2246 - val_accuracy: 0.5578 - val_auc: 0.6192 - val_categorical_accuracy: 0.5578 - val_false_negatives: 3475.0000 - val_false_positives: 1477.0000 - val_loss: 1.6247 - val_true_negatives: 195665.0000 - val_true_positives: 3323.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.7114 - auc: 0.8039 - categorical_accuracy: 0.7114 - false_negatives: 9819.8057 - false_positives: 2836.1714 - loss: 0.9267 - true_negatives: 739098.6875 - true_positives: 15764.1543 - val_accuracy: 0.5000 - val_auc: 0.5437 - val_categorical_accuracy: 0.5000 - val_false_negatives: 3790.0000 - val_false_positives: 1846.0000 - val_loss: 1.8941 - val_true_negatives: 195296.0000 - val_true_positives: 3008.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.7216 - auc: 0.8163 - categorical_accuracy: 0.7216 - false_negatives: 9364.4795 - false_positives: 2811.1814 - loss: 0.8854 - true_negatives: 739123.6875 - true_positives: 16219.4805 - val_accuracy: 0.5597 - val_auc: 0.6143 - val_categorical_accuracy: 0.5597 - val_false_negatives: 3485.0000 - val_false_positives: 1520.0000 - val_loss: 1.6352 - val_true_negatives: 195622.0000 - val_true_positives: 3313.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.7315 - auc: 0.8287 - categorical_accuracy: 0.7315 - false_negatives: 8938.6611 - false_positives: 2760.6145 - loss: 0.8460 - true_negatives: 739174.2500 - true_positives: 16645.2988 - val_accuracy: 0.5718 - val_auc: 0.6302 - val_categorical_accuracy: 0.5718 - val_false_negatives: 3345.0000 - val_false_positives: 1530.0000 - val_loss: 1.5993 - val_true_negatives: 195612.0000 - val_true_positives: 3453.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.7423 - auc: 0.8377 - categorical_accuracy: 0.7423 - false_negatives: 8622.7021 - false_positives: 2799.7134 - loss: 0.8129 - true_negatives: 739135.1250 - true_positives: 16961.2578 - val_accuracy: 0.5322 - val_auc: 0.5701 - val_categorical_accuracy: 0.5322 - val_false_negatives: 3638.0000 - val_false_positives: 1781.0000 - val_loss: 1.8229 - val_true_negatives: 195361.0000 - val_true_positives: 3160.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 11ms/step - accuracy: 0.7529 - auc: 0.8468 - categorical_accuracy: 0.7529 - false_negatives: 8247.5449 - false_positives: 2762.7646 - loss: 0.7836 - true_negatives: 739172.0625 - true_positives: 17336.4141 - val_accuracy: 0.5371 - val_auc: 0.5910 - val_categorical_accuracy: 0.5371 - val_false_negatives: 3531.0000 - val_false_positives: 1813.0000 - val_loss: 1.8174 - val_true_negatives: 195329.0000 - val_true_positives: 3267.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.7664 - auc: 0.8589 - categorical_accuracy: 0.7664 - false_negatives: 7872.7886 - false_positives: 2608.8655 - loss: 0.7433 - true_negatives: 739326.0000 - true_positives: 17711.1719 - val_accuracy: 0.5596 - val_auc: 0.6100 - val_categorical_accuracy: 0.5596 - val_false_negatives: 3375.0000 - val_false_positives: 1696.0000 - val_loss: 1.7439 - val_true_negatives: 195446.0000 - val_true_positives: 3423.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.7722 - auc: 0.8657 - categorical_accuracy: 0.7722 - false_negatives: 7607.0039 - false_positives: 2604.4556 - loss: 0.7177 - true_negatives: 739330.3750 - true_positives: 17976.9570 - val_accuracy: 0.5706 - val_auc: 0.6227 - val_categorical_accuracy: 0.5706 - val_false_negatives: 3263.0000 - val_false_positives: 1693.0000 - val_loss: 1.6921 - val_true_negatives: 195449.0000 - val_true_positives: 3535.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.7835 - auc: 0.8766 - categorical_accuracy: 0.7835 - false_negatives: 7239.6372 - false_positives: 2517.2371 - loss: 0.6784 - true_negatives: 739417.6250 - true_positives: 18344.3223 - val_accuracy: 0.5758 - val_auc: 0.6286 - val_categorical_accuracy: 0.5758 - val_false_negatives: 3216.0000 - val_false_positives: 1831.0000 - val_loss: 1.7203 - val_true_negatives: 195311.0000 - val_true_positives: 3582.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.7912 - auc: 0.8843 - categorical_accuracy: 0.7912 - false_negatives: 6973.0771 - false_positives: 2471.8223 - loss: 0.6537 - true_negatives: 739463.0000 - true_positives: 18610.8828 - val_accuracy: 0.5502 - val_auc: 0.5926 - val_categorical_accuracy: 0.5502 - val_false_negatives: 3348.0000 - val_false_positives: 1949.0000 - val_loss: 1.8853 - val_true_negatives: 195193.0000 - val_true_positives: 3450.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8002 - auc: 0.8925 - categorical_accuracy: 0.8002 - false_negatives: 6642.9429 - false_positives: 2407.8835 - loss: 0.6225 - true_negatives: 739526.9375 - true_positives: 18941.0176 - val_accuracy: 0.5435 - val_auc: 0.5823 - val_categorical_accuracy: 0.5435 - val_false_negatives: 3357.0000 - val_false_positives: 2075.0000 - val_loss: 2.0234 - val_true_negatives: 195067.0000 - val_true_positives: 3441.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8071 - auc: 0.8970 - categorical_accuracy: 0.8071 - false_negatives: 6401.4736 - false_positives: 2376.5713 - loss: 0.6019 - true_negatives: 739558.2500 - true_positives: 19182.4863 - val_accuracy: 0.5791 - val_auc: 0.6275 - val_categorical_accuracy: 0.5791 - val_false_negatives: 3135.0000 - val_false_positives: 1900.0000 - val_loss: 1.7647 - val_true_negatives: 195242.0000 - val_true_positives: 3663.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8130 - auc: 0.9034 - categorical_accuracy: 0.8130 - false_negatives: 6089.3574 - false_positives: 2389.6045 - loss: 0.5800 - true_negatives: 739545.2500 - true_positives: 19494.6035 - val_accuracy: 0.5888 - val_auc: 0.6395 - val_categorical_accuracy: 0.5888 - val_false_negatives: 3048.0000 - val_false_positives: 1865.0000 - val_loss: 1.7451 - val_true_negatives: 195277.0000 - val_true_positives: 3750.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 11ms/step - accuracy: 0.8257 - auc: 0.9132 - categorical_accuracy: 0.8257 - false_negatives: 5708.4731 - false_positives: 2201.5269 - loss: 0.5426 - true_negatives: 739733.3125 - true_positives: 19875.4863 - val_accuracy: 0.5405 - val_auc: 0.5779 - val_categorical_accuracy: 0.5405 - val_false_negatives: 3367.0000 - val_false_positives: 2093.0000 - val_loss: 2.0735 - val_true_negatives: 195049.0000 - val_true_positives: 3431.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 12ms/step - accuracy: 0.8315 - auc: 0.9175 - categorical_accuracy: 0.8315 - false_negatives: 5528.3794 - false_positives: 2185.5945 - loss: 0.5258 - true_negatives: 739749.2500 - true_positives: 20055.5801 - val_accuracy: 0.5449 - val_auc: 0.5801 - val_categorical_accuracy: 0.5449 - val_false_negatives: 3286.0000 - val_false_positives: 2260.0000 - val_loss: 2.1273 - val_true_negatives: 194882.0000 - val_true_positives: 3512.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8371 - auc: 0.9218 - categorical_accuracy: 0.8371 - false_negatives: 5326.1069 - false_positives: 2168.9263 - loss: 0.5071 - true_negatives: 739765.9375 - true_positives: 20257.8535 - val_accuracy: 0.5665 - val_auc: 0.6110 - val_categorical_accuracy: 0.5665 - val_false_negatives: 3129.0000 - val_false_positives: 2135.0000 - val_loss: 1.9822 - val_true_negatives: 195007.0000 - val_true_positives: 3669.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8427 - auc: 0.9263 - categorical_accuracy: 0.8427 - false_negatives: 5030.1890 - false_positives: 2143.5012 - loss: 0.4871 - true_negatives: 739791.3125 - true_positives: 20553.7715 - val_accuracy: 0.5146 - val_auc: 0.5323 - val_categorical_accuracy: 0.5146 - val_false_negatives: 3458.0000 - val_false_positives: 2527.0000 - val_loss: 2.5351 - val_true_negatives: 194615.0000 - val_true_positives: 3340.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8538 - auc: 0.9337 - categorical_accuracy: 0.8538 - false_negatives: 4687.1665 - false_positives: 1988.8937 - loss: 0.4561 - true_negatives: 739945.9375 - true_positives: 20896.7930 - val_accuracy: 0.5796 - val_auc: 0.6226 - val_categorical_accuracy: 0.5796 - val_false_negatives: 3056.0000 - val_false_positives: 2022.0000 - val_loss: 1.9169 - val_true_negatives: 195120.0000 - val_true_positives: 3742.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 12ms/step - accuracy: 0.8631 - auc: 0.9400 - categorical_accuracy: 0.8631 - false_negatives: 4558.0000 - false_positives: 1907.7922 - loss: 0.4313 - true_negatives: 740027.0625 - true_positives: 21025.9590 - val_accuracy: 0.5883 - val_auc: 0.6266 - val_categorical_accuracy: 0.5883 - val_false_negatives: 3016.0000 - val_false_positives: 2085.0000 - val_loss: 1.9628 - val_true_negatives: 195057.0000 - val_true_positives: 3782.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - accuracy: 0.8640 - auc: 0.9421 - categorical_accuracy: 0.8640 - false_negatives: 4361.5571 - false_positives: 1912.8392 - loss: 0.4203 - true_negatives: 740022.0000 - true_positives: 21222.4023 - val_accuracy: 0.5727 - val_auc: 0.6075 - val_categorical_accuracy: 0.5727 - val_false_negatives: 3082.0000 - val_false_positives: 2202.0000 - val_loss: 2.1040 - val_true_negatives: 194940.0000 - val_true_positives: 3716.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8697 - auc: 0.9455 - categorical_accuracy: 0.8697 - false_negatives: 4185.1694 - false_positives: 1856.2697 - loss: 0.4028 - true_negatives: 740078.5625 - true_positives: 21398.7910 - val_accuracy: 0.5977 - val_auc: 0.6325 - val_categorical_accuracy: 0.5977 - val_false_negatives: 2908.0000 - val_false_positives: 2065.0000 - val_loss: 1.9899 - val_true_negatives: 195077.0000 - val_true_positives: 3890.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8792 - auc: 0.9510 - categorical_accuracy: 0.8792 - false_negatives: 3951.6033 - false_positives: 1782.6289 - loss: 0.3770 - true_negatives: 740152.1875 - true_positives: 21632.3574 - val_accuracy: 0.5830 - val_auc: 0.6146 - val_categorical_accuracy: 0.5830 - val_false_negatives: 3012.0000 - val_false_positives: 2176.0000 - val_loss: 2.1086 - val_true_negatives: 194966.0000 - val_true_positives: 3786.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8782 - auc: 0.9517 - categorical_accuracy: 0.8782 - false_negatives: 3866.6265 - false_positives: 1815.4518 - loss: 0.3738 - true_negatives: 740119.3750 - true_positives: 21717.3340 - val_accuracy: 0.5809 - val_auc: 0.6091 - val_categorical_accuracy: 0.5809 - val_false_negatives: 3010.0000 - val_false_positives: 2192.0000 - val_loss: 2.1283 - val_true_negatives: 194950.0000 - val_true_positives: 3788.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8830 - auc: 0.9544 - categorical_accuracy: 0.8830 - false_negatives: 3750.6282 - false_positives: 1786.8185 - loss: 0.3592 - true_negatives: 740148.0000 - true_positives: 21833.3320 - val_accuracy: 0.5853 - val_auc: 0.6086 - val_categorical_accuracy: 0.5853 - val_false_negatives: 2986.0000 - val_false_positives: 2200.0000 - val_loss: 2.2088 - val_true_negatives: 194942.0000 - val_true_positives: 3812.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.8958 - auc: 0.9614 - categorical_accuracy: 0.8958 - false_negatives: 3376.3755 - false_positives: 1584.3160 - loss: 0.3271 - true_negatives: 740350.5000 - true_positives: 22207.5840 - val_accuracy: 0.5949 - val_auc: 0.6223 - val_categorical_accuracy: 0.5949 - val_false_negatives: 2912.0000 - val_false_positives: 2147.0000 - val_loss: 2.1411 - val_true_negatives: 194995.0000 - val_true_positives: 3886.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - accuracy: 0.9003 - auc: 0.9654 - categorical_accuracy: 0.9003 - false_negatives: 3140.8403 - false_positives: 1524.3079 - loss: 0.3088 - true_negatives: 740410.5000 - true_positives: 22443.1191 - val_accuracy: 0.5753 - val_auc: 0.5941 - val_categorical_accuracy: 0.5753 - val_false_negatives: 3015.0000 - val_false_positives: 2271.0000 - val_loss: 2.3491 - val_true_negatives: 194871.0000 - val_true_positives: 3783.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8897 - auc: 0.9587 - categorical_accuracy: 0.8897 - false_negatives: 3385.5112 - false_positives: 1727.4812 - loss: 0.3362 - true_negatives: 740207.3750 - true_positives: 22198.4492 - val_accuracy: 0.5728 - val_auc: 0.5980 - val_categorical_accuracy: 0.5728 - val_false_negatives: 3043.0000 - val_false_positives: 2255.0000 - val_loss: 2.3091 - val_true_negatives: 194887.0000 - val_true_positives: 3755.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9002 - auc: 0.9655 - categorical_accuracy: 0.9002 - false_negatives: 3110.9907 - false_positives: 1552.7784 - loss: 0.3037 - true_negatives: 740382.0625 - true_positives: 22472.9688 - val_accuracy: 0.5677 - val_auc: 0.5793 - val_categorical_accuracy: 0.5677 - val_false_negatives: 3068.0000 - val_false_positives: 2396.0000 - val_loss: 2.4731 - val_true_negatives: 194746.0000 - val_true_positives: 3730.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9028 - auc: 0.9664 - categorical_accuracy: 0.9028 - false_negatives: 2986.4019 - false_positives: 1525.3411 - loss: 0.2947 - true_negatives: 740409.5000 - true_positives: 22597.5586 - val_accuracy: 0.5793 - val_auc: 0.5984 - val_categorical_accuracy: 0.5793 - val_false_negatives: 2969.0000 - val_false_positives: 2354.0000 - val_loss: 2.4053 - val_true_negatives: 194788.0000 - val_true_positives: 3829.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.9081 - auc: 0.9685 - categorical_accuracy: 0.9081 - false_negatives: 2805.0813 - false_positives: 1454.5901 - loss: 0.2842 - true_negatives: 740480.2500 - true_positives: 22778.8789 - val_accuracy: 0.5999 - val_auc: 0.6200 - val_categorical_accuracy: 0.5999 - val_false_negatives: 2824.0000 - val_false_positives: 2257.0000 - val_loss: 2.3087 - val_true_negatives: 194885.0000 - val_true_positives: 3974.0000\n"
     ]
    }
   ],
   "source": [
    "def deep_ann(input_shape = (256, 256)) -> keras.Model:\n",
    "    inputs = keras.Input((*input_shape, 1), dtype=np.float32)\n",
    "    x = keras.layers.Rescaling(scale=1./255)(inputs)\n",
    "    x = keras.layers.Flatten(\"channels_last\")(x)\n",
    "    x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(512, activation=\"relu\")(x)\n",
    "    outputs = keras.layers.Dense(30, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs, name=\"DeepNN\")\n",
    "    return model\n",
    "\n",
    "model = deep_ann()\n",
    "model.summary()\n",
    "\n",
    "optimizer = SGD()\n",
    "loss = CategoricalCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "log_dir = os.path.join(LOG_DIR, \"kaggle-speech-recognition\")\n",
    "model_log_dir = os.path.join(log_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S-{model.name}\"))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1)\n",
    "history = model.fit(x=ds_train, validation_data=ds_valid, batch_size=batch_size, epochs=50,\n",
    "            callbacks=[tensorboard_cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It does! No we can have fun with different architectures.\n",
    "\n",
    "### CNN\n",
    "Very simple cnn with 3 convolutional and pooling layers, dense layers at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"SimpleCNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"SimpleCNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_2             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12800</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │     <span style=\"color: #00af00; text-decoration-color: #00af00\">3,277,056</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,710</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ rescaling_2 (\u001b[38;5;33mRescaling\u001b[0m)         │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m84\u001b[0m, \u001b[38;5;34m84\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_2             │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m12800\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │     \u001b[38;5;34m3,277,056\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m)               │         \u001b[38;5;34m7,710\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,387,774</span> (12.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,387,774\u001b[0m (12.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,387,774</span> (12.92 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,387,774\u001b[0m (12.92 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732460489.903043   18537 service.cc:148] XLA service 0x7f977800afb0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732460489.903069   18537 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-11-24 16:01:29.947882: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1732460490.024152   18537 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   4/1597\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - auc: 0.0323 - categorical_accuracy: 0.0495 - f1_score: 0.0238 - false_negatives: 80.0000 - false_positives: 0.0000e+00 - loss: 3.4019 - true_negatives: 2320.0000 - true_positives: 0.0000e+00 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732460496.267377   18537 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 28ms/step - auc: 0.0353 - categorical_accuracy: 0.0409 - f1_score: 0.0107 - false_negatives: 25583.9590 - false_positives: 0.0000e+00 - loss: 3.3981 - true_negatives: 741934.8125 - true_positives: 0.0000e+00 - val_auc: 0.0399 - val_categorical_accuracy: 0.0474 - val_f1_score: 0.0167 - val_false_negatives: 6798.0000 - val_false_positives: 0.0000e+00 - val_loss: 3.3869 - val_true_negatives: 197142.0000 - val_true_positives: 0.0000e+00\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.0394 - categorical_accuracy: 0.0519 - f1_score: 0.0196 - false_negatives: 25583.9590 - false_positives: 0.0000e+00 - loss: 3.3884 - true_negatives: 741934.8125 - true_positives: 0.0000e+00 - val_auc: 0.0442 - val_categorical_accuracy: 0.0713 - val_f1_score: 0.0336 - val_false_negatives: 6798.0000 - val_false_positives: 0.0000e+00 - val_loss: 3.3742 - val_true_negatives: 197142.0000 - val_true_positives: 0.0000e+00\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - auc: 0.0458 - categorical_accuracy: 0.0700 - f1_score: 0.0279 - false_negatives: 25583.9590 - false_positives: 0.0000e+00 - loss: 3.3753 - true_negatives: 741934.8125 - true_positives: 0.0000e+00 - val_auc: 0.0571 - val_categorical_accuracy: 0.0866 - val_f1_score: 0.0441 - val_false_negatives: 6798.0000 - val_false_positives: 0.0000e+00 - val_loss: 3.3458 - val_true_negatives: 197142.0000 - val_true_positives: 0.0000e+00\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.0574 - categorical_accuracy: 0.0834 - f1_score: 0.0399 - false_negatives: 25583.9590 - false_positives: 0.0000e+00 - loss: 3.3411 - true_negatives: 741934.8125 - true_positives: 0.0000e+00 - val_auc: 0.0791 - val_categorical_accuracy: 0.1027 - val_f1_score: 0.0586 - val_false_negatives: 6798.0000 - val_false_positives: 0.0000e+00 - val_loss: 3.2526 - val_true_negatives: 197142.0000 - val_true_positives: 0.0000e+00\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.0772 - categorical_accuracy: 0.1039 - f1_score: 0.0675 - false_negatives: 25583.9590 - false_positives: 0.0000e+00 - loss: 3.2339 - true_negatives: 741934.8125 - true_positives: 0.0000e+00 - val_auc: 0.1139 - val_categorical_accuracy: 0.1365 - val_f1_score: 0.0949 - val_false_negatives: 6797.0000 - val_false_positives: 0.0000e+00 - val_loss: 3.0706 - val_true_negatives: 197142.0000 - val_true_positives: 1.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - auc: 0.1056 - categorical_accuracy: 0.1341 - f1_score: 0.1106 - false_negatives: 25565.7422 - false_positives: 1.1126 - loss: 3.0898 - true_negatives: 741933.7500 - true_positives: 18.2178 - val_auc: 0.1412 - val_categorical_accuracy: 0.1617 - val_f1_score: 0.1212 - val_false_negatives: 6779.0000 - val_false_positives: 2.0000 - val_loss: 2.9507 - val_true_negatives: 197140.0000 - val_true_positives: 19.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.1351 - categorical_accuracy: 0.1642 - f1_score: 0.1470 - false_negatives: 25472.5156 - false_positives: 32.0889 - loss: 2.9708 - true_negatives: 741902.7500 - true_positives: 111.4443 - val_auc: 0.1735 - val_categorical_accuracy: 0.1909 - val_f1_score: 0.1640 - val_false_negatives: 6714.0000 - val_false_positives: 20.0000 - val_loss: 2.8228 - val_true_negatives: 197122.0000 - val_true_positives: 84.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.1709 - categorical_accuracy: 0.1970 - f1_score: 0.1835 - false_negatives: 25246.2520 - false_positives: 109.6533 - loss: 2.8422 - true_negatives: 741825.1875 - true_positives: 337.7071 - val_auc: 0.2074 - val_categorical_accuracy: 0.2180 - val_f1_score: 0.2023 - val_false_negatives: 6648.0000 - val_false_positives: 39.0000 - val_loss: 2.7169 - val_true_negatives: 197103.0000 - val_true_positives: 150.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.2091 - categorical_accuracy: 0.2284 - f1_score: 0.2172 - false_negatives: 24850.0156 - false_positives: 264.3529 - loss: 2.7137 - true_negatives: 741670.5000 - true_positives: 733.9437 - val_auc: 0.2442 - val_categorical_accuracy: 0.2487 - val_f1_score: 0.2461 - val_false_negatives: 6470.0000 - val_false_positives: 86.0000 - val_loss: 2.5755 - val_true_negatives: 197056.0000 - val_true_positives: 328.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.2466 - categorical_accuracy: 0.2578 - f1_score: 0.2480 - false_negatives: 24309.3633 - false_positives: 452.9612 - loss: 2.5908 - true_negatives: 741481.8750 - true_positives: 1274.5957 - val_auc: 0.2765 - val_categorical_accuracy: 0.2758 - val_f1_score: 0.2720 - val_false_negatives: 6350.0000 - val_false_positives: 161.0000 - val_loss: 2.4915 - val_true_negatives: 196981.0000 - val_true_positives: 448.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.2812 - categorical_accuracy: 0.2839 - f1_score: 0.2747 - false_negatives: 23763.4863 - false_positives: 605.7791 - loss: 2.4813 - true_negatives: 741329.0625 - true_positives: 1820.4738 - val_auc: 0.3067 - val_categorical_accuracy: 0.3046 - val_f1_score: 0.3062 - val_false_negatives: 6228.0000 - val_false_positives: 161.0000 - val_loss: 2.3952 - val_true_negatives: 196981.0000 - val_true_positives: 570.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.3147 - categorical_accuracy: 0.3102 - f1_score: 0.3025 - false_negatives: 23159.1250 - false_positives: 776.0381 - loss: 2.3853 - true_negatives: 741158.8125 - true_positives: 2424.8354 - val_auc: 0.3220 - val_categorical_accuracy: 0.3154 - val_f1_score: 0.3064 - val_false_negatives: 6016.0000 - val_false_positives: 298.0000 - val_loss: 2.3528 - val_true_negatives: 196844.0000 - val_true_positives: 782.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.3466 - categorical_accuracy: 0.3404 - f1_score: 0.3334 - false_negatives: 22554.0684 - false_positives: 964.8041 - loss: 2.2925 - true_negatives: 740970.0625 - true_positives: 3029.8923 - val_auc: 0.3680 - val_categorical_accuracy: 0.3511 - val_f1_score: 0.3599 - val_false_negatives: 5889.0000 - val_false_positives: 274.0000 - val_loss: 2.1991 - val_true_negatives: 196868.0000 - val_true_positives: 909.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.3772 - categorical_accuracy: 0.3625 - f1_score: 0.3561 - false_negatives: 21994.9785 - false_positives: 1057.8817 - loss: 2.2065 - true_negatives: 740876.9375 - true_positives: 3588.9812 - val_auc: 0.3577 - val_categorical_accuracy: 0.3402 - val_f1_score: 0.3341 - val_false_negatives: 5705.0000 - val_false_positives: 546.0000 - val_loss: 2.2223 - val_true_negatives: 196596.0000 - val_true_positives: 1093.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - auc: 0.4047 - categorical_accuracy: 0.3842 - f1_score: 0.3783 - false_negatives: 21441.0156 - false_positives: 1167.8679 - loss: 2.1319 - true_negatives: 740767.0000 - true_positives: 4142.9443 - val_auc: 0.4148 - val_categorical_accuracy: 0.3866 - val_f1_score: 0.3794 - val_false_negatives: 5532.0000 - val_false_positives: 378.0000 - val_loss: 2.0866 - val_true_negatives: 196764.0000 - val_true_positives: 1266.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.4293 - categorical_accuracy: 0.4029 - f1_score: 0.3976 - false_negatives: 20930.0391 - false_positives: 1311.3623 - loss: 2.0641 - true_negatives: 740623.5000 - true_positives: 4653.9219 - val_auc: 0.4177 - val_categorical_accuracy: 0.3897 - val_f1_score: 0.3864 - val_false_negatives: 5470.0000 - val_false_positives: 515.0000 - val_loss: 2.0551 - val_true_negatives: 196627.0000 - val_true_positives: 1328.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.4504 - categorical_accuracy: 0.4198 - f1_score: 0.4150 - false_negatives: 20430.7910 - false_positives: 1420.3022 - loss: 2.0019 - true_negatives: 740514.5625 - true_positives: 5153.1685 - val_auc: 0.4413 - val_categorical_accuracy: 0.4129 - val_f1_score: 0.4172 - val_false_negatives: 5330.0000 - val_false_positives: 549.0000 - val_loss: 2.0055 - val_true_negatives: 196593.0000 - val_true_positives: 1468.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.4715 - categorical_accuracy: 0.4363 - f1_score: 0.4319 - false_negatives: 19952.3008 - false_positives: 1566.1445 - loss: 1.9425 - true_negatives: 740368.6875 - true_positives: 5631.6592 - val_auc: 0.4699 - val_categorical_accuracy: 0.4281 - val_f1_score: 0.4236 - val_false_negatives: 5219.0000 - val_false_positives: 485.0000 - val_loss: 1.9265 - val_true_negatives: 196657.0000 - val_true_positives: 1579.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.4884 - categorical_accuracy: 0.4493 - f1_score: 0.4455 - false_negatives: 19551.1855 - false_positives: 1621.2354 - loss: 1.8947 - true_negatives: 740313.6250 - true_positives: 6032.7734 - val_auc: 0.4855 - val_categorical_accuracy: 0.4394 - val_f1_score: 0.4352 - val_false_negatives: 5092.0000 - val_false_positives: 531.0000 - val_loss: 1.8803 - val_true_negatives: 196611.0000 - val_true_positives: 1706.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - auc: 0.5062 - categorical_accuracy: 0.4654 - f1_score: 0.4617 - false_negatives: 19062.2910 - false_positives: 1741.5883 - loss: 1.8470 - true_negatives: 740193.2500 - true_positives: 6521.6689 - val_auc: 0.4973 - val_categorical_accuracy: 0.4481 - val_f1_score: 0.4444 - val_false_negatives: 5017.0000 - val_false_positives: 547.0000 - val_loss: 1.8534 - val_true_negatives: 196595.0000 - val_true_positives: 1781.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.5195 - categorical_accuracy: 0.4762 - f1_score: 0.4731 - false_negatives: 18655.6211 - false_positives: 1821.5276 - loss: 1.8077 - true_negatives: 740113.3125 - true_positives: 6928.3394 - val_auc: 0.4765 - val_categorical_accuracy: 0.4354 - val_f1_score: 0.4426 - val_false_negatives: 5029.0000 - val_false_positives: 662.0000 - val_loss: 1.9028 - val_true_negatives: 196480.0000 - val_true_positives: 1769.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.5338 - categorical_accuracy: 0.4845 - f1_score: 0.4814 - false_negatives: 18299.8887 - false_positives: 1881.2328 - loss: 1.7666 - true_negatives: 740053.6250 - true_positives: 7284.0708 - val_auc: 0.5225 - val_categorical_accuracy: 0.4723 - val_f1_score: 0.4714 - val_false_negatives: 4849.0000 - val_false_positives: 565.0000 - val_loss: 1.7932 - val_true_negatives: 196577.0000 - val_true_positives: 1949.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.5468 - categorical_accuracy: 0.4967 - f1_score: 0.4940 - false_negatives: 17976.0742 - false_positives: 1968.2578 - loss: 1.7305 - true_negatives: 739966.5625 - true_positives: 7607.8853 - val_auc: 0.5188 - val_categorical_accuracy: 0.4669 - val_f1_score: 0.4654 - val_false_negatives: 4757.0000 - val_false_positives: 690.0000 - val_loss: 1.7838 - val_true_negatives: 196452.0000 - val_true_positives: 2041.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.5581 - categorical_accuracy: 0.5073 - f1_score: 0.5046 - false_negatives: 17630.2422 - false_positives: 2060.4707 - loss: 1.6957 - true_negatives: 739874.3750 - true_positives: 7953.7173 - val_auc: 0.5303 - val_categorical_accuracy: 0.4801 - val_f1_score: 0.4790 - val_false_negatives: 4689.0000 - val_false_positives: 689.0000 - val_loss: 1.7622 - val_true_negatives: 196453.0000 - val_true_positives: 2109.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.5690 - categorical_accuracy: 0.5146 - f1_score: 0.5122 - false_negatives: 17260.9238 - false_positives: 2152.6421 - loss: 1.6659 - true_negatives: 739782.1875 - true_positives: 8323.0361 - val_auc: 0.5275 - val_categorical_accuracy: 0.4784 - val_f1_score: 0.4852 - val_false_negatives: 4685.0000 - val_false_positives: 724.0000 - val_loss: 1.7574 - val_true_negatives: 196418.0000 - val_true_positives: 2113.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - auc: 0.5793 - categorical_accuracy: 0.5210 - f1_score: 0.5185 - false_negatives: 16971.1895 - false_positives: 2158.2534 - loss: 1.6326 - true_negatives: 739776.5625 - true_positives: 8612.7705 - val_auc: 0.5492 - val_categorical_accuracy: 0.4929 - val_f1_score: 0.4918 - val_false_negatives: 4546.0000 - val_false_positives: 714.0000 - val_loss: 1.7205 - val_true_negatives: 196428.0000 - val_true_positives: 2252.0000\n",
      "Epoch 27/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.5900 - categorical_accuracy: 0.5299 - f1_score: 0.5276 - false_negatives: 16682.3379 - false_positives: 2193.7742 - loss: 1.6048 - true_negatives: 739741.0625 - true_positives: 8901.6230 - val_auc: 0.5584 - val_categorical_accuracy: 0.5044 - val_f1_score: 0.5014 - val_false_negatives: 4480.0000 - val_false_positives: 720.0000 - val_loss: 1.6942 - val_true_negatives: 196422.0000 - val_true_positives: 2318.0000\n",
      "Epoch 28/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.5983 - categorical_accuracy: 0.5365 - f1_score: 0.5346 - false_negatives: 16465.2441 - false_positives: 2314.8892 - loss: 1.5793 - true_negatives: 739619.9375 - true_positives: 9118.7148 - val_auc: 0.5647 - val_categorical_accuracy: 0.5106 - val_f1_score: 0.5101 - val_false_negatives: 4407.0000 - val_false_positives: 782.0000 - val_loss: 1.6694 - val_true_negatives: 196360.0000 - val_true_positives: 2391.0000\n",
      "Epoch 29/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.6066 - categorical_accuracy: 0.5444 - f1_score: 0.5423 - false_negatives: 16181.5039 - false_positives: 2319.5532 - loss: 1.5516 - true_negatives: 739615.3125 - true_positives: 9402.4561 - val_auc: 0.5815 - val_categorical_accuracy: 0.5235 - val_f1_score: 0.5215 - val_false_negatives: 4380.0000 - val_false_positives: 693.0000 - val_loss: 1.6329 - val_true_negatives: 196449.0000 - val_true_positives: 2418.0000\n",
      "Epoch 30/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.6164 - categorical_accuracy: 0.5540 - f1_score: 0.5523 - false_negatives: 15933.3613 - false_positives: 2364.3359 - loss: 1.5273 - true_negatives: 739570.5000 - true_positives: 9650.5986 - val_auc: 0.5807 - val_categorical_accuracy: 0.5185 - val_f1_score: 0.5161 - val_false_negatives: 4295.0000 - val_false_positives: 760.0000 - val_loss: 1.6391 - val_true_negatives: 196382.0000 - val_true_positives: 2503.0000\n",
      "Epoch 31/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.6243 - categorical_accuracy: 0.5598 - f1_score: 0.5582 - false_negatives: 15646.2002 - false_positives: 2409.5745 - loss: 1.5020 - true_negatives: 739525.2500 - true_positives: 9937.7598 - val_auc: 0.5796 - val_categorical_accuracy: 0.5231 - val_f1_score: 0.5227 - val_false_negatives: 4228.0000 - val_false_positives: 809.0000 - val_loss: 1.6446 - val_true_negatives: 196333.0000 - val_true_positives: 2570.0000\n",
      "Epoch 32/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.6323 - categorical_accuracy: 0.5669 - f1_score: 0.5654 - false_negatives: 15415.2900 - false_positives: 2405.4788 - loss: 1.4795 - true_negatives: 739529.3750 - true_positives: 10168.6699 - val_auc: 0.5924 - val_categorical_accuracy: 0.5303 - val_f1_score: 0.5269 - val_false_negatives: 4167.0000 - val_false_positives: 759.0000 - val_loss: 1.6064 - val_true_negatives: 196383.0000 - val_true_positives: 2631.0000\n",
      "Epoch 33/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.6403 - categorical_accuracy: 0.5703 - f1_score: 0.5684 - false_negatives: 15194.3213 - false_positives: 2478.6165 - loss: 1.4568 - true_negatives: 739456.2500 - true_positives: 10389.6387 - val_auc: 0.5907 - val_categorical_accuracy: 0.5350 - val_f1_score: 0.5369 - val_false_negatives: 4140.0000 - val_false_positives: 863.0000 - val_loss: 1.6094 - val_true_negatives: 196279.0000 - val_true_positives: 2658.0000\n",
      "Epoch 34/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.6469 - categorical_accuracy: 0.5769 - f1_score: 0.5754 - false_negatives: 14953.1436 - false_positives: 2525.7510 - loss: 1.4350 - true_negatives: 739409.0625 - true_positives: 10630.8164 - val_auc: 0.6003 - val_categorical_accuracy: 0.5399 - val_f1_score: 0.5399 - val_false_negatives: 4101.0000 - val_false_positives: 808.0000 - val_loss: 1.5867 - val_true_negatives: 196334.0000 - val_true_positives: 2697.0000\n",
      "Epoch 35/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.6534 - categorical_accuracy: 0.5854 - f1_score: 0.5839 - false_negatives: 14810.5635 - false_positives: 2551.0293 - loss: 1.4144 - true_negatives: 739383.8125 - true_positives: 10773.3965 - val_auc: 0.6073 - val_categorical_accuracy: 0.5460 - val_f1_score: 0.5466 - val_false_negatives: 4040.0000 - val_false_positives: 844.0000 - val_loss: 1.5619 - val_true_negatives: 196298.0000 - val_true_positives: 2758.0000\n",
      "Epoch 36/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.6612 - categorical_accuracy: 0.5904 - f1_score: 0.5891 - false_negatives: 14573.2373 - false_positives: 2557.5312 - loss: 1.3937 - true_negatives: 739377.3125 - true_positives: 11010.7227 - val_auc: 0.6117 - val_categorical_accuracy: 0.5455 - val_f1_score: 0.5478 - val_false_negatives: 3986.0000 - val_false_positives: 840.0000 - val_loss: 1.5616 - val_true_negatives: 196302.0000 - val_true_positives: 2812.0000\n",
      "Epoch 37/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.6673 - categorical_accuracy: 0.5936 - f1_score: 0.5925 - false_negatives: 14300.9795 - false_positives: 2558.4299 - loss: 1.3751 - true_negatives: 739376.4375 - true_positives: 11282.9805 - val_auc: 0.5970 - val_categorical_accuracy: 0.5353 - val_f1_score: 0.5397 - val_false_negatives: 4009.0000 - val_false_positives: 916.0000 - val_loss: 1.5972 - val_true_negatives: 196226.0000 - val_true_positives: 2789.0000\n",
      "Epoch 38/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.6747 - categorical_accuracy: 0.6009 - f1_score: 0.6001 - false_negatives: 14095.0811 - false_positives: 2585.1953 - loss: 1.3548 - true_negatives: 739349.6250 - true_positives: 11488.8789 - val_auc: 0.6163 - val_categorical_accuracy: 0.5518 - val_f1_score: 0.5559 - val_false_negatives: 3944.0000 - val_false_positives: 832.0000 - val_loss: 1.5474 - val_true_negatives: 196310.0000 - val_true_positives: 2854.0000\n",
      "Epoch 39/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.6805 - categorical_accuracy: 0.6068 - f1_score: 0.6056 - false_negatives: 13912.0498 - false_positives: 2593.9587 - loss: 1.3371 - true_negatives: 739340.8750 - true_positives: 11671.9102 - val_auc: 0.6044 - val_categorical_accuracy: 0.5457 - val_f1_score: 0.5429 - val_false_negatives: 3941.0000 - val_false_positives: 994.0000 - val_loss: 1.5738 - val_true_negatives: 196148.0000 - val_true_positives: 2857.0000\n",
      "Epoch 40/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.6869 - categorical_accuracy: 0.6119 - f1_score: 0.6109 - false_negatives: 13663.7275 - false_positives: 2637.9211 - loss: 1.3172 - true_negatives: 739296.9375 - true_positives: 11920.2324 - val_auc: 0.6225 - val_categorical_accuracy: 0.5606 - val_f1_score: 0.5660 - val_false_negatives: 3846.0000 - val_false_positives: 920.0000 - val_loss: 1.5246 - val_true_negatives: 196222.0000 - val_true_positives: 2952.0000\n",
      "Epoch 41/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.6926 - categorical_accuracy: 0.6163 - f1_score: 0.6151 - false_negatives: 13527.6689 - false_positives: 2654.2190 - loss: 1.2983 - true_negatives: 739280.6250 - true_positives: 12056.2910 - val_auc: 0.6226 - val_categorical_accuracy: 0.5646 - val_f1_score: 0.5641 - val_false_negatives: 3824.0000 - val_false_positives: 936.0000 - val_loss: 1.5285 - val_true_negatives: 196206.0000 - val_true_positives: 2974.0000\n",
      "Epoch 42/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.6995 - categorical_accuracy: 0.6220 - f1_score: 0.6210 - false_negatives: 13307.8789 - false_positives: 2648.1140 - loss: 1.2795 - true_negatives: 739286.7500 - true_positives: 12276.0811 - val_auc: 0.6308 - val_categorical_accuracy: 0.5665 - val_f1_score: 0.5694 - val_false_negatives: 3798.0000 - val_false_positives: 942.0000 - val_loss: 1.4993 - val_true_negatives: 196200.0000 - val_true_positives: 3000.0000\n",
      "Epoch 43/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.7047 - categorical_accuracy: 0.6271 - f1_score: 0.6263 - false_negatives: 13158.1348 - false_positives: 2663.8186 - loss: 1.2635 - true_negatives: 739271.0000 - true_positives: 12425.8252 - val_auc: 0.6292 - val_categorical_accuracy: 0.5635 - val_f1_score: 0.5634 - val_false_negatives: 3735.0000 - val_false_positives: 977.0000 - val_loss: 1.5189 - val_true_negatives: 196165.0000 - val_true_positives: 3063.0000\n",
      "Epoch 44/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.7105 - categorical_accuracy: 0.6324 - f1_score: 0.6316 - false_negatives: 12980.5674 - false_positives: 2672.6489 - loss: 1.2464 - true_negatives: 739262.1875 - true_positives: 12603.3926 - val_auc: 0.6348 - val_categorical_accuracy: 0.5705 - val_f1_score: 0.5713 - val_false_negatives: 3731.0000 - val_false_positives: 960.0000 - val_loss: 1.4950 - val_true_negatives: 196182.0000 - val_true_positives: 3067.0000\n",
      "Epoch 45/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.7177 - categorical_accuracy: 0.6414 - f1_score: 0.6405 - false_negatives: 12774.6074 - false_positives: 2644.4312 - loss: 1.2267 - true_negatives: 739290.4375 - true_positives: 12809.3525 - val_auc: 0.6346 - val_categorical_accuracy: 0.5716 - val_f1_score: 0.5698 - val_false_negatives: 3687.0000 - val_false_positives: 990.0000 - val_loss: 1.5071 - val_true_negatives: 196152.0000 - val_true_positives: 3111.0000\n",
      "Epoch 46/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.7212 - categorical_accuracy: 0.6406 - f1_score: 0.6398 - false_negatives: 12590.9834 - false_positives: 2696.3191 - loss: 1.2126 - true_negatives: 739238.5000 - true_positives: 12992.9766 - val_auc: 0.6356 - val_categorical_accuracy: 0.5718 - val_f1_score: 0.5726 - val_false_negatives: 3700.0000 - val_false_positives: 968.0000 - val_loss: 1.4978 - val_true_negatives: 196174.0000 - val_true_positives: 3098.0000\n",
      "Epoch 47/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.7269 - categorical_accuracy: 0.6467 - f1_score: 0.6460 - false_negatives: 12417.6250 - false_positives: 2665.1013 - loss: 1.1952 - true_negatives: 739269.7500 - true_positives: 13166.3350 - val_auc: 0.6408 - val_categorical_accuracy: 0.5747 - val_f1_score: 0.5755 - val_false_negatives: 3636.0000 - val_false_positives: 1026.0000 - val_loss: 1.4842 - val_true_negatives: 196116.0000 - val_true_positives: 3162.0000\n",
      "Epoch 48/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.7325 - categorical_accuracy: 0.6517 - f1_score: 0.6508 - false_negatives: 12304.9883 - false_positives: 2654.6685 - loss: 1.1792 - true_negatives: 739280.1875 - true_positives: 13278.9717 - val_auc: 0.6303 - val_categorical_accuracy: 0.5681 - val_f1_score: 0.5714 - val_false_negatives: 3641.0000 - val_false_positives: 1127.0000 - val_loss: 1.5102 - val_true_negatives: 196015.0000 - val_true_positives: 3157.0000\n",
      "Epoch 49/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.7379 - categorical_accuracy: 0.6564 - f1_score: 0.6556 - false_negatives: 12056.8701 - false_positives: 2626.0420 - loss: 1.1632 - true_negatives: 739308.8125 - true_positives: 13527.0898 - val_auc: 0.6473 - val_categorical_accuracy: 0.5846 - val_f1_score: 0.5868 - val_false_negatives: 3537.0000 - val_false_positives: 1037.0000 - val_loss: 1.4678 - val_true_negatives: 196105.0000 - val_true_positives: 3261.0000\n",
      "Epoch 50/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.7425 - categorical_accuracy: 0.6609 - f1_score: 0.6601 - false_negatives: 11909.5762 - false_positives: 2647.1926 - loss: 1.1480 - true_negatives: 739287.6250 - true_positives: 13674.3838 - val_auc: 0.6395 - val_categorical_accuracy: 0.5744 - val_f1_score: 0.5742 - val_false_negatives: 3593.0000 - val_false_positives: 1115.0000 - val_loss: 1.4953 - val_true_negatives: 196027.0000 - val_true_positives: 3205.0000\n",
      "Epoch 1/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 24ms/step - auc: 0.2251 - categorical_accuracy: 0.1963 - f1_score: 0.2210 - false_negatives: 29176.9590 - false_positives: 1115.0000 - loss: 3.3926 - true_negatives: 937961.8125 - true_positives: 3205.0000 - val_auc: 0.0514 - val_categorical_accuracy: 0.0743 - val_f1_score: 0.0394 - val_false_negatives: 6798.0000 - val_false_positives: 0.0000e+00 - val_loss: 3.3541 - val_true_negatives: 197142.0000 - val_true_positives: 0.0000e+00\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - auc: 0.0586 - categorical_accuracy: 0.0855 - f1_score: 0.0582 - false_negatives: 25583.9492 - false_positives: 0.0269 - loss: 3.3122 - true_negatives: 741934.8125 - true_positives: 0.0113 - val_auc: 0.1124 - val_categorical_accuracy: 0.1327 - val_f1_score: 0.1069 - val_false_negatives: 6797.0000 - val_false_positives: 0.0000e+00 - val_loss: 3.0733 - val_true_negatives: 197142.0000 - val_true_positives: 1.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - auc: 0.1144 - categorical_accuracy: 0.1382 - f1_score: 0.1223 - false_negatives: 25496.1387 - false_positives: 26.7497 - loss: 3.0493 - true_negatives: 741908.0625 - true_positives: 87.8210 - val_auc: 0.1897 - val_categorical_accuracy: 0.2027 - val_f1_score: 0.1904 - val_false_negatives: 6717.0000 - val_false_positives: 23.0000 - val_loss: 2.7544 - val_true_negatives: 197119.0000 - val_true_positives: 81.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - auc: 0.1981 - categorical_accuracy: 0.2130 - f1_score: 0.2015 - false_negatives: 24869.1621 - false_positives: 237.6852 - loss: 2.7361 - true_negatives: 741697.1250 - true_positives: 714.7972 - val_auc: 0.2613 - val_categorical_accuracy: 0.2699 - val_f1_score: 0.2449 - val_false_negatives: 6264.0000 - val_false_positives: 272.0000 - val_loss: 2.4758 - val_true_negatives: 196870.0000 - val_true_positives: 534.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.2937 - categorical_accuracy: 0.2946 - f1_score: 0.2843 - false_negatives: 23573.5352 - false_positives: 629.9024 - loss: 2.4428 - true_negatives: 741304.9375 - true_positives: 2010.4255 - val_auc: 0.3693 - val_categorical_accuracy: 0.3532 - val_f1_score: 0.3467 - val_false_negatives: 5936.0000 - val_false_positives: 254.0000 - val_loss: 2.1876 - val_true_negatives: 196888.0000 - val_true_positives: 862.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - auc: 0.3690 - categorical_accuracy: 0.3532 - f1_score: 0.3453 - false_negatives: 22174.8750 - false_positives: 1020.4099 - loss: 2.2211 - true_negatives: 740914.4375 - true_positives: 3409.0857 - val_auc: 0.3739 - val_categorical_accuracy: 0.3529 - val_f1_score: 0.3473 - val_false_negatives: 5665.0000 - val_false_positives: 514.0000 - val_loss: 2.1585 - val_true_negatives: 196628.0000 - val_true_positives: 1133.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - auc: 0.4257 - categorical_accuracy: 0.4008 - f1_score: 0.3950 - false_negatives: 20887.1230 - false_positives: 1411.7422 - loss: 2.0565 - true_negatives: 740523.1250 - true_positives: 4696.8369 - val_auc: 0.4418 - val_categorical_accuracy: 0.4100 - val_f1_score: 0.4035 - val_false_negatives: 5331.0000 - val_false_positives: 537.0000 - val_loss: 1.9804 - val_true_negatives: 196605.0000 - val_true_positives: 1467.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - auc: 0.4691 - categorical_accuracy: 0.4346 - f1_score: 0.4297 - false_negatives: 19704.3027 - false_positives: 1774.9974 - loss: 1.9323 - true_negatives: 740159.8125 - true_positives: 5879.6577 - val_auc: 0.4884 - val_categorical_accuracy: 0.4520 - val_f1_score: 0.4489 - val_false_negatives: 5063.0000 - val_false_positives: 542.0000 - val_loss: 1.8711 - val_true_negatives: 196600.0000 - val_true_positives: 1735.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - auc: 0.5038 - categorical_accuracy: 0.4589 - f1_score: 0.4553 - false_negatives: 18765.6641 - false_positives: 1983.3041 - loss: 1.8351 - true_negatives: 739951.5625 - true_positives: 6818.2964 - val_auc: 0.5138 - val_categorical_accuracy: 0.4619 - val_f1_score: 0.4638 - val_false_negatives: 4889.0000 - val_false_positives: 574.0000 - val_loss: 1.7963 - val_true_negatives: 196568.0000 - val_true_positives: 1909.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - auc: 0.5306 - categorical_accuracy: 0.4822 - f1_score: 0.4791 - false_negatives: 18035.5840 - false_positives: 2188.4392 - loss: 1.7556 - true_negatives: 739746.3750 - true_positives: 7548.3755 - val_auc: 0.5208 - val_categorical_accuracy: 0.4721 - val_f1_score: 0.4748 - val_false_negatives: 4720.0000 - val_false_positives: 682.0000 - val_loss: 1.7830 - val_true_negatives: 196460.0000 - val_true_positives: 2078.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 25ms/step - auc: 0.5559 - categorical_accuracy: 0.5028 - f1_score: 0.4999 - false_negatives: 17296.4297 - false_positives: 2348.0945 - loss: 1.6839 - true_negatives: 739586.7500 - true_positives: 8287.5303 - val_auc: 0.5462 - val_categorical_accuracy: 0.4919 - val_f1_score: 0.4907 - val_false_negatives: 4585.0000 - val_false_positives: 683.0000 - val_loss: 1.7187 - val_true_negatives: 196459.0000 - val_true_positives: 2213.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.5777 - categorical_accuracy: 0.5225 - f1_score: 0.5198 - false_negatives: 16737.9551 - false_positives: 2439.5032 - loss: 1.6221 - true_negatives: 739495.3125 - true_positives: 8846.0059 - val_auc: 0.5614 - val_categorical_accuracy: 0.5066 - val_f1_score: 0.5071 - val_false_negatives: 4416.0000 - val_false_positives: 762.0000 - val_loss: 1.6701 - val_true_negatives: 196380.0000 - val_true_positives: 2382.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.5971 - categorical_accuracy: 0.5381 - f1_score: 0.5358 - false_negatives: 16222.2266 - false_positives: 2474.7498 - loss: 1.5675 - true_negatives: 739460.0625 - true_positives: 9361.7334 - val_auc: 0.5757 - val_categorical_accuracy: 0.5113 - val_f1_score: 0.5090 - val_false_negatives: 4315.0000 - val_false_positives: 777.0000 - val_loss: 1.6444 - val_true_negatives: 196365.0000 - val_true_positives: 2483.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.6150 - categorical_accuracy: 0.5518 - f1_score: 0.5496 - false_negatives: 15708.1230 - false_positives: 2563.4756 - loss: 1.5157 - true_negatives: 739371.3750 - true_positives: 9875.8369 - val_auc: 0.5699 - val_categorical_accuracy: 0.5065 - val_f1_score: 0.5120 - val_false_negatives: 4283.0000 - val_false_positives: 912.0000 - val_loss: 1.6494 - val_true_negatives: 196230.0000 - val_true_positives: 2515.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.6320 - categorical_accuracy: 0.5646 - f1_score: 0.5628 - false_negatives: 15173.1465 - false_positives: 2648.8347 - loss: 1.4661 - true_negatives: 739286.0000 - true_positives: 10410.8135 - val_auc: 0.5859 - val_categorical_accuracy: 0.5227 - val_f1_score: 0.5217 - val_false_negatives: 4071.0000 - val_false_positives: 978.0000 - val_loss: 1.6162 - val_true_negatives: 196164.0000 - val_true_positives: 2727.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.6486 - categorical_accuracy: 0.5796 - f1_score: 0.5778 - false_negatives: 14706.4561 - false_positives: 2704.7803 - loss: 1.4169 - true_negatives: 739230.0625 - true_positives: 10877.5039 - val_auc: 0.6043 - val_categorical_accuracy: 0.5405 - val_f1_score: 0.5361 - val_false_negatives: 3994.0000 - val_false_positives: 939.0000 - val_loss: 1.5589 - val_true_negatives: 196203.0000 - val_true_positives: 2804.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.6638 - categorical_accuracy: 0.5957 - f1_score: 0.5941 - false_negatives: 14306.5879 - false_positives: 2714.3511 - loss: 1.3724 - true_negatives: 739220.5000 - true_positives: 11277.3721 - val_auc: 0.6189 - val_categorical_accuracy: 0.5516 - val_f1_score: 0.5519 - val_false_negatives: 3948.0000 - val_false_positives: 915.0000 - val_loss: 1.5179 - val_true_negatives: 196227.0000 - val_true_positives: 2850.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - auc: 0.6782 - categorical_accuracy: 0.6051 - f1_score: 0.6038 - false_negatives: 13808.0391 - false_positives: 2749.1077 - loss: 1.3303 - true_negatives: 739185.7500 - true_positives: 11775.9209 - val_auc: 0.5946 - val_categorical_accuracy: 0.5353 - val_f1_score: 0.5297 - val_false_negatives: 3825.0000 - val_false_positives: 1169.0000 - val_loss: 1.6085 - val_true_negatives: 195973.0000 - val_true_positives: 2973.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - auc: 0.6928 - categorical_accuracy: 0.6174 - f1_score: 0.6162 - false_negatives: 13364.2871 - false_positives: 2774.8435 - loss: 1.2856 - true_negatives: 739160.0000 - true_positives: 12219.6729 - val_auc: 0.6289 - val_categorical_accuracy: 0.5640 - val_f1_score: 0.5632 - val_false_negatives: 3776.0000 - val_false_positives: 988.0000 - val_loss: 1.4960 - val_true_negatives: 196154.0000 - val_true_positives: 3022.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - auc: 0.7083 - categorical_accuracy: 0.6341 - f1_score: 0.6331 - false_negatives: 12910.4463 - false_positives: 2738.0745 - loss: 1.2413 - true_negatives: 739196.7500 - true_positives: 12673.5137 - val_auc: 0.6253 - val_categorical_accuracy: 0.5553 - val_f1_score: 0.5572 - val_false_negatives: 3746.0000 - val_false_positives: 1079.0000 - val_loss: 1.5165 - val_true_negatives: 196063.0000 - val_true_positives: 3052.0000\n",
      "Epoch 1/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 27ms/step - auc: 0.2276 - categorical_accuracy: 0.2011 - f1_score: 0.2201 - false_negatives: 29329.1992 - false_positives: 1079.3461 - loss: 3.3656 - true_negatives: 937997.5000 - true_positives: 3052.7603 - val_auc: 0.0964 - val_categorical_accuracy: 0.1219 - val_f1_score: 0.0908 - val_false_negatives: 6628.0000 - val_false_positives: 708.0000 - val_loss: 3.1548 - val_true_negatives: 196434.0000 - val_true_positives: 170.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.1583 - categorical_accuracy: 0.1772 - f1_score: 0.1618 - false_negatives: 25096.2109 - false_positives: 184.0707 - loss: 2.8784 - true_negatives: 741750.7500 - true_positives: 487.7491 - val_auc: 0.3116 - val_categorical_accuracy: 0.3007 - val_f1_score: 0.3014 - val_false_negatives: 6233.0000 - val_false_positives: 156.0000 - val_loss: 2.3563 - val_true_negatives: 196986.0000 - val_true_positives: 565.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.3388 - categorical_accuracy: 0.3325 - f1_score: 0.3243 - false_negatives: 22482.6816 - false_positives: 1058.5682 - loss: 2.2891 - true_negatives: 740876.2500 - true_positives: 3101.2778 - val_auc: 0.4272 - val_categorical_accuracy: 0.3957 - val_f1_score: 0.3931 - val_false_negatives: 5288.0000 - val_false_positives: 650.0000 - val_loss: 2.0345 - val_true_negatives: 196492.0000 - val_true_positives: 1510.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 25ms/step - auc: 0.4408 - categorical_accuracy: 0.4114 - f1_score: 0.4060 - false_negatives: 20197.2090 - false_positives: 1759.4818 - loss: 2.0033 - true_negatives: 740175.3750 - true_positives: 5386.7510 - val_auc: 0.4759 - val_categorical_accuracy: 0.4394 - val_f1_score: 0.4443 - val_false_negatives: 5220.0000 - val_false_positives: 521.0000 - val_loss: 1.8827 - val_true_negatives: 196621.0000 - val_true_positives: 1578.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.5022 - categorical_accuracy: 0.4596 - f1_score: 0.4557 - false_negatives: 18601.0684 - false_positives: 2221.9907 - loss: 1.8215 - true_negatives: 739712.8750 - true_positives: 6982.8911 - val_auc: 0.5159 - val_categorical_accuracy: 0.4707 - val_f1_score: 0.4683 - val_false_negatives: 4819.0000 - val_false_positives: 675.0000 - val_loss: 1.7873 - val_true_negatives: 196467.0000 - val_true_positives: 1979.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.5510 - categorical_accuracy: 0.5012 - f1_score: 0.4982 - false_negatives: 17361.1719 - false_positives: 2473.9675 - loss: 1.6897 - true_negatives: 739460.8750 - true_positives: 8222.7881 - val_auc: 0.5554 - val_categorical_accuracy: 0.4990 - val_f1_score: 0.4963 - val_false_negatives: 4451.0000 - val_false_positives: 801.0000 - val_loss: 1.6848 - val_true_negatives: 196341.0000 - val_true_positives: 2347.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.5915 - categorical_accuracy: 0.5347 - f1_score: 0.5322 - false_negatives: 16264.6689 - false_positives: 2675.9507 - loss: 1.5658 - true_negatives: 739258.8750 - true_positives: 9319.2910 - val_auc: 0.5354 - val_categorical_accuracy: 0.4859 - val_f1_score: 0.4830 - val_false_negatives: 4474.0000 - val_false_positives: 912.0000 - val_loss: 1.7115 - val_true_negatives: 196230.0000 - val_true_positives: 2324.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.6403 - categorical_accuracy: 0.5750 - f1_score: 0.5734 - false_negatives: 14894.1719 - false_positives: 2770.7302 - loss: 1.4320 - true_negatives: 739164.1250 - true_positives: 10689.7881 - val_auc: 0.6115 - val_categorical_accuracy: 0.5472 - val_f1_score: 0.5444 - val_false_negatives: 3950.0000 - val_false_positives: 1024.0000 - val_loss: 1.5133 - val_true_negatives: 196118.0000 - val_true_positives: 2848.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.6829 - categorical_accuracy: 0.6086 - f1_score: 0.6075 - false_negatives: 13649.4561 - false_positives: 2761.7854 - loss: 1.3062 - true_negatives: 739173.0625 - true_positives: 11934.5039 - val_auc: 0.6561 - val_categorical_accuracy: 0.5828 - val_f1_score: 0.5815 - val_false_negatives: 3649.0000 - val_false_positives: 924.0000 - val_loss: 1.4024 - val_true_negatives: 196218.0000 - val_true_positives: 3149.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.7277 - categorical_accuracy: 0.6475 - f1_score: 0.6466 - false_negatives: 12272.7480 - false_positives: 2811.2354 - loss: 1.1713 - true_negatives: 739123.6250 - true_positives: 13311.2119 - val_auc: 0.6636 - val_categorical_accuracy: 0.5862 - val_f1_score: 0.5839 - val_false_negatives: 3521.0000 - val_false_positives: 1043.0000 - val_loss: 1.3803 - val_true_negatives: 196099.0000 - val_true_positives: 3277.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.7699 - categorical_accuracy: 0.6848 - f1_score: 0.6841 - false_negatives: 10914.5078 - false_positives: 2773.3843 - loss: 1.0469 - true_negatives: 739161.4375 - true_positives: 14669.4521 - val_auc: 0.6670 - val_categorical_accuracy: 0.5941 - val_f1_score: 0.5972 - val_false_negatives: 3368.0000 - val_false_positives: 1126.0000 - val_loss: 1.3936 - val_true_negatives: 196016.0000 - val_true_positives: 3430.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 25ms/step - auc: 0.8076 - categorical_accuracy: 0.7169 - f1_score: 0.7164 - false_negatives: 9742.8320 - false_positives: 2717.3374 - loss: 0.9288 - true_negatives: 739217.5000 - true_positives: 15841.1279 - val_auc: 0.7212 - val_categorical_accuracy: 0.6418 - val_f1_score: 0.6440 - val_false_negatives: 2968.0000 - val_false_positives: 1100.0000 - val_loss: 1.2231 - val_true_negatives: 196042.0000 - val_true_positives: 3830.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - auc: 0.8385 - categorical_accuracy: 0.7475 - f1_score: 0.7470 - false_negatives: 8555.5088 - false_positives: 2546.9031 - loss: 0.8285 - true_negatives: 739387.9375 - true_positives: 17028.4512 - val_auc: 0.7294 - val_categorical_accuracy: 0.6467 - val_f1_score: 0.6489 - val_false_negatives: 2849.0000 - val_false_positives: 1198.0000 - val_loss: 1.2193 - val_true_negatives: 195944.0000 - val_true_positives: 3949.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.8651 - categorical_accuracy: 0.7754 - f1_score: 0.7749 - false_negatives: 7606.6890 - false_positives: 2465.9768 - loss: 0.7373 - true_negatives: 739468.8750 - true_positives: 17977.2715 - val_auc: 0.7631 - val_categorical_accuracy: 0.6759 - val_f1_score: 0.6775 - val_false_negatives: 2582.0000 - val_false_positives: 1128.0000 - val_loss: 1.1119 - val_true_negatives: 196014.0000 - val_true_positives: 4216.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - auc: 0.8905 - categorical_accuracy: 0.8028 - f1_score: 0.8025 - false_negatives: 6562.5630 - false_positives: 2242.1489 - loss: 0.6453 - true_negatives: 739692.6875 - true_positives: 19021.3965 - val_auc: 0.7634 - val_categorical_accuracy: 0.6789 - val_f1_score: 0.6767 - val_false_negatives: 2509.0000 - val_false_positives: 1257.0000 - val_loss: 1.1300 - val_true_negatives: 195885.0000 - val_true_positives: 4289.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.9118 - categorical_accuracy: 0.8274 - f1_score: 0.8271 - false_negatives: 5738.7817 - false_positives: 2079.7014 - loss: 0.5620 - true_negatives: 739855.1250 - true_positives: 19845.1777 - val_auc: 0.7850 - val_categorical_accuracy: 0.7004 - val_f1_score: 0.7016 - val_false_negatives: 2355.0000 - val_false_positives: 1157.0000 - val_loss: 1.0472 - val_true_negatives: 195985.0000 - val_true_positives: 4443.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.9291 - categorical_accuracy: 0.8485 - f1_score: 0.8483 - false_negatives: 4979.3208 - false_positives: 1887.6215 - loss: 0.4899 - true_negatives: 740047.1875 - true_positives: 20604.6387 - val_auc: 0.7650 - val_categorical_accuracy: 0.6868 - val_f1_score: 0.6899 - val_false_negatives: 2345.0000 - val_false_positives: 1422.0000 - val_loss: 1.2096 - val_true_negatives: 195720.0000 - val_true_positives: 4453.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - auc: 0.9436 - categorical_accuracy: 0.8700 - f1_score: 0.8698 - false_negatives: 4257.4780 - false_positives: 1730.7604 - loss: 0.4239 - true_negatives: 740204.0625 - true_positives: 21326.4824 - val_auc: 0.7790 - val_categorical_accuracy: 0.7043 - val_f1_score: 0.7052 - val_false_negatives: 2231.0000 - val_false_positives: 1385.0000 - val_loss: 1.1616 - val_true_negatives: 195757.0000 - val_true_positives: 4567.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - auc: 0.9557 - categorical_accuracy: 0.8849 - f1_score: 0.8849 - false_negatives: 3677.9231 - false_positives: 1542.1421 - loss: 0.3656 - true_negatives: 740392.6875 - true_positives: 21906.0371 - val_auc: 0.7801 - val_categorical_accuracy: 0.7070 - val_f1_score: 0.7069 - val_false_negatives: 2147.0000 - val_false_positives: 1444.0000 - val_loss: 1.2093 - val_true_negatives: 195698.0000 - val_true_positives: 4651.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.9652 - categorical_accuracy: 0.9014 - f1_score: 0.9013 - false_negatives: 3160.7842 - false_positives: 1370.8110 - loss: 0.3152 - true_negatives: 740564.0000 - true_positives: 22423.1758 - val_auc: 0.7672 - val_categorical_accuracy: 0.7034 - val_f1_score: 0.7073 - val_false_negatives: 2168.0000 - val_false_positives: 1533.0000 - val_loss: 1.3043 - val_true_negatives: 195609.0000 - val_true_positives: 4630.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9738 - categorical_accuracy: 0.9168 - f1_score: 0.9167 - false_negatives: 2694.2246 - false_positives: 1189.0282 - loss: 0.2660 - true_negatives: 740745.8125 - true_positives: 22889.7344 - val_auc: 0.7784 - val_categorical_accuracy: 0.7157 - val_f1_score: 0.7166 - val_false_negatives: 2048.0000 - val_false_positives: 1519.0000 - val_loss: 1.2816 - val_true_negatives: 195623.0000 - val_true_positives: 4750.0000\n",
      "Epoch 22/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9784 - categorical_accuracy: 0.9230 - f1_score: 0.9229 - false_negatives: 2398.0820 - false_positives: 1147.2434 - loss: 0.2365 - true_negatives: 740787.6250 - true_positives: 23185.8789 - val_auc: 0.7796 - val_categorical_accuracy: 0.7209 - val_f1_score: 0.7208 - val_false_negatives: 1993.0000 - val_false_positives: 1528.0000 - val_loss: 1.3509 - val_true_negatives: 195614.0000 - val_true_positives: 4805.0000\n",
      "Epoch 23/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9839 - categorical_accuracy: 0.9366 - f1_score: 0.9365 - false_negatives: 1973.6539 - false_positives: 958.4794 - loss: 0.1998 - true_negatives: 740976.3750 - true_positives: 23610.3066 - val_auc: 0.7443 - val_categorical_accuracy: 0.6962 - val_f1_score: 0.6999 - val_false_negatives: 2154.0000 - val_false_positives: 1725.0000 - val_loss: 1.6040 - val_true_negatives: 195417.0000 - val_true_positives: 4644.0000\n",
      "Epoch 24/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.9875 - categorical_accuracy: 0.9440 - f1_score: 0.9440 - false_negatives: 1711.3429 - false_positives: 873.6070 - loss: 0.1716 - true_negatives: 741061.2500 - true_positives: 23872.6172 - val_auc: 0.7516 - val_categorical_accuracy: 0.7070 - val_f1_score: 0.7067 - val_false_negatives: 2057.0000 - val_false_positives: 1668.0000 - val_loss: 1.5503 - val_true_negatives: 195474.0000 - val_true_positives: 4741.0000\n",
      "Epoch 25/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.9890 - categorical_accuracy: 0.9490 - f1_score: 0.9490 - false_negatives: 1548.0426 - false_positives: 799.6470 - loss: 0.1577 - true_negatives: 741135.1875 - true_positives: 24035.9180 - val_auc: 0.7297 - val_categorical_accuracy: 0.6956 - val_f1_score: 0.6975 - val_false_negatives: 2138.0000 - val_false_positives: 1779.0000 - val_loss: 1.7236 - val_true_negatives: 195363.0000 - val_true_positives: 4660.0000\n",
      "Epoch 26/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 23ms/step - auc: 0.9914 - categorical_accuracy: 0.9584 - f1_score: 0.9584 - false_negatives: 1326.4224 - false_positives: 682.2215 - loss: 0.1366 - true_negatives: 741252.6250 - true_positives: 24257.5371 - val_auc: 0.7621 - val_categorical_accuracy: 0.7180 - val_f1_score: 0.7195 - val_false_negatives: 1974.0000 - val_false_positives: 1634.0000 - val_loss: 1.6024 - val_true_negatives: 195508.0000 - val_true_positives: 4824.0000\n"
     ]
    }
   ],
   "source": [
    "def simple_cnn(input_shape = (256, 256), batch_size = 32) -> keras.Model:\n",
    "    inputs = keras.layers.Input(shape=input_shape, batch_size=batch_size)\n",
    "\n",
    "    # Preprocessing\n",
    "    x = keras.layers.Reshape((*input_shape, 1))(inputs)\n",
    "    x = keras.layers.Rescaling(scale=1.0/255, offset=0.0)(x)\n",
    "\n",
    "    # Convolution layers\n",
    "    x = keras.layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(3, 3))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(64, kernel_size=(2, 2), activation=\"relu\")(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128, kernel_size=(2, 2), activation=\"relu\")(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = keras.layers.AvgPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Dense layer\n",
    "    x = keras.layers.Flatten(\"channels_last\")(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    outputs = keras.layers.Dense(30, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs, name=\"SimpleCNN\")\n",
    "\n",
    "\n",
    "\n",
    "simple_cnn().summary()\n",
    "log_dir = os.path.join(LOG_DIR, \"kaggle-speech-recognition\", \"SimpleCNN\")\n",
    "\n",
    "learning_rates = np.logspace(-3, -2, 3)\n",
    "models = []\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True, start_from_epoch=10)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = simple_cnn()\n",
    "\n",
    "    optimizer = SGD(learning_rate=lr)\n",
    "    loss = CategoricalCrossentropy()\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    model_log_dir = os.path.join(log_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S_lr-{lr}\"))\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1)\n",
    "    history = model.fit(x=ds_train, validation_data=ds_valid, batch_size=batch_size, epochs=50,\n",
    "                callbacks=[tensorboard_cb, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 25ms/step - auc: 0.2908 - categorical_accuracy: 0.2623 - f1_score: 0.2738 - false_negatives: 27460.2305 - false_positives: 1689.2784 - loss: 3.2854 - true_negatives: 937387.5625 - true_positives: 4921.7290 - val_auc: 0.2594 - val_categorical_accuracy: 0.2661 - val_f1_score: 0.2478 - val_false_negatives: 6403.0000 - val_false_positives: 161.0000 - val_loss: 2.4677 - val_true_negatives: 196981.0000 - val_true_positives: 395.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - auc: 0.3136 - categorical_accuracy: 0.3109 - f1_score: 0.3025 - false_negatives: 22547.4180 - false_positives: 1286.6221 - loss: 2.3401 - true_negatives: 740648.1875 - true_positives: 3036.5413 - val_auc: 0.4323 - val_categorical_accuracy: 0.4053 - val_f1_score: 0.4009 - val_false_negatives: 5246.0000 - val_false_positives: 673.0000 - val_loss: 1.9897 - val_true_negatives: 196469.0000 - val_true_positives: 1552.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - auc: 0.5027 - categorical_accuracy: 0.4639 - f1_score: 0.4601 - false_negatives: 18385.7344 - false_positives: 2352.4180 - loss: 1.7978 - true_negatives: 739582.4375 - true_positives: 7198.2266 - val_auc: 0.5847 - val_categorical_accuracy: 0.5291 - val_f1_score: 0.5293 - val_false_negatives: 4086.0000 - val_false_positives: 1026.0000 - val_loss: 1.5517 - val_true_negatives: 196116.0000 - val_true_positives: 2712.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 22ms/step - auc: 0.6651 - categorical_accuracy: 0.5910 - f1_score: 0.5894 - false_negatives: 13810.4922 - false_positives: 2985.3992 - loss: 1.3356 - true_negatives: 738949.4375 - true_positives: 11773.4678 - val_auc: 0.7116 - val_categorical_accuracy: 0.6297 - val_f1_score: 0.6286 - val_false_negatives: 3108.0000 - val_false_positives: 1070.0000 - val_loss: 1.2225 - val_true_negatives: 196072.0000 - val_true_positives: 3690.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.7738 - categorical_accuracy: 0.6881 - f1_score: 0.6873 - false_negatives: 10435.3057 - false_positives: 2959.1946 - loss: 1.0261 - true_negatives: 738975.6250 - true_positives: 15148.6543 - val_auc: 0.7393 - val_categorical_accuracy: 0.6580 - val_f1_score: 0.6612 - val_false_negatives: 2835.0000 - val_false_positives: 1127.0000 - val_loss: 1.1338 - val_true_negatives: 196015.0000 - val_true_positives: 3963.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.8445 - categorical_accuracy: 0.7556 - f1_score: 0.7550 - false_negatives: 8127.1450 - false_positives: 2725.1685 - loss: 0.7991 - true_negatives: 739209.6875 - true_positives: 17456.8145 - val_auc: 0.7843 - val_categorical_accuracy: 0.7001 - val_f1_score: 0.6998 - val_false_negatives: 2448.0000 - val_false_positives: 1080.0000 - val_loss: 1.0069 - val_true_negatives: 196062.0000 - val_true_positives: 4350.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.8947 - categorical_accuracy: 0.8073 - f1_score: 0.8071 - false_negatives: 6258.1953 - false_positives: 2393.5752 - loss: 0.6211 - true_negatives: 739541.2500 - true_positives: 19325.7656 - val_auc: 0.7763 - val_categorical_accuracy: 0.6934 - val_f1_score: 0.6977 - val_false_negatives: 2335.0000 - val_false_positives: 1237.0000 - val_loss: 1.0795 - val_true_negatives: 195905.0000 - val_true_positives: 4463.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9270 - categorical_accuracy: 0.8449 - f1_score: 0.8448 - false_negatives: 4884.5405 - false_positives: 2076.2090 - loss: 0.4909 - true_negatives: 739858.6250 - true_positives: 20699.4199 - val_auc: 0.7828 - val_categorical_accuracy: 0.7107 - val_f1_score: 0.7141 - val_false_negatives: 2153.0000 - val_false_positives: 1400.0000 - val_loss: 1.1180 - val_true_negatives: 195742.0000 - val_true_positives: 4645.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9517 - categorical_accuracy: 0.8793 - f1_score: 0.8792 - false_negatives: 3826.4976 - false_positives: 1684.4706 - loss: 0.3812 - true_negatives: 740250.3750 - true_positives: 21757.4629 - val_auc: 0.8250 - val_categorical_accuracy: 0.7470 - val_f1_score: 0.7485 - val_false_negatives: 1882.0000 - val_false_positives: 1197.0000 - val_loss: 0.9727 - val_true_negatives: 195945.0000 - val_true_positives: 4916.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - auc: 0.9676 - categorical_accuracy: 0.9065 - f1_score: 0.9065 - false_negatives: 2930.3474 - false_positives: 1405.6107 - loss: 0.2957 - true_negatives: 740529.2500 - true_positives: 22653.6133 - val_auc: 0.8297 - val_categorical_accuracy: 0.7523 - val_f1_score: 0.7542 - val_false_negatives: 1788.0000 - val_false_positives: 1264.0000 - val_loss: 0.9976 - val_true_negatives: 195878.0000 - val_true_positives: 5010.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9764 - categorical_accuracy: 0.9228 - f1_score: 0.9228 - false_negatives: 2363.8887 - false_positives: 1202.8417 - loss: 0.2408 - true_negatives: 740732.0000 - true_positives: 23220.0723 - val_auc: 0.8333 - val_categorical_accuracy: 0.7708 - val_f1_score: 0.7721 - val_false_negatives: 1651.0000 - val_false_positives: 1202.0000 - val_loss: 1.0402 - val_true_negatives: 195940.0000 - val_true_positives: 5147.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9841 - categorical_accuracy: 0.9384 - f1_score: 0.9384 - false_negatives: 1914.8066 - false_positives: 1036.5388 - loss: 0.1901 - true_negatives: 740898.3125 - true_positives: 23669.1523 - val_auc: 0.8274 - val_categorical_accuracy: 0.7729 - val_f1_score: 0.7738 - val_false_negatives: 1623.0000 - val_false_positives: 1263.0000 - val_loss: 1.1313 - val_true_negatives: 195879.0000 - val_true_positives: 5175.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9873 - categorical_accuracy: 0.9461 - f1_score: 0.9461 - false_negatives: 1643.1139 - false_positives: 928.8836 - loss: 0.1647 - true_negatives: 741005.9375 - true_positives: 23940.8457 - val_auc: 0.8040 - val_categorical_accuracy: 0.7588 - val_f1_score: 0.7614 - val_false_negatives: 1731.0000 - val_false_positives: 1379.0000 - val_loss: 1.2797 - val_true_negatives: 195763.0000 - val_true_positives: 5067.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9902 - categorical_accuracy: 0.9550 - f1_score: 0.9550 - false_negatives: 1321.6959 - false_positives: 804.4211 - loss: 0.1382 - true_negatives: 741130.4375 - true_positives: 24262.2637 - val_auc: 0.8192 - val_categorical_accuracy: 0.7704 - val_f1_score: 0.7713 - val_false_negatives: 1610.0000 - val_false_positives: 1324.0000 - val_loss: 1.2233 - val_true_negatives: 195818.0000 - val_true_positives: 5188.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9930 - categorical_accuracy: 0.9627 - f1_score: 0.9627 - false_negatives: 1129.4468 - false_positives: 687.9199 - loss: 0.1140 - true_negatives: 741246.9375 - true_positives: 24454.5137 - val_auc: 0.8252 - val_categorical_accuracy: 0.7817 - val_f1_score: 0.7823 - val_false_negatives: 1541.0000 - val_false_positives: 1231.0000 - val_loss: 1.1679 - val_true_negatives: 195911.0000 - val_true_positives: 5257.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9934 - categorical_accuracy: 0.9677 - f1_score: 0.9677 - false_negatives: 959.5063 - false_positives: 605.5701 - loss: 0.1013 - true_negatives: 741329.2500 - true_positives: 24624.4531 - val_auc: 0.8240 - val_categorical_accuracy: 0.7817 - val_f1_score: 0.7832 - val_false_negatives: 1535.0000 - val_false_positives: 1269.0000 - val_loss: 1.2492 - val_true_negatives: 195873.0000 - val_true_positives: 5263.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.9956 - categorical_accuracy: 0.9749 - f1_score: 0.9749 - false_negatives: 757.1026 - false_positives: 497.8304 - loss: 0.0792 - true_negatives: 741437.0000 - true_positives: 24826.8574 - val_auc: 0.8167 - val_categorical_accuracy: 0.7811 - val_f1_score: 0.7822 - val_false_negatives: 1527.0000 - val_false_positives: 1316.0000 - val_loss: 1.3158 - val_true_negatives: 195826.0000 - val_true_positives: 5271.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.9957 - categorical_accuracy: 0.9767 - f1_score: 0.9766 - false_negatives: 700.4199 - false_positives: 474.1101 - loss: 0.0748 - true_negatives: 741460.7500 - true_positives: 24883.5410 - val_auc: 0.8098 - val_categorical_accuracy: 0.7792 - val_f1_score: 0.7801 - val_false_negatives: 1527.0000 - val_false_positives: 1347.0000 - val_loss: 1.4110 - val_true_negatives: 195795.0000 - val_true_positives: 5271.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.9959 - categorical_accuracy: 0.9764 - f1_score: 0.9764 - false_negatives: 654.3742 - false_positives: 466.2622 - loss: 0.0717 - true_negatives: 741468.5625 - true_positives: 24929.5859 - val_auc: 0.8113 - val_categorical_accuracy: 0.7757 - val_f1_score: 0.7773 - val_false_negatives: 1554.0000 - val_false_positives: 1343.0000 - val_loss: 1.3688 - val_true_negatives: 195799.0000 - val_true_positives: 5244.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.9974 - categorical_accuracy: 0.9830 - f1_score: 0.9830 - false_negatives: 518.9631 - false_positives: 376.3667 - loss: 0.0534 - true_negatives: 741558.5000 - true_positives: 25064.9961 - val_auc: 0.7558 - val_categorical_accuracy: 0.7333 - val_f1_score: 0.7393 - val_false_negatives: 1858.0000 - val_false_positives: 1632.0000 - val_loss: 1.6670 - val_true_negatives: 195510.0000 - val_true_positives: 4940.0000\n",
      "Epoch 21/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.9958 - categorical_accuracy: 0.9795 - f1_score: 0.9795 - false_negatives: 549.8611 - false_positives: 417.8461 - loss: 0.0648 - true_negatives: 741517.0000 - true_positives: 25034.0996 - val_auc: 0.8195 - val_categorical_accuracy: 0.7868 - val_f1_score: 0.7872 - val_false_negatives: 1486.0000 - val_false_positives: 1302.0000 - val_loss: 1.3443 - val_true_negatives: 195840.0000 - val_true_positives: 5312.0000\n",
      "Epoch 1/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 26ms/step - auc: 0.3371 - categorical_accuracy: 0.3020 - f1_score: 0.3098 - false_negatives: 26692.4434 - false_positives: 1570.8435 - loss: 3.1648 - true_negatives: 937506.0000 - true_positives: 5689.5161 - val_auc: 0.3598 - val_categorical_accuracy: 0.3522 - val_f1_score: 0.3439 - val_false_negatives: 5683.0000 - val_false_positives: 659.0000 - val_loss: 2.1353 - val_true_negatives: 196483.0000 - val_true_positives: 1115.0000\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.4854 - categorical_accuracy: 0.4558 - f1_score: 0.4508 - false_negatives: 18032.3320 - false_positives: 2685.6240 - loss: 1.8057 - true_negatives: 739249.1875 - true_positives: 7551.6274 - val_auc: 0.7155 - val_categorical_accuracy: 0.6403 - val_f1_score: 0.6453 - val_false_negatives: 2983.0000 - val_false_positives: 1183.0000 - val_loss: 1.1918 - val_true_negatives: 195959.0000 - val_true_positives: 3815.0000\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.7811 - categorical_accuracy: 0.6968 - f1_score: 0.6962 - false_negatives: 9870.9033 - false_positives: 3108.9780 - loss: 0.9920 - true_negatives: 738825.8750 - true_positives: 15713.0566 - val_auc: 0.8189 - val_categorical_accuracy: 0.7339 - val_f1_score: 0.7338 - val_false_negatives: 2175.0000 - val_false_positives: 975.0000 - val_loss: 0.8997 - val_true_negatives: 196167.0000 - val_true_positives: 4623.0000\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.8865 - categorical_accuracy: 0.8006 - f1_score: 0.8003 - false_negatives: 6276.9316 - false_positives: 2543.3054 - loss: 0.6483 - true_negatives: 739391.5625 - true_positives: 19307.0273 - val_auc: 0.7980 - val_categorical_accuracy: 0.7157 - val_f1_score: 0.7175 - val_false_negatives: 2147.0000 - val_false_positives: 1307.0000 - val_loss: 1.0344 - val_true_negatives: 195835.0000 - val_true_positives: 4651.0000\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9357 - categorical_accuracy: 0.8597 - f1_score: 0.8597 - false_negatives: 4323.6665 - false_positives: 1992.6171 - loss: 0.4517 - true_negatives: 739942.2500 - true_positives: 21260.2930 - val_auc: 0.8584 - val_categorical_accuracy: 0.7766 - val_f1_score: 0.7765 - val_false_negatives: 1718.0000 - val_false_positives: 1034.0000 - val_loss: 0.7963 - val_true_negatives: 196108.0000 - val_true_positives: 5080.0000\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9615 - categorical_accuracy: 0.8962 - f1_score: 0.8961 - false_negatives: 3122.3523 - false_positives: 1587.1289 - loss: 0.3265 - true_negatives: 740347.6875 - true_positives: 22461.6074 - val_auc: 0.8275 - val_categorical_accuracy: 0.7570 - val_f1_score: 0.7597 - val_false_negatives: 1807.0000 - val_false_positives: 1203.0000 - val_loss: 0.9612 - val_true_negatives: 195939.0000 - val_true_positives: 4991.0000\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 23ms/step - auc: 0.9745 - categorical_accuracy: 0.9197 - f1_score: 0.9197 - false_negatives: 2419.7214 - false_positives: 1318.7966 - loss: 0.2476 - true_negatives: 740616.0625 - true_positives: 23164.2383 - val_auc: 0.8405 - val_categorical_accuracy: 0.7751 - val_f1_score: 0.7763 - val_false_negatives: 1636.0000 - val_false_positives: 1224.0000 - val_loss: 0.9944 - val_true_negatives: 195918.0000 - val_true_positives: 5162.0000\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9847 - categorical_accuracy: 0.9412 - f1_score: 0.9412 - false_negatives: 1818.1934 - false_positives: 1050.1395 - loss: 0.1829 - true_negatives: 740884.6875 - true_positives: 23765.7656 - val_auc: 0.8463 - val_categorical_accuracy: 0.7813 - val_f1_score: 0.7820 - val_false_negatives: 1551.0000 - val_false_positives: 1194.0000 - val_loss: 0.9868 - val_true_negatives: 195948.0000 - val_true_positives: 5247.0000\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 24ms/step - auc: 0.9871 - categorical_accuracy: 0.9492 - f1_score: 0.9492 - false_negatives: 1547.9055 - false_positives: 949.0720 - loss: 0.1572 - true_negatives: 740985.7500 - true_positives: 24036.0547 - val_auc: 0.7273 - val_categorical_accuracy: 0.6675 - val_f1_score: 0.6701 - val_false_negatives: 2412.0000 - val_false_positives: 1746.0000 - val_loss: 1.4906 - val_true_negatives: 195396.0000 - val_true_positives: 4386.0000\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9888 - categorical_accuracy: 0.9559 - f1_score: 0.9559 - false_negatives: 1231.5763 - false_positives: 792.5889 - loss: 0.1399 - true_negatives: 741142.2500 - true_positives: 24352.3828 - val_auc: 0.8432 - val_categorical_accuracy: 0.7821 - val_f1_score: 0.7825 - val_false_negatives: 1579.0000 - val_false_positives: 1201.0000 - val_loss: 0.9846 - val_true_negatives: 195941.0000 - val_true_positives: 5219.0000\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9922 - categorical_accuracy: 0.9662 - f1_score: 0.9662 - false_negatives: 990.6402 - false_positives: 672.8580 - loss: 0.1082 - true_negatives: 741262.0000 - true_positives: 24593.3203 - val_auc: 0.8335 - val_categorical_accuracy: 0.7921 - val_f1_score: 0.7925 - val_false_negatives: 1461.0000 - val_false_positives: 1240.0000 - val_loss: 1.1503 - val_true_negatives: 195902.0000 - val_true_positives: 5337.0000\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9937 - categorical_accuracy: 0.9717 - f1_score: 0.9717 - false_negatives: 824.4481 - false_positives: 587.5507 - loss: 0.0905 - true_negatives: 741347.3125 - true_positives: 24759.5117 - val_auc: 0.8391 - val_categorical_accuracy: 0.7955 - val_f1_score: 0.7969 - val_false_negatives: 1434.0000 - val_false_positives: 1217.0000 - val_loss: 1.0850 - val_true_negatives: 195925.0000 - val_true_positives: 5364.0000\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9957 - categorical_accuracy: 0.9767 - f1_score: 0.9767 - false_negatives: 677.5519 - false_positives: 522.6108 - loss: 0.0714 - true_negatives: 741412.2500 - true_positives: 24906.4082 - val_auc: 0.8227 - val_categorical_accuracy: 0.7944 - val_f1_score: 0.7952 - val_false_negatives: 1435.0000 - val_false_positives: 1264.0000 - val_loss: 1.3005 - val_true_negatives: 195878.0000 - val_true_positives: 5363.0000\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9941 - categorical_accuracy: 0.9738 - f1_score: 0.9739 - false_negatives: 708.5194 - false_positives: 569.9925 - loss: 0.0827 - true_negatives: 741364.8750 - true_positives: 24875.4414 - val_auc: 0.8366 - val_categorical_accuracy: 0.8023 - val_f1_score: 0.8026 - val_false_negatives: 1375.0000 - val_false_positives: 1209.0000 - val_loss: 1.2123 - val_true_negatives: 195933.0000 - val_true_positives: 5423.0000\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9950 - categorical_accuracy: 0.9798 - f1_score: 0.9798 - false_negatives: 551.5820 - false_positives: 462.8999 - loss: 0.0664 - true_negatives: 741471.9375 - true_positives: 25032.3789 - val_auc: 0.8414 - val_categorical_accuracy: 0.8080 - val_f1_score: 0.8094 - val_false_negatives: 1344.0000 - val_false_positives: 1170.0000 - val_loss: 1.1867 - val_true_negatives: 195972.0000 - val_true_positives: 5454.0000\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9963 - categorical_accuracy: 0.9825 - f1_score: 0.9825 - false_negatives: 501.4249 - false_positives: 420.6433 - loss: 0.0554 - true_negatives: 741514.1875 - true_positives: 25082.5352 - val_auc: 0.8050 - val_categorical_accuracy: 0.7770 - val_f1_score: 0.7801 - val_false_negatives: 1555.0000 - val_false_positives: 1355.0000 - val_loss: 1.4005 - val_true_negatives: 195787.0000 - val_true_positives: 5243.0000\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9960 - categorical_accuracy: 0.9808 - f1_score: 0.9808 - false_negatives: 498.7453 - false_positives: 426.7146 - loss: 0.0619 - true_negatives: 741508.1250 - true_positives: 25085.2148 - val_auc: 0.8147 - val_categorical_accuracy: 0.7961 - val_f1_score: 0.7959 - val_false_negatives: 1402.0000 - val_false_positives: 1291.0000 - val_loss: 1.4394 - val_true_negatives: 195851.0000 - val_true_positives: 5396.0000\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9978 - categorical_accuracy: 0.9875 - f1_score: 0.9875 - false_negatives: 342.0044 - false_positives: 294.0119 - loss: 0.0405 - true_negatives: 741640.8125 - true_positives: 25241.9551 - val_auc: 0.8348 - val_categorical_accuracy: 0.8076 - val_f1_score: 0.8081 - val_false_negatives: 1335.0000 - val_false_positives: 1185.0000 - val_loss: 1.2460 - val_true_negatives: 195957.0000 - val_true_positives: 5463.0000\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 24ms/step - auc: 0.9971 - categorical_accuracy: 0.9859 - f1_score: 0.9859 - false_negatives: 367.8554 - false_positives: 328.8830 - loss: 0.0447 - true_negatives: 741605.9375 - true_positives: 25216.1055 - val_auc: 0.8341 - val_categorical_accuracy: 0.8055 - val_f1_score: 0.8064 - val_false_negatives: 1355.0000 - val_false_positives: 1196.0000 - val_loss: 1.2670 - val_true_negatives: 195946.0000 - val_true_positives: 5443.0000\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 23ms/step - auc: 0.9986 - categorical_accuracy: 0.9908 - f1_score: 0.9908 - false_negatives: 259.6827 - false_positives: 229.1289 - loss: 0.0296 - true_negatives: 741705.6875 - true_positives: 25324.2773 - val_auc: 0.8312 - val_categorical_accuracy: 0.8091 - val_f1_score: 0.8096 - val_false_negatives: 1329.0000 - val_false_positives: 1175.0000 - val_loss: 1.2974 - val_true_negatives: 195967.0000 - val_true_positives: 5469.0000\n"
     ]
    }
   ],
   "source": [
    "learning_rates = np.logspace(-1.5, -1, 2)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = simple_cnn()\n",
    "\n",
    "    optimizer = SGD(learning_rate=lr)\n",
    "    loss = CategoricalCrossentropy()\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    model_log_dir = os.path.join(log_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S_lr-{lr}\"))\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1)\n",
    "    history = model.fit(x=ds_train, validation_data=ds_valid, batch_size=batch_size, epochs=50,\n",
    "                callbacks=[tensorboard_cb, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above we can tell that higher learning rate is desirable for first few epochs but quickly becomes too big.\n",
    "From now on we will train models with higher initial learning rate and apply exponential decay to it.\n",
    "\n",
    "### Normalized input\n",
    "Data is not normalized now, let's see how normalization will improve accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"NormalizedCNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"NormalizedCNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_11            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,107,456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,710</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_11 (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_11 (\u001b[38;5;33mReshape\u001b[0m)            │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_33 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_22 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m84\u001b[0m, \u001b[38;5;34m84\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_34 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_23 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_35 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_11            │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_11 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m51200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │    \u001b[38;5;34m13,107,456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m)               │         \u001b[38;5;34m7,710\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,218,174</span> (50.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,218,174\u001b[0m (50.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,218,174</span> (50.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,218,174\u001b[0m (50.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-24 18:34:01.903879: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732469642.171638   49245 service.cc:148] XLA service 0x7f40ac0196d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732469642.171730   49245 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-11-24 18:34:02.219106: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1732469642.297611   49245 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   4/1597\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - categorical_accuracy: 0.0247 - loss: 3.4048  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732469648.667617   49245 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 23ms/step - categorical_accuracy: 0.0952 - loss: 3.2128 - val_categorical_accuracy: 0.2804 - val_loss: 2.4511\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 17ms/step - categorical_accuracy: 0.3667 - loss: 2.1646 - val_categorical_accuracy: 0.4550 - val_loss: 1.8390\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - categorical_accuracy: 0.5169 - loss: 1.6302 - val_categorical_accuracy: 0.5166 - val_loss: 1.6195\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.6055 - loss: 1.3244 - val_categorical_accuracy: 0.5987 - val_loss: 1.3661\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - categorical_accuracy: 0.6729 - loss: 1.1004 - val_categorical_accuracy: 0.5947 - val_loss: 1.4060\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - categorical_accuracy: 0.7242 - loss: 0.9221 - val_categorical_accuracy: 0.6395 - val_loss: 1.2222\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 0.7727 - loss: 0.7581 - val_categorical_accuracy: 0.6650 - val_loss: 1.1926\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - categorical_accuracy: 0.8152 - loss: 0.6080 - val_categorical_accuracy: 0.6887 - val_loss: 1.1445\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - categorical_accuracy: 0.8549 - loss: 0.4783 - val_categorical_accuracy: 0.6743 - val_loss: 1.3023\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - categorical_accuracy: 0.8882 - loss: 0.3605 - val_categorical_accuracy: 0.6892 - val_loss: 1.3080\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - categorical_accuracy: 0.9162 - loss: 0.2729 - val_categorical_accuracy: 0.6949 - val_loss: 1.4133\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - categorical_accuracy: 0.9368 - loss: 0.2037 - val_categorical_accuracy: 0.6645 - val_loss: 1.8374\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 20ms/step - categorical_accuracy: 0.9526 - loss: 0.1543 - val_categorical_accuracy: 0.7127 - val_loss: 1.4998\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9666 - loss: 0.1101 - val_categorical_accuracy: 0.7229 - val_loss: 1.5794\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9710 - loss: 0.0921 - val_categorical_accuracy: 0.7195 - val_loss: 1.5987\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 0.9783 - loss: 0.0727 - val_categorical_accuracy: 0.7083 - val_loss: 1.8415\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 0.9799 - loss: 0.0658 - val_categorical_accuracy: 0.7151 - val_loss: 1.7978\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 20ms/step - categorical_accuracy: 0.9841 - loss: 0.0524 - val_categorical_accuracy: 0.7321 - val_loss: 1.7596\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9891 - loss: 0.0370 - val_categorical_accuracy: 0.7115 - val_loss: 1.9372\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - categorical_accuracy: 0.9889 - loss: 0.0402 - val_categorical_accuracy: 0.7282 - val_loss: 1.8567\n",
      "Epoch 21/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 18ms/step - categorical_accuracy: 0.9903 - loss: 0.0317 - val_categorical_accuracy: 0.7229 - val_loss: 1.9634\n",
      "Epoch 1/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 23ms/step - categorical_accuracy: 0.3276 - loss: 2.9693 - val_categorical_accuracy: 0.4097 - val_loss: 1.9553\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - categorical_accuracy: 0.4923 - loss: 1.6931 - val_categorical_accuracy: 0.5914 - val_loss: 1.3388\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - categorical_accuracy: 0.6522 - loss: 1.1440 - val_categorical_accuracy: 0.6389 - val_loss: 1.2445\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - categorical_accuracy: 0.7638 - loss: 0.7719 - val_categorical_accuracy: 0.7034 - val_loss: 1.0220\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.8414 - loss: 0.5040 - val_categorical_accuracy: 0.7295 - val_loss: 1.0324\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.8974 - loss: 0.3285 - val_categorical_accuracy: 0.7176 - val_loss: 1.2090\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9322 - loss: 0.2101 - val_categorical_accuracy: 0.7411 - val_loss: 1.1654\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9530 - loss: 0.1434 - val_categorical_accuracy: 0.7056 - val_loss: 1.6932\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9674 - loss: 0.0979 - val_categorical_accuracy: 0.7538 - val_loss: 1.3829\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9771 - loss: 0.0702 - val_categorical_accuracy: 0.7721 - val_loss: 1.3022\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9856 - loss: 0.0474 - val_categorical_accuracy: 0.7688 - val_loss: 1.4531\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9905 - loss: 0.0318 - val_categorical_accuracy: 0.7614 - val_loss: 1.5189\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9896 - loss: 0.0362 - val_categorical_accuracy: 0.7585 - val_loss: 1.5869\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9940 - loss: 0.0206 - val_categorical_accuracy: 0.7714 - val_loss: 1.5311\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9936 - loss: 0.0215 - val_categorical_accuracy: 0.7780 - val_loss: 1.5963\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9961 - loss: 0.0132 - val_categorical_accuracy: 0.7742 - val_loss: 1.7187\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9969 - loss: 0.0090 - val_categorical_accuracy: 0.7760 - val_loss: 1.6934\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9982 - loss: 0.0056 - val_categorical_accuracy: 0.7814 - val_loss: 1.7415\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 0.9982 - loss: 0.0063 - val_categorical_accuracy: 0.7870 - val_loss: 1.7682\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 0.9995 - loss: 0.0021 - val_categorical_accuracy: 0.7876 - val_loss: 1.8057\n",
      "Epoch 1/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 22ms/step - categorical_accuracy: 0.3445 - loss: 2.9527 - val_categorical_accuracy: 0.4944 - val_loss: 1.6441\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 0.5633 - loss: 1.4462 - val_categorical_accuracy: 0.6940 - val_loss: 1.0165\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.7696 - loss: 0.7507 - val_categorical_accuracy: 0.7043 - val_loss: 1.0617\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 0.8634 - loss: 0.4305 - val_categorical_accuracy: 0.7532 - val_loss: 0.9751\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9196 - loss: 0.2470 - val_categorical_accuracy: 0.7658 - val_loss: 1.0069\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 0.9510 - loss: 0.1521 - val_categorical_accuracy: 0.7504 - val_loss: 1.2000\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 0.9672 - loss: 0.1038 - val_categorical_accuracy: 0.7817 - val_loss: 1.1787\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9745 - loss: 0.0831 - val_categorical_accuracy: 0.7767 - val_loss: 1.1380\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 0.9813 - loss: 0.0583 - val_categorical_accuracy: 0.7766 - val_loss: 1.3291\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 0.9878 - loss: 0.0384 - val_categorical_accuracy: 0.7886 - val_loss: 1.3009\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9898 - loss: 0.0327 - val_categorical_accuracy: 0.8064 - val_loss: 1.2188\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9923 - loss: 0.0257 - val_categorical_accuracy: 0.7979 - val_loss: 1.3948\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9938 - loss: 0.0221 - val_categorical_accuracy: 0.8008 - val_loss: 1.3486\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 0.9957 - loss: 0.0136 - val_categorical_accuracy: 0.8004 - val_loss: 1.3413\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.9977 - loss: 0.0074 - val_categorical_accuracy: 0.8067 - val_loss: 1.4420\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - categorical_accuracy: 0.9988 - loss: 0.0048 - val_categorical_accuracy: 0.8160 - val_loss: 1.4912\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 0.9991 - loss: 0.0028 - val_categorical_accuracy: 0.8160 - val_loss: 1.4958\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 1.0000 - loss: 1.7765e-04 - val_categorical_accuracy: 0.8188 - val_loss: 1.5428\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 1.0000 - loss: 4.8521e-05 - val_categorical_accuracy: 0.8186 - val_loss: 1.5638\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 1.0000 - loss: 3.3146e-05 - val_categorical_accuracy: 0.8185 - val_loss: 1.5844\n",
      "Epoch 21/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 1.0000 - loss: 2.7053e-05 - val_categorical_accuracy: 0.8195 - val_loss: 1.6017\n"
     ]
    }
   ],
   "source": [
    "def normalized_cnn(normalization_layer = None, input_shape = (256, 256), batch_size = 32) -> keras.Model:\n",
    "    inputs = keras.layers.Input(shape=input_shape, batch_size=batch_size)\n",
    "\n",
    "    # Preprocessing\n",
    "    x = keras.layers.Reshape((*input_shape, 1))(inputs)\n",
    "    if normalization_layer is not None:\n",
    "        x = normalization_layer(x)\n",
    "\n",
    "    # Convolution layers\n",
    "    x = keras.layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(3, 3))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(64, kernel_size=(2, 2), activation=\"relu\")(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128, kernel_size=(2, 2), activation=\"relu\")(x)\n",
    "    x = keras.layers.AvgPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Dense layer\n",
    "    x = keras.layers.Flatten(\"channels_last\")(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    outputs = keras.layers.Dense(30, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs, name=\"NormalizedCNN\")\n",
    "\n",
    "\n",
    "\n",
    "normalized_cnn().summary()\n",
    "\n",
    "log_dir = os.path.join(LOG_DIR, \"kaggle-speech-recognition\", \"NormalizedCNN\")\n",
    "models = []\n",
    "\n",
    "learning_rates = np.logspace(-2, -1, 3)\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True, start_from_epoch=10)\n",
    "normalization_layer = keras.layers.Normalization(axis=-1)\n",
    "feature_ds = ds_train.map(lambda x, y: x)\n",
    "normalization_layer.adapt(feature_ds)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = normalized_cnn(normalization_layer)\n",
    "\n",
    "    lr_scheduler = ExponentialDecay(lr, decay_steps=10_000, decay_rate=0.9)\n",
    "    optimizer = SGD(learning_rate=lr_scheduler)\n",
    "    loss = CategoricalCrossentropy()\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    model_log_dir = os.path.join(log_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S_lr-{lr}\"))\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1)\n",
    "    history = model.fit(x=ds_train, validation_data=ds_valid, batch_size=batch_size, epochs=50,\n",
    "                callbacks=[tensorboard_cb, early_stopping])\n",
    "    models.append((model, history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization helped a lot with smoothing loss function, making it easier for optimizer to skip local minima.\n",
    "Overfitting is hard, but we are going to take care of that later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[2][0].save(\"../models/NormalizedCNN.keras\", zipped=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "Since our model seems to be able to capture complexity of the data, we are going to regularize it to\n",
    "and see if it generalizes better. After first and second Dense layer I put dropout with rate 0.7.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"RegularizedCNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"RegularizedCNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">254</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,107,456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,710</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape (\u001b[38;5;33mReshape\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m254\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m84\u001b[0m, \u001b[38;5;34m84\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m51200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │    \u001b[38;5;34m13,107,456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m)               │         \u001b[38;5;34m7,710\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,218,174</span> (50.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,218,174\u001b[0m (50.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,218,174</span> (50.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,218,174\u001b[0m (50.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def regularized_cnn(\n",
    "        dropout_rate = 0.7,\n",
    "        normalization_layer = None,\n",
    "        input_shape = (256, 256),\n",
    "        batch_size = 32\n",
    ") -> keras.Model:\n",
    "    inputs = keras.layers.Input(shape=input_shape, batch_size=batch_size)\n",
    "\n",
    "    # Preprocessing\n",
    "    x = keras.layers.Reshape((*input_shape, 1))(inputs)\n",
    "    if normalization_layer is not None:\n",
    "        x = normalization_layer(x)\n",
    "\n",
    "    # Convolution layers\n",
    "    x = keras.layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(3, 3))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(64, kernel_size=(2, 2), activation=\"relu\")(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128, kernel_size=(2, 2), activation=\"relu\")(x)\n",
    "    x = keras.layers.AvgPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Dense layer\n",
    "    x = keras.layers.Flatten(\"channels_last\")(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    outputs = keras.layers.Dense(30, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs, name=\"RegularizedCNN\")\n",
    "\n",
    "\n",
    "\n",
    "regularized_cnn().summary()\n",
    "\n",
    "log_dir = os.path.join(LOG_DIR, \"kaggle-speech-recognition\", regularized_cnn().name)\n",
    "models = []\n",
    "learning_rates = np.logspace(-2, -1, 3)\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True, start_from_epoch=10)\n",
    "normalization_layer = keras.layers.Normalization(axis=-1)\n",
    "feature_ds = ds_train.map(lambda x, y: x)\n",
    "normalization_layer.adapt(feature_ds)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = regularized_cnn(normalization_layer)\n",
    "\n",
    "    lr_scheduler = ExponentialDecay(lr, decay_steps=10_000, decay_rate=0.9)\n",
    "    optimizer = SGD(learning_rate=lr_scheduler)\n",
    "    loss = CategoricalCrossentropy()\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    model_log_dir = os.path.join(log_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S_lr-{lr}\"))\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1)\n",
    "    history = model.fit(x=ds_train, validation_data=ds_valid, batch_size=batch_size, epochs=50,\n",
    "                callbacks=[tensorboard_cb, early_stopping])\n",
    "    models.append((model, history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try smaller dropout rate, as 0.7 from AlexNet may be too strict for our smaller dataset.\n",
    "\n",
    "Also I have tweaked decay_steps parameter in ExponentialDecay, now it's 5000, instead of 10000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 12:56:49.319064: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1732535809.606476    4156 service.cc:148] XLA service 0x7f2ebc003e60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1732535809.606976    4156 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-11-25 12:56:49.656319: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1732535809.735075    4156 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m   7/1597\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m29s\u001b[0m 19ms/step - categorical_accuracy: 0.0291 - loss: 3.4135    "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732535815.226566    4156 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 25ms/step - categorical_accuracy: 0.0573 - loss: 3.3497 - val_categorical_accuracy: 0.2030 - val_loss: 2.8263\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - categorical_accuracy: 0.1639 - loss: 2.9006 - val_categorical_accuracy: 0.3124 - val_loss: 2.3651\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - categorical_accuracy: 0.2536 - loss: 2.5318 - val_categorical_accuracy: 0.4141 - val_loss: 2.0139\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 0.3298 - loss: 2.2427 - val_categorical_accuracy: 0.4900 - val_loss: 1.8244\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - categorical_accuracy: 0.3900 - loss: 2.0206 - val_categorical_accuracy: 0.5427 - val_loss: 1.5774\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - categorical_accuracy: 0.4441 - loss: 1.8424 - val_categorical_accuracy: 0.5738 - val_loss: 1.4691\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - categorical_accuracy: 0.4878 - loss: 1.6883 - val_categorical_accuracy: 0.6021 - val_loss: 1.3218\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - categorical_accuracy: 0.5247 - loss: 1.5486 - val_categorical_accuracy: 0.6219 - val_loss: 1.2696\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - categorical_accuracy: 0.5678 - loss: 1.4143 - val_categorical_accuracy: 0.6552 - val_loss: 1.1770\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 20ms/step - categorical_accuracy: 0.6105 - loss: 1.2717 - val_categorical_accuracy: 0.6623 - val_loss: 1.1289\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - categorical_accuracy: 0.6390 - loss: 1.1584 - val_categorical_accuracy: 0.6918 - val_loss: 1.0172\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.6659 - loss: 1.0507 - val_categorical_accuracy: 0.7087 - val_loss: 0.9679\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - categorical_accuracy: 0.6976 - loss: 0.9560 - val_categorical_accuracy: 0.7249 - val_loss: 0.9337\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.7298 - loss: 0.8572 - val_categorical_accuracy: 0.7329 - val_loss: 0.9213\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.7516 - loss: 0.7774 - val_categorical_accuracy: 0.7357 - val_loss: 0.8855\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 18ms/step - categorical_accuracy: 0.7767 - loss: 0.7033 - val_categorical_accuracy: 0.7530 - val_loss: 0.8467\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.7989 - loss: 0.6322 - val_categorical_accuracy: 0.7533 - val_loss: 0.8444\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.8089 - loss: 0.5844 - val_categorical_accuracy: 0.7527 - val_loss: 0.8474\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 16ms/step - categorical_accuracy: 0.8254 - loss: 0.5339 - val_categorical_accuracy: 0.7568 - val_loss: 0.8592\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.8404 - loss: 0.4914 - val_categorical_accuracy: 0.7574 - val_loss: 0.8580\n",
      "Epoch 21/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.8524 - loss: 0.4515 - val_categorical_accuracy: 0.7629 - val_loss: 0.8195\n",
      "Epoch 22/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - categorical_accuracy: 0.8651 - loss: 0.4148 - val_categorical_accuracy: 0.7588 - val_loss: 0.8575\n",
      "Epoch 23/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 22ms/step - categorical_accuracy: 0.8719 - loss: 0.3831 - val_categorical_accuracy: 0.7686 - val_loss: 0.8512\n",
      "Epoch 24/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 21ms/step - categorical_accuracy: 0.8841 - loss: 0.3490 - val_categorical_accuracy: 0.7695 - val_loss: 0.8381\n",
      "Epoch 25/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 21ms/step - categorical_accuracy: 0.8885 - loss: 0.3370 - val_categorical_accuracy: 0.7714 - val_loss: 0.8747\n",
      "Epoch 26/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - categorical_accuracy: 0.8971 - loss: 0.3039 - val_categorical_accuracy: 0.7746 - val_loss: 0.8631\n",
      "Epoch 27/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - categorical_accuracy: 0.9010 - loss: 0.2921 - val_categorical_accuracy: 0.7770 - val_loss: 0.8861\n",
      "Epoch 28/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.9115 - loss: 0.2651 - val_categorical_accuracy: 0.7761 - val_loss: 0.8791\n",
      "Epoch 29/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.9151 - loss: 0.2575 - val_categorical_accuracy: 0.7768 - val_loss: 0.9100\n",
      "Epoch 30/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.9197 - loss: 0.2466 - val_categorical_accuracy: 0.7843 - val_loss: 0.8750\n",
      "Epoch 31/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.9260 - loss: 0.2230 - val_categorical_accuracy: 0.7789 - val_loss: 0.9305\n",
      "Epoch 1/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 20ms/step - categorical_accuracy: 0.2756 - loss: 3.2887 - val_categorical_accuracy: 0.2690 - val_loss: 2.5421\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 17ms/step - categorical_accuracy: 0.2256 - loss: 2.6430 - val_categorical_accuracy: 0.3676 - val_loss: 2.2017\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.3473 - loss: 2.1787 - val_categorical_accuracy: 0.5071 - val_loss: 1.6167\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.4473 - loss: 1.8092 - val_categorical_accuracy: 0.6169 - val_loss: 1.2750\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.5498 - loss: 1.4748 - val_categorical_accuracy: 0.6698 - val_loss: 1.1401\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.6251 - loss: 1.2021 - val_categorical_accuracy: 0.7257 - val_loss: 0.9124\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - categorical_accuracy: 0.6899 - loss: 0.9879 - val_categorical_accuracy: 0.7485 - val_loss: 0.8394\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.7366 - loss: 0.8268 - val_categorical_accuracy: 0.7646 - val_loss: 0.7898\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - categorical_accuracy: 0.7771 - loss: 0.7022 - val_categorical_accuracy: 0.7735 - val_loss: 0.7510\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - categorical_accuracy: 0.8086 - loss: 0.5860 - val_categorical_accuracy: 0.7795 - val_loss: 0.7455\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.8362 - loss: 0.4956 - val_categorical_accuracy: 0.7942 - val_loss: 0.7265\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - categorical_accuracy: 0.8639 - loss: 0.4153 - val_categorical_accuracy: 0.7707 - val_loss: 0.8146\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - categorical_accuracy: 0.8822 - loss: 0.3610 - val_categorical_accuracy: 0.7949 - val_loss: 0.7517\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 17ms/step - categorical_accuracy: 0.8975 - loss: 0.3086 - val_categorical_accuracy: 0.7998 - val_loss: 0.7668\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 20ms/step - categorical_accuracy: 0.9132 - loss: 0.2639 - val_categorical_accuracy: 0.8054 - val_loss: 0.7566\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - categorical_accuracy: 0.9213 - loss: 0.2384 - val_categorical_accuracy: 0.8052 - val_loss: 0.7839\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - categorical_accuracy: 0.9315 - loss: 0.2059 - val_categorical_accuracy: 0.7911 - val_loss: 0.7909\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 20ms/step - categorical_accuracy: 0.9415 - loss: 0.1802 - val_categorical_accuracy: 0.8077 - val_loss: 0.7783\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.9448 - loss: 0.1648 - val_categorical_accuracy: 0.8117 - val_loss: 0.7944\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - categorical_accuracy: 0.9532 - loss: 0.1422 - val_categorical_accuracy: 0.8119 - val_loss: 0.8474\n",
      "Epoch 21/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - categorical_accuracy: 0.9570 - loss: 0.1292 - val_categorical_accuracy: 0.8049 - val_loss: 0.8680\n",
      "Epoch 1/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 20ms/step - categorical_accuracy: 0.2981 - loss: 3.2046 - val_categorical_accuracy: 0.3366 - val_loss: 2.2503\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.3391 - loss: 2.1839 - val_categorical_accuracy: 0.6133 - val_loss: 1.2715\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - categorical_accuracy: 0.5407 - loss: 1.4711 - val_categorical_accuracy: 0.7265 - val_loss: 0.9149\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - categorical_accuracy: 0.6699 - loss: 1.0617 - val_categorical_accuracy: 0.7517 - val_loss: 0.7871\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.7415 - loss: 0.8065 - val_categorical_accuracy: 0.7585 - val_loss: 0.7971\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - categorical_accuracy: 0.7997 - loss: 0.6137 - val_categorical_accuracy: 0.7833 - val_loss: 0.7453\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - categorical_accuracy: 0.8447 - loss: 0.4825 - val_categorical_accuracy: 0.7954 - val_loss: 0.7399\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 19ms/step - categorical_accuracy: 0.8740 - loss: 0.3861 - val_categorical_accuracy: 0.8042 - val_loss: 0.7111\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.8968 - loss: 0.3157 - val_categorical_accuracy: 0.8149 - val_loss: 0.6944\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.9168 - loss: 0.2557 - val_categorical_accuracy: 0.8054 - val_loss: 0.7504\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.9274 - loss: 0.2180 - val_categorical_accuracy: 0.8057 - val_loss: 0.7737\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.9411 - loss: 0.1782 - val_categorical_accuracy: 0.8033 - val_loss: 0.7954\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - categorical_accuracy: 0.9474 - loss: 0.1589 - val_categorical_accuracy: 0.8160 - val_loss: 0.8093\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.9568 - loss: 0.1351 - val_categorical_accuracy: 0.8191 - val_loss: 0.7556\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.9625 - loss: 0.1158 - val_categorical_accuracy: 0.8120 - val_loss: 0.8247\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.9677 - loss: 0.1023 - val_categorical_accuracy: 0.8049 - val_loss: 0.9214\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.9703 - loss: 0.0880 - val_categorical_accuracy: 0.8048 - val_loss: 0.8708\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 17ms/step - categorical_accuracy: 0.9738 - loss: 0.0797 - val_categorical_accuracy: 0.8102 - val_loss: 0.9129\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.9755 - loss: 0.0773 - val_categorical_accuracy: 0.8260 - val_loss: 0.8380\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 19ms/step - categorical_accuracy: 0.9778 - loss: 0.0679 - val_categorical_accuracy: 0.8177 - val_loss: 0.8974\n"
     ]
    }
   ],
   "source": [
    "log_dir = os.path.join(LOG_DIR, \"kaggle-speech-recognition\", regularized_cnn().name)\n",
    "models = []\n",
    "learning_rates = np.logspace(-2, -1, 3)\n",
    "early_stopping = EarlyStopping(patience=10, restore_best_weights=True, start_from_epoch=10)\n",
    "normalization_layer = keras.layers.Normalization(axis=-1)\n",
    "feature_ds = ds_train.map(lambda x, y: x)\n",
    "normalization_layer.adapt(feature_ds)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = regularized_cnn(dropout_rate=0.35, normalization_layer=normalization_layer)\n",
    "\n",
    "    lr_scheduler = ExponentialDecay(lr, decay_steps=5_000, decay_rate=0.9)\n",
    "    optimizer = SGD(learning_rate=lr_scheduler)\n",
    "    loss = CategoricalCrossentropy()\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    model_log_dir = os.path.join(log_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S_lr-{lr}_dropout-0.35\"))\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1)\n",
    "    history = model.fit(x=ds_train, validation_data=ds_valid, batch_size=batch_size, epochs=50,\n",
    "                callbacks=[tensorboard_cb, early_stopping])\n",
    "    models.append((model, history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks as model is overfitting even with regularization. Maybe training data is not sufficient to\n",
    "model real distribution of the problem. Let's try adding random crop to augment the data. Moreover \n",
    "I'm going to increase dropout to 0.5 and lengthen patience in early stopping for longer training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"AugmentedRegularizedCNN\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"AugmentedRegularizedCNN\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_crop (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomCrop</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">253</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">84</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">83</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">41</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_6             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">51200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │    <span style=\"color: #00af00; text-decoration-color: #00af00\">13,107,456</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,710</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_6 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_6 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_crop (\u001b[38;5;33mRandomCrop\u001b[0m)        │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m255\u001b[0m, \u001b[38;5;34m255\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m253\u001b[0m, \u001b[38;5;34m16\u001b[0m)     │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m84\u001b[0m, \u001b[38;5;34m84\u001b[0m, \u001b[38;5;34m16\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m83\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m41\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m32,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ average_pooling2d_6             │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m20\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_6 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m51200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_18 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │    \u001b[38;5;34m13,107,456\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_12 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_13 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m)               │         \u001b[38;5;34m7,710\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,218,174</span> (50.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,218,174\u001b[0m (50.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,218,174</span> (50.42 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,218,174\u001b[0m (50.42 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-25 14:29:24.288235: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 30ms/step - categorical_accuracy: 0.2650 - loss: 3.3848 - val_categorical_accuracy: 0.1309 - val_loss: 3.1664\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.0958 - loss: 3.2007 - val_categorical_accuracy: 0.2221 - val_loss: 2.7690\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.1510 - loss: 2.9397 - val_categorical_accuracy: 0.3213 - val_loss: 2.4631\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.2105 - loss: 2.6776 - val_categorical_accuracy: 0.3797 - val_loss: 2.2242\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.2671 - loss: 2.4551 - val_categorical_accuracy: 0.4237 - val_loss: 2.0051\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.3084 - loss: 2.2950 - val_categorical_accuracy: 0.4801 - val_loss: 1.8544\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 28ms/step - categorical_accuracy: 0.3465 - loss: 2.1707 - val_categorical_accuracy: 0.5009 - val_loss: 1.7665\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.3809 - loss: 2.0444 - val_categorical_accuracy: 0.5403 - val_loss: 1.6672\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.4149 - loss: 1.9358 - val_categorical_accuracy: 0.5652 - val_loss: 1.5381\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.4448 - loss: 1.8176 - val_categorical_accuracy: 0.5811 - val_loss: 1.4932\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 28ms/step - categorical_accuracy: 0.4764 - loss: 1.7091 - val_categorical_accuracy: 0.6321 - val_loss: 1.2796\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.5064 - loss: 1.5869 - val_categorical_accuracy: 0.6468 - val_loss: 1.2536\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.5408 - loss: 1.4840 - val_categorical_accuracy: 0.6581 - val_loss: 1.1758\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.5734 - loss: 1.3730 - val_categorical_accuracy: 0.6840 - val_loss: 1.0982\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.6020 - loss: 1.2845 - val_categorical_accuracy: 0.7089 - val_loss: 0.9967\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.6242 - loss: 1.2001 - val_categorical_accuracy: 0.7208 - val_loss: 0.9566\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.6449 - loss: 1.1289 - val_categorical_accuracy: 0.7276 - val_loss: 0.9443\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.6657 - loss: 1.0505 - val_categorical_accuracy: 0.7268 - val_loss: 0.9191\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.6830 - loss: 0.9977 - val_categorical_accuracy: 0.7379 - val_loss: 0.8790\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.7027 - loss: 0.9360 - val_categorical_accuracy: 0.7526 - val_loss: 0.8379\n",
      "Epoch 21/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.7165 - loss: 0.8870 - val_categorical_accuracy: 0.7607 - val_loss: 0.8214\n",
      "Epoch 22/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.7292 - loss: 0.8383 - val_categorical_accuracy: 0.7570 - val_loss: 0.8286\n",
      "Epoch 23/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.7391 - loss: 0.8176 - val_categorical_accuracy: 0.7638 - val_loss: 0.8055\n",
      "Epoch 24/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.7549 - loss: 0.7557 - val_categorical_accuracy: 0.7590 - val_loss: 0.8218\n",
      "Epoch 25/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.7661 - loss: 0.7215 - val_categorical_accuracy: 0.7683 - val_loss: 0.7902\n",
      "Epoch 26/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.7773 - loss: 0.6888 - val_categorical_accuracy: 0.7648 - val_loss: 0.7993\n",
      "Epoch 27/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.7865 - loss: 0.6536 - val_categorical_accuracy: 0.7718 - val_loss: 0.7838\n",
      "Epoch 28/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.7968 - loss: 0.6185 - val_categorical_accuracy: 0.7838 - val_loss: 0.7550\n",
      "Epoch 29/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.8033 - loss: 0.5967 - val_categorical_accuracy: 0.7846 - val_loss: 0.7638\n",
      "Epoch 30/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8159 - loss: 0.5650 - val_categorical_accuracy: 0.7745 - val_loss: 0.7904\n",
      "Epoch 31/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8201 - loss: 0.5449 - val_categorical_accuracy: 0.7813 - val_loss: 0.7561\n",
      "Epoch 32/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8253 - loss: 0.5292 - val_categorical_accuracy: 0.7836 - val_loss: 0.7624\n",
      "Epoch 33/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.8305 - loss: 0.5105 - val_categorical_accuracy: 0.7829 - val_loss: 0.7594\n",
      "Epoch 34/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8381 - loss: 0.4866 - val_categorical_accuracy: 0.7885 - val_loss: 0.7620\n",
      "Epoch 35/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8485 - loss: 0.4590 - val_categorical_accuracy: 0.7876 - val_loss: 0.7635\n",
      "Epoch 36/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8493 - loss: 0.4579 - val_categorical_accuracy: 0.7901 - val_loss: 0.7787\n",
      "Epoch 37/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.8548 - loss: 0.4364 - val_categorical_accuracy: 0.7923 - val_loss: 0.7629\n",
      "Epoch 38/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8639 - loss: 0.4069 - val_categorical_accuracy: 0.7921 - val_loss: 0.7708\n",
      "Epoch 39/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8659 - loss: 0.3997 - val_categorical_accuracy: 0.7938 - val_loss: 0.7815\n",
      "Epoch 40/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8754 - loss: 0.3808 - val_categorical_accuracy: 0.7955 - val_loss: 0.7752\n",
      "Epoch 41/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.8758 - loss: 0.3733 - val_categorical_accuracy: 0.7921 - val_loss: 0.7792\n",
      "Epoch 42/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8823 - loss: 0.3506 - val_categorical_accuracy: 0.7927 - val_loss: 0.7809\n",
      "Epoch 43/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8842 - loss: 0.3494 - val_categorical_accuracy: 0.7954 - val_loss: 0.7685\n",
      "Epoch 1/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.2628 - loss: 3.3664 - val_categorical_accuracy: 0.1706 - val_loss: 3.0026\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.1345 - loss: 3.0080 - val_categorical_accuracy: 0.3420 - val_loss: 2.3470\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.2277 - loss: 2.5950 - val_categorical_accuracy: 0.4292 - val_loss: 1.9813\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.3152 - loss: 2.2457 - val_categorical_accuracy: 0.5388 - val_loss: 1.6738\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.4103 - loss: 1.9318 - val_categorical_accuracy: 0.5781 - val_loss: 1.4205\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.4911 - loss: 1.6491 - val_categorical_accuracy: 0.6839 - val_loss: 1.1285\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.5616 - loss: 1.4162 - val_categorical_accuracy: 0.7134 - val_loss: 1.0177\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.6111 - loss: 1.2415 - val_categorical_accuracy: 0.7427 - val_loss: 0.9037\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.6575 - loss: 1.0884 - val_categorical_accuracy: 0.7368 - val_loss: 0.8638\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.7000 - loss: 0.9456 - val_categorical_accuracy: 0.7730 - val_loss: 0.7858\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.7318 - loss: 0.8447 - val_categorical_accuracy: 0.7836 - val_loss: 0.7337\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.7621 - loss: 0.7458 - val_categorical_accuracy: 0.7826 - val_loss: 0.7228\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.7836 - loss: 0.6668 - val_categorical_accuracy: 0.8045 - val_loss: 0.6840\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8031 - loss: 0.5966 - val_categorical_accuracy: 0.7996 - val_loss: 0.7133\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.8237 - loss: 0.5392 - val_categorical_accuracy: 0.8039 - val_loss: 0.7130\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8389 - loss: 0.4864 - val_categorical_accuracy: 0.8099 - val_loss: 0.6714\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 30ms/step - categorical_accuracy: 0.8531 - loss: 0.4392 - val_categorical_accuracy: 0.8154 - val_loss: 0.6736\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.8632 - loss: 0.4134 - val_categorical_accuracy: 0.8155 - val_loss: 0.6790\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.8808 - loss: 0.3611 - val_categorical_accuracy: 0.8173 - val_loss: 0.7092\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8893 - loss: 0.3375 - val_categorical_accuracy: 0.8211 - val_loss: 0.6941\n",
      "Epoch 21/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.9002 - loss: 0.3036 - val_categorical_accuracy: 0.8223 - val_loss: 0.7011\n",
      "Epoch 22/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.9059 - loss: 0.2871 - val_categorical_accuracy: 0.8164 - val_loss: 0.7218\n",
      "Epoch 23/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.9120 - loss: 0.2699 - val_categorical_accuracy: 0.8211 - val_loss: 0.7196\n",
      "Epoch 24/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - categorical_accuracy: 0.9203 - loss: 0.2402 - val_categorical_accuracy: 0.8233 - val_loss: 0.7377\n",
      "Epoch 25/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.9235 - loss: 0.2232 - val_categorical_accuracy: 0.8213 - val_loss: 0.7474\n",
      "Epoch 26/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.9306 - loss: 0.2115 - val_categorical_accuracy: 0.8232 - val_loss: 0.7562\n",
      "Epoch 27/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.9350 - loss: 0.1993 - val_categorical_accuracy: 0.8198 - val_loss: 0.7676\n",
      "Epoch 28/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.9392 - loss: 0.1852 - val_categorical_accuracy: 0.8222 - val_loss: 0.7645\n",
      "Epoch 29/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.9436 - loss: 0.1726 - val_categorical_accuracy: 0.8220 - val_loss: 0.7458\n",
      "Epoch 30/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.9450 - loss: 0.1663 - val_categorical_accuracy: 0.8224 - val_loss: 0.7520\n",
      "Epoch 31/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.9463 - loss: 0.1574 - val_categorical_accuracy: 0.8255 - val_loss: 0.7806\n",
      "Epoch 1/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 28ms/step - categorical_accuracy: 0.2806 - loss: 3.3252 - val_categorical_accuracy: 0.2387 - val_loss: 2.5608\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.2306 - loss: 2.5917 - val_categorical_accuracy: 0.4775 - val_loss: 1.7427\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.3736 - loss: 2.0421 - val_categorical_accuracy: 0.6277 - val_loss: 1.3089\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 30ms/step - categorical_accuracy: 0.5053 - loss: 1.5852 - val_categorical_accuracy: 0.7077 - val_loss: 1.0181\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.6070 - loss: 1.2562 - val_categorical_accuracy: 0.7304 - val_loss: 0.9022\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.6735 - loss: 1.0283 - val_categorical_accuracy: 0.7573 - val_loss: 0.8214\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.7251 - loss: 0.8726 - val_categorical_accuracy: 0.7739 - val_loss: 0.7515\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 30ms/step - categorical_accuracy: 0.7621 - loss: 0.7511 - val_categorical_accuracy: 0.7910 - val_loss: 0.6931\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.5735 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.0369 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.0367 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 29ms/step - categorical_accuracy: 0.0369 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.0369 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.0369 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.0367 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 29ms/step - categorical_accuracy: 0.0367 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.0369 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.0369 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.0369 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.0368 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 21/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 29ms/step - categorical_accuracy: 0.0369 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 22/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.0369 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 23/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.0369 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 24/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 28ms/step - categorical_accuracy: 0.0368 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n",
      "Epoch 25/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.0369 - loss: nan - val_categorical_accuracy: 0.0338 - val_loss: nan\n"
     ]
    }
   ],
   "source": [
    "def augment_regularized_cnn(\n",
    "        normalization_layer = None,\n",
    "        dropout_rate = 0.5,\n",
    "        input_shape = (256, 256),\n",
    "        batch_size = 32\n",
    ") -> keras.Model:\n",
    "    inputs = keras.layers.Input(shape=input_shape, batch_size=batch_size)\n",
    "\n",
    "    # Preprocessing\n",
    "    x = keras.layers.Reshape((*input_shape, 1))(inputs)\n",
    "    if normalization_layer is not None:\n",
    "        x = normalization_layer(x)\n",
    "    x = keras.layers.RandomCrop(height=255, width=255)(x)\n",
    "\n",
    "    # Convolution layers\n",
    "    x = keras.layers.Conv2D(16, kernel_size=(3, 3), activation=\"relu\")(x)\n",
    "    # Batch normalization can be done like this\n",
    "    # x = keras.layers.Conv2D(16, kernel_size=(3, 3))(x)\n",
    "    # x = keras.layers.BatchNormalization()(x)\n",
    "    # x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(3, 3))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(64, kernel_size=(2, 2), activation=\"relu\")(x)\n",
    "    x = keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128, kernel_size=(2, 2), activation=\"relu\")(x)\n",
    "    x = keras.layers.AvgPool2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Dense layer\n",
    "    x = keras.layers.Flatten(\"channels_last\")(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    outputs = keras.layers.Dense(30, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs, name=\"AugmentedRegularizedCNN\")\n",
    "\n",
    "\n",
    "\n",
    "augment_regularized_cnn().summary()\n",
    "\n",
    "log_dir = os.path.join(LOG_DIR, \"kaggle-speech-recognition\", augment_regularized_cnn().name)\n",
    "models = []\n",
    "learning_rates = np.logspace(-2, -1, 3)\n",
    "early_stopping = EarlyStopping(patience=15, restore_best_weights=True, start_from_epoch=10)\n",
    "normalization_layer = keras.layers.Normalization(axis=-1)\n",
    "feature_ds = ds_train.map(lambda x, y: x)\n",
    "normalization_layer.adapt(feature_ds)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = augment_regularized_cnn(normalization_layer=normalization_layer)\n",
    "\n",
    "    lr_scheduler = ExponentialDecay(lr, decay_steps=5_000, decay_rate=0.9)\n",
    "    optimizer = SGD(learning_rate=lr_scheduler)\n",
    "    loss = CategoricalCrossentropy()\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "    model_log_dir = os.path.join(log_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S_lr-{lr}\"))\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1)\n",
    "    history = model.fit(x=ds_train, validation_data=ds_valid, batch_size=batch_size, epochs=50,\n",
    "                callbacks=[tensorboard_cb, early_stopping])\n",
    "    models.append((model, history))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "?? I don't understand what happened with biggest learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 29ms/step - categorical_accuracy: 0.0544 - loss: 3.3243 - val_categorical_accuracy: 0.2240 - val_loss: 2.6671\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 28ms/step - categorical_accuracy: 0.2136 - loss: 2.6388 - val_categorical_accuracy: 0.4612 - val_loss: 1.8971\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - categorical_accuracy: 0.3531 - loss: 2.0955 - val_categorical_accuracy: 0.5646 - val_loss: 1.4071\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 33ms/step - categorical_accuracy: 0.4978 - loss: 1.6076 - val_categorical_accuracy: 0.7015 - val_loss: 1.0037\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 31ms/step - categorical_accuracy: 0.5909 - loss: 1.2923 - val_categorical_accuracy: 0.7307 - val_loss: 0.8926\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 38ms/step - categorical_accuracy: 0.6608 - loss: 1.0714 - val_categorical_accuracy: 0.7664 - val_loss: 0.7560\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 32ms/step - categorical_accuracy: 0.7116 - loss: 0.9031 - val_categorical_accuracy: 0.7883 - val_loss: 0.7087\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 28ms/step - categorical_accuracy: 0.7588 - loss: 0.7581 - val_categorical_accuracy: 0.7954 - val_loss: 0.6871\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 30ms/step - categorical_accuracy: 0.7868 - loss: 0.6639 - val_categorical_accuracy: 0.8076 - val_loss: 0.6435\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8189 - loss: 0.5626 - val_categorical_accuracy: 0.8020 - val_loss: 0.6891\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.8362 - loss: 0.5105 - val_categorical_accuracy: 0.8124 - val_loss: 0.6714\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 29ms/step - categorical_accuracy: 0.8548 - loss: 0.4450 - val_categorical_accuracy: 0.8148 - val_loss: 0.6513\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 28ms/step - categorical_accuracy: 0.8732 - loss: 0.3927 - val_categorical_accuracy: 0.8214 - val_loss: 0.6491\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.8864 - loss: 0.3521 - val_categorical_accuracy: 0.8185 - val_loss: 0.6404\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.8993 - loss: 0.3153 - val_categorical_accuracy: 0.8266 - val_loss: 0.6642\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - categorical_accuracy: 0.9077 - loss: 0.2806 - val_categorical_accuracy: 0.8154 - val_loss: 0.6972\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.9131 - loss: 0.2630 - val_categorical_accuracy: 0.8249 - val_loss: 0.6866\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.9200 - loss: 0.2384 - val_categorical_accuracy: 0.8167 - val_loss: 0.7301\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.9304 - loss: 0.2133 - val_categorical_accuracy: 0.8258 - val_loss: 0.6946\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - categorical_accuracy: 0.9381 - loss: 0.1902 - val_categorical_accuracy: 0.8241 - val_loss: 0.7269\n",
      "Epoch 21/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.9385 - loss: 0.1860 - val_categorical_accuracy: 0.8301 - val_loss: 0.7074\n",
      "Epoch 22/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.9446 - loss: 0.1701 - val_categorical_accuracy: 0.8255 - val_loss: 0.7549\n",
      "Epoch 23/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.9495 - loss: 0.1557 - val_categorical_accuracy: 0.8335 - val_loss: 0.7235\n",
      "Epoch 24/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 29ms/step - categorical_accuracy: 0.9522 - loss: 0.1471 - val_categorical_accuracy: 0.8297 - val_loss: 0.7325\n",
      "Epoch 25/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.9568 - loss: 0.1355 - val_categorical_accuracy: 0.8254 - val_loss: 0.7810\n",
      "Epoch 26/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.9604 - loss: 0.1233 - val_categorical_accuracy: 0.8238 - val_loss: 0.7985\n",
      "Epoch 27/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 27ms/step - categorical_accuracy: 0.9608 - loss: 0.1217 - val_categorical_accuracy: 0.8319 - val_loss: 0.7890\n",
      "Epoch 28/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 29ms/step - categorical_accuracy: 0.9622 - loss: 0.1121 - val_categorical_accuracy: 0.8329 - val_loss: 0.8362\n",
      "Epoch 29/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 27ms/step - categorical_accuracy: 0.9632 - loss: 0.1119 - val_categorical_accuracy: 0.8342 - val_loss: 0.7728\n"
     ]
    }
   ],
   "source": [
    "model = augment_regularized_cnn(normalization_layer=normalization_layer)\n",
    "\n",
    "lr_scheduler = ExponentialDecay(0.1, decay_steps=5_000, decay_rate=0.9)\n",
    "optimizer = SGD(learning_rate=lr_scheduler)\n",
    "loss = CategoricalCrossentropy()\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "model_log_dir = os.path.join(log_dir, datetime.now().strftime(f\"%Y%m%d-%H%M%S_lr-{lr}\"))\n",
    "tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1)\n",
    "history = model.fit(x=ds_train, validation_data=ds_valid, batch_size=batch_size, epochs=50,\n",
    "            callbacks=[tensorboard_cb, early_stopping])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum\n",
    "We are going to try now fitting dataset with different optimizers. I'm going to train a model with:\n",
    "1. SGD with momentum (normal, not nesterov)\n",
    "2. Adam\n",
    "\n",
    "We will see if momentum can help somehow. Moreover, droupout increased to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MyAlexNet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MyAlexNet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_crop_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">RandomCrop</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">227</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">227</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">113</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">262,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">7,710</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_2 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ reshape_2 (\u001b[38;5;33mReshape\u001b[0m)             │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ random_crop_2 (\u001b[38;5;33mRandomCrop\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m227\u001b[0m, \u001b[38;5;34m227\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m113\u001b[0m, \u001b[38;5;34m113\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │         \u001b[38;5;34m1,280\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)                  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_10          │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_10 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m262,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_11          │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_8 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m1024\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │       \u001b[38;5;34m262,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │        \u001b[38;5;34m65,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m)               │         \u001b[38;5;34m7,710\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,176,734</span> (4.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,176,734\u001b[0m (4.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,175,198</span> (4.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,175,198\u001b[0m (4.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 12:58:19.635431: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "I0000 00:00:1732795101.335141    1362 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 60ms/step - categorical_accuracy: 0.0407 - loss: 3.4310 - val_categorical_accuracy: 0.0482 - val_loss: 3.3462\n",
      "Epoch 2/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 60ms/step - categorical_accuracy: 0.0483 - loss: 3.3581 - val_categorical_accuracy: 0.0565 - val_loss: 3.3486\n",
      "Epoch 3/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0736 - loss: 3.2237 - val_categorical_accuracy: 0.0763 - val_loss: 3.1292\n",
      "Epoch 4/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0958 - loss: 3.0536 - val_categorical_accuracy: 0.1475 - val_loss: 2.8220\n",
      "Epoch 5/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 60ms/step - categorical_accuracy: 0.1448 - loss: 2.8283 - val_categorical_accuracy: 0.2284 - val_loss: 2.6245\n",
      "Epoch 6/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.2317 - loss: 2.5048 - val_categorical_accuracy: 0.2451 - val_loss: 2.4202\n",
      "Epoch 7/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.3302 - loss: 2.1459 - val_categorical_accuracy: 0.4706 - val_loss: 1.7456\n",
      "Epoch 8/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.4626 - loss: 1.7173 - val_categorical_accuracy: 0.6065 - val_loss: 1.2933\n",
      "Epoch 9/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.5709 - loss: 1.3691 - val_categorical_accuracy: 0.6484 - val_loss: 1.2024\n",
      "Epoch 10/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 60ms/step - categorical_accuracy: 0.6506 - loss: 1.1399 - val_categorical_accuracy: 0.6695 - val_loss: 1.1072\n",
      "Epoch 11/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 59ms/step - categorical_accuracy: 0.7012 - loss: 0.9814 - val_categorical_accuracy: 0.5455 - val_loss: 1.6975\n",
      "Epoch 12/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.7409 - loss: 0.8625 - val_categorical_accuracy: 0.7651 - val_loss: 0.8010\n",
      "Epoch 13/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.7640 - loss: 0.7948 - val_categorical_accuracy: 0.7804 - val_loss: 0.7412\n",
      "Epoch 14/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.7853 - loss: 0.7213 - val_categorical_accuracy: 0.7949 - val_loss: 0.6895\n",
      "Epoch 15/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.7992 - loss: 0.6804 - val_categorical_accuracy: 0.7757 - val_loss: 0.7665\n",
      "Epoch 16/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8089 - loss: 0.6441 - val_categorical_accuracy: 0.7688 - val_loss: 0.7803\n",
      "Epoch 17/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 61ms/step - categorical_accuracy: 0.8186 - loss: 0.6079 - val_categorical_accuracy: 0.8135 - val_loss: 0.6284\n",
      "Epoch 18/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8295 - loss: 0.5750 - val_categorical_accuracy: 0.8142 - val_loss: 0.6454\n",
      "Epoch 19/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8337 - loss: 0.5645 - val_categorical_accuracy: 0.8017 - val_loss: 0.6834\n",
      "Epoch 20/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8444 - loss: 0.5234 - val_categorical_accuracy: 0.7907 - val_loss: 0.7299\n",
      "Epoch 21/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8493 - loss: 0.5131 - val_categorical_accuracy: 0.8016 - val_loss: 0.6911\n",
      "Epoch 22/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 60ms/step - categorical_accuracy: 0.8547 - loss: 0.4996 - val_categorical_accuracy: 0.8066 - val_loss: 0.6670\n",
      "Epoch 23/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8619 - loss: 0.4722 - val_categorical_accuracy: 0.8276 - val_loss: 0.5963\n",
      "Epoch 24/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8643 - loss: 0.4588 - val_categorical_accuracy: 0.8260 - val_loss: 0.6178\n",
      "Epoch 25/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8676 - loss: 0.4536 - val_categorical_accuracy: 0.8311 - val_loss: 0.5879\n",
      "Epoch 26/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8706 - loss: 0.4371 - val_categorical_accuracy: 0.8061 - val_loss: 0.6766\n",
      "Epoch 27/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8736 - loss: 0.4295 - val_categorical_accuracy: 0.8285 - val_loss: 0.6076\n",
      "Epoch 28/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 61ms/step - categorical_accuracy: 0.8749 - loss: 0.4232 - val_categorical_accuracy: 0.8294 - val_loss: 0.5805\n",
      "Epoch 29/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8820 - loss: 0.4019 - val_categorical_accuracy: 0.8385 - val_loss: 0.5726\n",
      "Epoch 30/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8849 - loss: 0.3855 - val_categorical_accuracy: 0.8274 - val_loss: 0.6148\n",
      "Epoch 31/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8850 - loss: 0.3935 - val_categorical_accuracy: 0.8217 - val_loss: 0.6410\n",
      "Epoch 32/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.8851 - loss: 0.3836 - val_categorical_accuracy: 0.8213 - val_loss: 0.6454\n",
      "Epoch 33/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8870 - loss: 0.3852 - val_categorical_accuracy: 0.8435 - val_loss: 0.5524\n",
      "Epoch 34/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 61ms/step - categorical_accuracy: 0.8917 - loss: 0.3686 - val_categorical_accuracy: 0.8470 - val_loss: 0.5500\n",
      "Epoch 35/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8920 - loss: 0.3660 - val_categorical_accuracy: 0.8316 - val_loss: 0.5899\n",
      "Epoch 36/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.8958 - loss: 0.3463 - val_categorical_accuracy: 0.8110 - val_loss: 0.7070\n",
      "Epoch 37/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8938 - loss: 0.3566 - val_categorical_accuracy: 0.8458 - val_loss: 0.5531\n",
      "Epoch 38/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8999 - loss: 0.3431 - val_categorical_accuracy: 0.8392 - val_loss: 0.5695\n",
      "Epoch 39/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.9008 - loss: 0.3307 - val_categorical_accuracy: 0.8420 - val_loss: 0.5689\n",
      "Epoch 40/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.9044 - loss: 0.3298 - val_categorical_accuracy: 0.8482 - val_loss: 0.5729\n",
      "Epoch 41/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.9062 - loss: 0.3235 - val_categorical_accuracy: 0.8377 - val_loss: 0.5854\n",
      "Epoch 42/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.9072 - loss: 0.3199 - val_categorical_accuracy: 0.8213 - val_loss: 0.6652\n",
      "Epoch 43/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 65ms/step - categorical_accuracy: 0.9055 - loss: 0.3192 - val_categorical_accuracy: 0.8386 - val_loss: 0.5873\n",
      "Epoch 44/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 65ms/step - categorical_accuracy: 0.9085 - loss: 0.3092 - val_categorical_accuracy: 0.8507 - val_loss: 0.5580\n",
      "Epoch 45/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 65ms/step - categorical_accuracy: 0.9078 - loss: 0.3122 - val_categorical_accuracy: 0.8498 - val_loss: 0.5431\n",
      "Epoch 46/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 65ms/step - categorical_accuracy: 0.9098 - loss: 0.2996 - val_categorical_accuracy: 0.8498 - val_loss: 0.5401\n",
      "Epoch 47/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.9128 - loss: 0.2943 - val_categorical_accuracy: 0.8505 - val_loss: 0.5332\n",
      "Epoch 48/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 65ms/step - categorical_accuracy: 0.9128 - loss: 0.2903 - val_categorical_accuracy: 0.8457 - val_loss: 0.5816\n",
      "Epoch 49/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.9113 - loss: 0.2978 - val_categorical_accuracy: 0.8514 - val_loss: 0.5531\n",
      "Epoch 50/50\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.9150 - loss: 0.2885 - val_categorical_accuracy: 0.8558 - val_loss: 0.5149\n"
     ]
    }
   ],
   "source": [
    "def MyAlexNet(\n",
    "        normalization_layer = None,\n",
    "        dropout_rate = 0.5,\n",
    "        input_shape = (256, 256),\n",
    "        batch_size = 32\n",
    ") -> keras.Model:\n",
    "    inputs = keras.layers.Input(shape=input_shape, batch_size=batch_size)\n",
    "\n",
    "    # Preprocessing\n",
    "    x = keras.layers.Reshape((*input_shape, 1))(inputs)\n",
    "    if normalization_layer is not None:\n",
    "        x = normalization_layer(x)\n",
    "    x = keras.layers.RandomCrop(height=227, width=227)(x)\n",
    "\n",
    "    # Convolutional layers\n",
    "    # Instead of 11x11 stride 4 we are going to use subsequent 3x3 layers\n",
    "    x = keras.layers.Conv2D(128, kernel_size=(3, 3), strides=2)(x)\n",
    "    x = keras.layers.Conv2D(128, kernel_size=(3, 3), strides=2)(x)\n",
    "    x = keras.layers.Conv2D(128, kernel_size=(3, 3))(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.MaxPool2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(128, kernel_size=(3, 3))(x)\n",
    "    # x = keras.layers.Conv2D(256, kernel_size=(3, 3), padding=\"same\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.MaxPool2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(256, kernel_size=(2, 2), strides=2)(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.Conv2D(256, kernel_size=(2, 2))(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "    # x = keras.layers.Conv2D(256, kernel_size=(2, 2))(x)\n",
    "    # x = keras.layers.BatchNormalization()(x)\n",
    "    # x = keras.layers.ReLU()(x)\n",
    "    x = keras.layers.MaxPool2D((2, 2), strides=(2, 2))(x)\n",
    "\n",
    "\n",
    "    # Dense layer\n",
    "    x = keras.layers.Flatten(\"channels_last\")(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dropout(rate=dropout_rate)(x)\n",
    "    outputs = keras.layers.Dense(30, activation=\"softmax\")(x)\n",
    "\n",
    "    return keras.Model(inputs=inputs, outputs=outputs, name=\"MyAlexNet\")\n",
    "\n",
    "\n",
    "\n",
    "MyAlexNet().summary()\n",
    "\n",
    "log_dir = os.path.join(LOG_DIR, \"kaggle-speech-recognition\", MyAlexNet().name)\n",
    "models = []\n",
    "\n",
    "optimizers = [SGD(learning_rate=0.01, momentum=0.9)]\n",
    "early_stopping = EarlyStopping(patience=25, restore_best_weights=True, start_from_epoch=10)\n",
    "normalization_layer = keras.layers.Normalization(axis=-1)\n",
    "feature_ds = ds_train.map(lambda x, y: x)\n",
    "normalization_layer.adapt(feature_ds)\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    model = MyAlexNet(normalization_layer=normalization_layer)\n",
    "    loss = CategoricalCrossentropy()\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[CategoricalAccuracy(name=\"categorical_accuracy\")])\n",
    "\n",
    "    model_log_dir = os.path.join(log_dir, f\"opt-{optimizer.name}_lr={0.01}_momentum-{0.9}\")\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1)\n",
    "    history = model.fit(x=ds_train, validation_data=ds_valid, batch_size=batch_size, epochs=50,\n",
    "                callbacks=[tensorboard_cb, early_stopping])\n",
    "    models.append((model, history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../models/MyAlexNet.keras\", zipped=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SGD with momentum and exponential decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-28 14:35:02.776640: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 59ms/step - categorical_accuracy: 0.0432 - loss: 3.4934 - val_categorical_accuracy: 0.1114 - val_loss: 3.2755\n",
      "Epoch 2/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 59ms/step - categorical_accuracy: 0.0847 - loss: 3.2523 - val_categorical_accuracy: 0.1720 - val_loss: 2.9443\n",
      "Epoch 3/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 60ms/step - categorical_accuracy: 0.1739 - loss: 2.8228 - val_categorical_accuracy: 0.3358 - val_loss: 2.2859\n",
      "Epoch 4/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.3157 - loss: 2.2591 - val_categorical_accuracy: 0.4875 - val_loss: 1.7904\n",
      "Epoch 5/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.4261 - loss: 1.8737 - val_categorical_accuracy: 0.5643 - val_loss: 1.4597\n",
      "Epoch 6/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.4976 - loss: 1.6333 - val_categorical_accuracy: 0.6039 - val_loss: 1.3258\n",
      "Epoch 7/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 61ms/step - categorical_accuracy: 0.5589 - loss: 1.4445 - val_categorical_accuracy: 0.6208 - val_loss: 1.2724\n",
      "Epoch 8/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 66ms/step - categorical_accuracy: 0.5960 - loss: 1.3251 - val_categorical_accuracy: 0.6826 - val_loss: 1.0886\n",
      "Epoch 9/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.6285 - loss: 1.2189 - val_categorical_accuracy: 0.5986 - val_loss: 1.3385\n",
      "Epoch 10/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.6556 - loss: 1.1275 - val_categorical_accuracy: 0.6918 - val_loss: 1.0334\n",
      "Epoch 11/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.6781 - loss: 1.0570 - val_categorical_accuracy: 0.7133 - val_loss: 0.9577\n",
      "Epoch 12/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.6963 - loss: 0.9993 - val_categorical_accuracy: 0.7265 - val_loss: 0.9205\n",
      "Epoch 13/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.7158 - loss: 0.9409 - val_categorical_accuracy: 0.7482 - val_loss: 0.8470\n",
      "Epoch 14/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.7258 - loss: 0.9020 - val_categorical_accuracy: 0.7604 - val_loss: 0.8182\n",
      "Epoch 15/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 60ms/step - categorical_accuracy: 0.7338 - loss: 0.8712 - val_categorical_accuracy: 0.7732 - val_loss: 0.7832\n",
      "Epoch 16/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.7491 - loss: 0.8313 - val_categorical_accuracy: 0.7664 - val_loss: 0.7973\n",
      "Epoch 17/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.7569 - loss: 0.8026 - val_categorical_accuracy: 0.7538 - val_loss: 0.8425\n",
      "Epoch 18/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.7659 - loss: 0.7744 - val_categorical_accuracy: 0.7667 - val_loss: 0.7874\n",
      "Epoch 19/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.7708 - loss: 0.7472 - val_categorical_accuracy: 0.7848 - val_loss: 0.7202\n",
      "Epoch 20/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 61ms/step - categorical_accuracy: 0.7793 - loss: 0.7327 - val_categorical_accuracy: 0.7896 - val_loss: 0.7127\n",
      "Epoch 21/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.7845 - loss: 0.7096 - val_categorical_accuracy: 0.7904 - val_loss: 0.7203\n",
      "Epoch 22/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.7909 - loss: 0.6873 - val_categorical_accuracy: 0.7874 - val_loss: 0.7106\n",
      "Epoch 23/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.7972 - loss: 0.6736 - val_categorical_accuracy: 0.7919 - val_loss: 0.7005\n",
      "Epoch 24/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8013 - loss: 0.6591 - val_categorical_accuracy: 0.8045 - val_loss: 0.6613\n",
      "Epoch 25/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8094 - loss: 0.6370 - val_categorical_accuracy: 0.7883 - val_loss: 0.7249\n",
      "Epoch 26/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 60ms/step - categorical_accuracy: 0.8101 - loss: 0.6274 - val_categorical_accuracy: 0.8038 - val_loss: 0.6648\n",
      "Epoch 27/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8177 - loss: 0.6016 - val_categorical_accuracy: 0.8039 - val_loss: 0.6754\n",
      "Epoch 28/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 62ms/step - categorical_accuracy: 0.8191 - loss: 0.5985 - val_categorical_accuracy: 0.8166 - val_loss: 0.6249\n",
      "Epoch 29/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8219 - loss: 0.5902 - val_categorical_accuracy: 0.8030 - val_loss: 0.6717\n",
      "Epoch 30/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8250 - loss: 0.5745 - val_categorical_accuracy: 0.8169 - val_loss: 0.6274\n",
      "Epoch 31/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 60ms/step - categorical_accuracy: 0.8338 - loss: 0.5547 - val_categorical_accuracy: 0.8014 - val_loss: 0.6809\n",
      "Epoch 32/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.8335 - loss: 0.5526 - val_categorical_accuracy: 0.8166 - val_loss: 0.6302\n",
      "Epoch 33/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8364 - loss: 0.5466 - val_categorical_accuracy: 0.8211 - val_loss: 0.6151\n",
      "Epoch 34/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8401 - loss: 0.5350 - val_categorical_accuracy: 0.8013 - val_loss: 0.6817\n",
      "Epoch 35/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8458 - loss: 0.5139 - val_categorical_accuracy: 0.7910 - val_loss: 0.7445\n",
      "Epoch 36/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8413 - loss: 0.5192 - val_categorical_accuracy: 0.8076 - val_loss: 0.6767\n",
      "Epoch 37/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 61ms/step - categorical_accuracy: 0.8450 - loss: 0.5048 - val_categorical_accuracy: 0.8292 - val_loss: 0.5845\n",
      "Epoch 38/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8497 - loss: 0.4968 - val_categorical_accuracy: 0.8258 - val_loss: 0.6013\n",
      "Epoch 39/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8498 - loss: 0.4955 - val_categorical_accuracy: 0.8229 - val_loss: 0.5945\n",
      "Epoch 40/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8536 - loss: 0.4813 - val_categorical_accuracy: 0.8332 - val_loss: 0.5932\n",
      "Epoch 41/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.8581 - loss: 0.4724 - val_categorical_accuracy: 0.8357 - val_loss: 0.5737\n",
      "Epoch 42/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8585 - loss: 0.4708 - val_categorical_accuracy: 0.8266 - val_loss: 0.6004\n",
      "Epoch 43/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 60ms/step - categorical_accuracy: 0.8563 - loss: 0.4731 - val_categorical_accuracy: 0.8288 - val_loss: 0.5935\n",
      "Epoch 44/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8621 - loss: 0.4566 - val_categorical_accuracy: 0.8272 - val_loss: 0.5933\n",
      "Epoch 45/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8631 - loss: 0.4510 - val_categorical_accuracy: 0.8347 - val_loss: 0.5910\n",
      "Epoch 46/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8638 - loss: 0.4477 - val_categorical_accuracy: 0.8391 - val_loss: 0.5622\n",
      "Epoch 47/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8630 - loss: 0.4461 - val_categorical_accuracy: 0.8413 - val_loss: 0.5670\n",
      "Epoch 48/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 61ms/step - categorical_accuracy: 0.8676 - loss: 0.4375 - val_categorical_accuracy: 0.8272 - val_loss: 0.5945\n",
      "Epoch 49/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8698 - loss: 0.4317 - val_categorical_accuracy: 0.8373 - val_loss: 0.5557\n",
      "Epoch 50/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8714 - loss: 0.4251 - val_categorical_accuracy: 0.8411 - val_loss: 0.5585\n",
      "Epoch 51/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8726 - loss: 0.4184 - val_categorical_accuracy: 0.8430 - val_loss: 0.5505\n",
      "Epoch 52/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8700 - loss: 0.4239 - val_categorical_accuracy: 0.8395 - val_loss: 0.5513\n",
      "Epoch 53/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 60ms/step - categorical_accuracy: 0.8761 - loss: 0.4088 - val_categorical_accuracy: 0.8358 - val_loss: 0.5684\n",
      "Epoch 54/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.8736 - loss: 0.4141 - val_categorical_accuracy: 0.8417 - val_loss: 0.5588\n",
      "Epoch 55/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8784 - loss: 0.4006 - val_categorical_accuracy: 0.8485 - val_loss: 0.5377\n",
      "Epoch 56/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8785 - loss: 0.4039 - val_categorical_accuracy: 0.8388 - val_loss: 0.5591\n",
      "Epoch 57/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8836 - loss: 0.3891 - val_categorical_accuracy: 0.8370 - val_loss: 0.5645\n",
      "Epoch 58/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8809 - loss: 0.3949 - val_categorical_accuracy: 0.8410 - val_loss: 0.5681\n",
      "Epoch 59/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 60ms/step - categorical_accuracy: 0.8823 - loss: 0.3905 - val_categorical_accuracy: 0.8438 - val_loss: 0.5668\n",
      "Epoch 60/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8836 - loss: 0.3827 - val_categorical_accuracy: 0.8432 - val_loss: 0.5609\n",
      "Epoch 61/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8837 - loss: 0.3796 - val_categorical_accuracy: 0.8529 - val_loss: 0.5265\n",
      "Epoch 62/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.8864 - loss: 0.3768 - val_categorical_accuracy: 0.8457 - val_loss: 0.5396\n",
      "Epoch 63/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8854 - loss: 0.3814 - val_categorical_accuracy: 0.8457 - val_loss: 0.5454\n",
      "Epoch 64/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8858 - loss: 0.3739 - val_categorical_accuracy: 0.8525 - val_loss: 0.5128\n",
      "Epoch 65/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 61ms/step - categorical_accuracy: 0.8887 - loss: 0.3674 - val_categorical_accuracy: 0.8472 - val_loss: 0.5405\n",
      "Epoch 66/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 64ms/step - categorical_accuracy: 0.8905 - loss: 0.3601 - val_categorical_accuracy: 0.8482 - val_loss: 0.5416\n",
      "Epoch 67/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8899 - loss: 0.3609 - val_categorical_accuracy: 0.8594 - val_loss: 0.5037\n",
      "Epoch 68/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8909 - loss: 0.3652 - val_categorical_accuracy: 0.8489 - val_loss: 0.5246\n",
      "Epoch 69/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8970 - loss: 0.3462 - val_categorical_accuracy: 0.8517 - val_loss: 0.5198\n",
      "Epoch 70/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8941 - loss: 0.3488 - val_categorical_accuracy: 0.8455 - val_loss: 0.5393\n",
      "Epoch 71/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 61ms/step - categorical_accuracy: 0.8934 - loss: 0.3516 - val_categorical_accuracy: 0.8520 - val_loss: 0.5361\n",
      "Epoch 72/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8926 - loss: 0.3539 - val_categorical_accuracy: 0.8550 - val_loss: 0.5119\n",
      "Epoch 73/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8929 - loss: 0.3473 - val_categorical_accuracy: 0.8457 - val_loss: 0.5489\n",
      "Epoch 74/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8942 - loss: 0.3494 - val_categorical_accuracy: 0.8541 - val_loss: 0.5167\n",
      "Epoch 75/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8973 - loss: 0.3367 - val_categorical_accuracy: 0.8402 - val_loss: 0.5745\n",
      "Epoch 76/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8949 - loss: 0.3395 - val_categorical_accuracy: 0.8567 - val_loss: 0.5159\n",
      "Epoch 77/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.8990 - loss: 0.3333 - val_categorical_accuracy: 0.8505 - val_loss: 0.5373\n",
      "Epoch 78/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8956 - loss: 0.3393 - val_categorical_accuracy: 0.8508 - val_loss: 0.5241\n",
      "Epoch 79/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.9006 - loss: 0.3323 - val_categorical_accuracy: 0.8589 - val_loss: 0.5048\n",
      "Epoch 80/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.9027 - loss: 0.3194 - val_categorical_accuracy: 0.8588 - val_loss: 0.5073\n",
      "Epoch 81/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.8996 - loss: 0.3299 - val_categorical_accuracy: 0.8563 - val_loss: 0.5127\n",
      "Epoch 82/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 61ms/step - categorical_accuracy: 0.9024 - loss: 0.3198 - val_categorical_accuracy: 0.8561 - val_loss: 0.5141\n",
      "Epoch 83/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.9002 - loss: 0.3232 - val_categorical_accuracy: 0.8526 - val_loss: 0.5279\n",
      "Epoch 84/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.9031 - loss: 0.3198 - val_categorical_accuracy: 0.8526 - val_loss: 0.5364\n",
      "Epoch 85/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.9042 - loss: 0.3130 - val_categorical_accuracy: 0.8569 - val_loss: 0.5098\n",
      "Epoch 86/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.9024 - loss: 0.3154 - val_categorical_accuracy: 0.8572 - val_loss: 0.5104\n",
      "Epoch 87/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.9030 - loss: 0.3153 - val_categorical_accuracy: 0.8460 - val_loss: 0.5576\n",
      "Epoch 88/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 60ms/step - categorical_accuracy: 0.9051 - loss: 0.3106 - val_categorical_accuracy: 0.8598 - val_loss: 0.5021\n",
      "Epoch 89/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.9080 - loss: 0.3046 - val_categorical_accuracy: 0.8605 - val_loss: 0.5001\n",
      "Epoch 90/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.9057 - loss: 0.3055 - val_categorical_accuracy: 0.8557 - val_loss: 0.5265\n",
      "Epoch 91/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.9061 - loss: 0.3109 - val_categorical_accuracy: 0.8532 - val_loss: 0.5224\n",
      "Epoch 92/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.9063 - loss: 0.3034 - val_categorical_accuracy: 0.8603 - val_loss: 0.5075\n",
      "Epoch 93/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 61ms/step - categorical_accuracy: 0.9105 - loss: 0.2947 - val_categorical_accuracy: 0.8583 - val_loss: 0.5061\n",
      "Epoch 94/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 63ms/step - categorical_accuracy: 0.9072 - loss: 0.3051 - val_categorical_accuracy: 0.8639 - val_loss: 0.5019\n",
      "Epoch 95/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.9054 - loss: 0.3036 - val_categorical_accuracy: 0.8519 - val_loss: 0.5332\n",
      "Epoch 96/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.9076 - loss: 0.2967 - val_categorical_accuracy: 0.8605 - val_loss: 0.4993\n",
      "Epoch 97/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.9113 - loss: 0.2920 - val_categorical_accuracy: 0.8588 - val_loss: 0.5149\n",
      "Epoch 98/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.9085 - loss: 0.2958 - val_categorical_accuracy: 0.8573 - val_loss: 0.5309\n",
      "Epoch 99/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.9094 - loss: 0.2943 - val_categorical_accuracy: 0.8604 - val_loss: 0.5119\n",
      "Epoch 100/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 62ms/step - categorical_accuracy: 0.9093 - loss: 0.2941 - val_categorical_accuracy: 0.8582 - val_loss: 0.5147\n",
      "Epoch 1/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 64ms/step - categorical_accuracy: 0.0387 - loss: 3.4382 - val_categorical_accuracy: 0.0559 - val_loss: 3.3506\n",
      "Epoch 2/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.0456 - loss: 3.3684 - val_categorical_accuracy: 0.0734 - val_loss: 3.2415\n",
      "Epoch 3/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 64ms/step - categorical_accuracy: 0.0621 - loss: 3.2518 - val_categorical_accuracy: 0.0718 - val_loss: 3.1197\n",
      "Epoch 4/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.0777 - loss: 3.1194 - val_categorical_accuracy: 0.0983 - val_loss: 3.0338\n",
      "Epoch 5/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.0908 - loss: 3.0460 - val_categorical_accuracy: 0.1555 - val_loss: 2.9006\n",
      "Epoch 6/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.1412 - loss: 2.8259 - val_categorical_accuracy: 0.2364 - val_loss: 2.6444\n",
      "Epoch 7/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.2355 - loss: 2.4845 - val_categorical_accuracy: 0.3878 - val_loss: 2.1527\n",
      "Epoch 8/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 64ms/step - categorical_accuracy: 0.3634 - loss: 2.0500 - val_categorical_accuracy: 0.5124 - val_loss: 1.6494\n",
      "Epoch 9/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.4834 - loss: 1.6535 - val_categorical_accuracy: 0.5894 - val_loss: 1.3679\n",
      "Epoch 10/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.5894 - loss: 1.3255 - val_categorical_accuracy: 0.6793 - val_loss: 1.0773\n",
      "Epoch 11/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.6531 - loss: 1.1336 - val_categorical_accuracy: 0.6973 - val_loss: 0.9675\n",
      "Epoch 12/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.7033 - loss: 0.9773 - val_categorical_accuracy: 0.7340 - val_loss: 0.8979\n",
      "Epoch 13/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.7379 - loss: 0.8623 - val_categorical_accuracy: 0.6821 - val_loss: 1.0939\n",
      "Epoch 14/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.7731 - loss: 0.7634 - val_categorical_accuracy: 0.7592 - val_loss: 0.8045\n",
      "Epoch 15/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 62ms/step - categorical_accuracy: 0.7898 - loss: 0.7020 - val_categorical_accuracy: 0.7515 - val_loss: 0.8282\n",
      "Epoch 16/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.8007 - loss: 0.6698 - val_categorical_accuracy: 0.7871 - val_loss: 0.7079\n",
      "Epoch 17/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 64ms/step - categorical_accuracy: 0.8148 - loss: 0.6220 - val_categorical_accuracy: 0.7713 - val_loss: 0.7640\n",
      "Epoch 18/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.8247 - loss: 0.5960 - val_categorical_accuracy: 0.8020 - val_loss: 0.6717\n",
      "Epoch 19/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.8311 - loss: 0.5664 - val_categorical_accuracy: 0.8139 - val_loss: 0.6279\n",
      "Epoch 20/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.8426 - loss: 0.5336 - val_categorical_accuracy: 0.7876 - val_loss: 0.7344\n",
      "Epoch 21/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.8527 - loss: 0.5071 - val_categorical_accuracy: 0.8044 - val_loss: 0.6621\n",
      "Epoch 22/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.8538 - loss: 0.4886 - val_categorical_accuracy: 0.7782 - val_loss: 0.7865\n",
      "Epoch 23/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.8630 - loss: 0.4717 - val_categorical_accuracy: 0.8164 - val_loss: 0.6077\n",
      "Epoch 24/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.8649 - loss: 0.4566 - val_categorical_accuracy: 0.8369 - val_loss: 0.5520\n",
      "Epoch 25/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.8708 - loss: 0.4372 - val_categorical_accuracy: 0.8217 - val_loss: 0.6075\n",
      "Epoch 26/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.8750 - loss: 0.4307 - val_categorical_accuracy: 0.8127 - val_loss: 0.6562\n",
      "Epoch 27/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.8763 - loss: 0.4184 - val_categorical_accuracy: 0.8151 - val_loss: 0.6492\n",
      "Epoch 28/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.8801 - loss: 0.4020 - val_categorical_accuracy: 0.8283 - val_loss: 0.5965\n",
      "Epoch 29/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.8834 - loss: 0.3923 - val_categorical_accuracy: 0.8336 - val_loss: 0.5889\n",
      "Epoch 30/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 62ms/step - categorical_accuracy: 0.8847 - loss: 0.3861 - val_categorical_accuracy: 0.8285 - val_loss: 0.5962\n",
      "Epoch 31/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.8908 - loss: 0.3735 - val_categorical_accuracy: 0.8429 - val_loss: 0.5470\n",
      "Epoch 32/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.8921 - loss: 0.3686 - val_categorical_accuracy: 0.8336 - val_loss: 0.5991\n",
      "Epoch 33/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 64ms/step - categorical_accuracy: 0.8951 - loss: 0.3507 - val_categorical_accuracy: 0.8480 - val_loss: 0.5329\n",
      "Epoch 34/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 64ms/step - categorical_accuracy: 0.9008 - loss: 0.3356 - val_categorical_accuracy: 0.8413 - val_loss: 0.5580\n",
      "Epoch 35/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 63ms/step - categorical_accuracy: 0.9008 - loss: 0.3337 - val_categorical_accuracy: 0.8407 - val_loss: 0.5880\n",
      "Epoch 1/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 62ms/step - categorical_accuracy: 0.0355 - loss: 3.4632 - val_categorical_accuracy: 0.0363 - val_loss: 3.3965\n",
      "Epoch 2/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0369 - loss: 3.4008 - val_categorical_accuracy: 0.0363 - val_loss: 3.3972\n",
      "Epoch 3/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 60ms/step - categorical_accuracy: 0.0376 - loss: 3.4008 - val_categorical_accuracy: 0.0363 - val_loss: 3.3966\n",
      "Epoch 4/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0366 - loss: 3.4016 - val_categorical_accuracy: 0.0363 - val_loss: 3.3976\n",
      "Epoch 5/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0369 - loss: 3.4012 - val_categorical_accuracy: 0.0363 - val_loss: 3.3966\n",
      "Epoch 6/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0355 - loss: 3.4008 - val_categorical_accuracy: 0.0363 - val_loss: 3.3958\n",
      "Epoch 7/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 60ms/step - categorical_accuracy: 0.0360 - loss: 3.4011 - val_categorical_accuracy: 0.0363 - val_loss: 3.3964\n",
      "Epoch 8/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 62ms/step - categorical_accuracy: 0.0364 - loss: 3.4002 - val_categorical_accuracy: 0.0363 - val_loss: 3.3962\n",
      "Epoch 9/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0357 - loss: 3.4008 - val_categorical_accuracy: 0.0363 - val_loss: 3.3952\n",
      "Epoch 10/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0356 - loss: 3.4005 - val_categorical_accuracy: 0.0363 - val_loss: 3.3945\n",
      "Epoch 11/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0368 - loss: 3.4004 - val_categorical_accuracy: 0.0363 - val_loss: 3.3955\n",
      "Epoch 12/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 60ms/step - categorical_accuracy: 0.0363 - loss: 3.4000 - val_categorical_accuracy: 0.0363 - val_loss: 3.3959\n",
      "Epoch 13/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0369 - loss: 3.4001 - val_categorical_accuracy: 0.0363 - val_loss: 3.3963\n",
      "Epoch 14/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0365 - loss: 3.3997 - val_categorical_accuracy: 0.0363 - val_loss: 3.3948\n",
      "Epoch 15/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0357 - loss: 3.4003 - val_categorical_accuracy: 0.0363 - val_loss: 3.3949\n",
      "Epoch 16/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0371 - loss: 3.3999 - val_categorical_accuracy: 0.0363 - val_loss: 3.3947\n",
      "Epoch 17/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 60ms/step - categorical_accuracy: 0.0374 - loss: 3.4000 - val_categorical_accuracy: 0.0363 - val_loss: 3.3959\n",
      "Epoch 18/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 62ms/step - categorical_accuracy: 0.0362 - loss: 3.3998 - val_categorical_accuracy: 0.0363 - val_loss: 3.3942\n",
      "Epoch 19/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 61ms/step - categorical_accuracy: 0.0360 - loss: 3.3993 - val_categorical_accuracy: 0.0363 - val_loss: 3.3936\n",
      "Epoch 20/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 62ms/step - categorical_accuracy: 0.0362 - loss: 3.3993 - val_categorical_accuracy: 0.0363 - val_loss: 3.3943\n",
      "Epoch 21/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 61ms/step - categorical_accuracy: 0.0367 - loss: 3.3990 - val_categorical_accuracy: 0.0363 - val_loss: 3.3949\n",
      "Epoch 22/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 59ms/step - categorical_accuracy: 0.0366 - loss: 3.3993 - val_categorical_accuracy: 0.0363 - val_loss: 3.3938\n",
      "Epoch 23/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 62ms/step - categorical_accuracy: 0.0368 - loss: 3.3990 - val_categorical_accuracy: 0.0363 - val_loss: 3.3936\n",
      "Epoch 24/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0358 - loss: 3.3990 - val_categorical_accuracy: 0.0363 - val_loss: 3.3941\n",
      "Epoch 25/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0371 - loss: 3.3988 - val_categorical_accuracy: 0.0363 - val_loss: 3.3930\n",
      "Epoch 26/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 59ms/step - categorical_accuracy: 0.0365 - loss: 3.3987 - val_categorical_accuracy: 0.0363 - val_loss: 3.3932\n",
      "Epoch 27/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0362 - loss: 3.3987 - val_categorical_accuracy: 0.0363 - val_loss: 3.3923\n",
      "Epoch 28/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 61ms/step - categorical_accuracy: 0.0362 - loss: 3.3985 - val_categorical_accuracy: 0.0363 - val_loss: 3.3926\n",
      "Epoch 29/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0359 - loss: 3.3985 - val_categorical_accuracy: 0.0363 - val_loss: 3.3923\n",
      "Epoch 30/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 59ms/step - categorical_accuracy: 0.0354 - loss: 3.3988 - val_categorical_accuracy: 0.0363 - val_loss: 3.3926\n",
      "Epoch 31/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0368 - loss: 3.3982 - val_categorical_accuracy: 0.0363 - val_loss: 3.3921\n",
      "Epoch 32/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 60ms/step - categorical_accuracy: 0.0361 - loss: 3.3981 - val_categorical_accuracy: 0.0363 - val_loss: 3.3924\n",
      "Epoch 33/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0361 - loss: 3.3980 - val_categorical_accuracy: 0.0363 - val_loss: 3.3927\n",
      "Epoch 34/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 59ms/step - categorical_accuracy: 0.0363 - loss: 3.3984 - val_categorical_accuracy: 0.0363 - val_loss: 3.3921\n",
      "Epoch 35/100\n",
      "\u001b[1m1597/1597\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 61ms/step - categorical_accuracy: 0.0381 - loss: 3.3979 - val_categorical_accuracy: 0.0363 - val_loss: 3.3923\n"
     ]
    }
   ],
   "source": [
    "log_dir = os.path.join(LOG_DIR, \"kaggle-speech-recognition\", MyAlexNet().name)\n",
    "models = []\n",
    "\n",
    "early_stopping = EarlyStopping(patience=25, restore_best_weights=True, start_from_epoch=10)\n",
    "normalization_layer = keras.layers.Normalization(axis=-1)\n",
    "feature_ds = ds_train.map(lambda x, y: x)\n",
    "normalization_layer.adapt(feature_ds)\n",
    "learning_rates = np.logspace(-3, -1, 3)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = MyAlexNet(normalization_layer=normalization_layer)\n",
    "    lr_scheduler = ExponentialDecay(lr, decay_steps=10_000, decay_rate=0.9)\n",
    "    optimizer = SGD(learning_rate=lr_scheduler, momentum=0.9)\n",
    "    loss = CategoricalCrossentropy()\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[CategoricalAccuracy(name=\"categorical_accuracy\")])\n",
    "\n",
    "    model_log_dir = os.path.join(log_dir, f\"opt-{optimizer.name}_exp_decay_lr={lr}_steps-{10_000}_rate-{0.9}_momentum-{0.9}\")\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1)\n",
    "    history = model.fit(x=ds_train, validation_data=ds_valid, batch_size=batch_size, epochs=100,\n",
    "                callbacks=[tensorboard_cb, early_stopping])\n",
    "    models.append((model, history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0][0].save(\"../models/MyAlexNet_opt-SGD_exp_decay_lr-0.001_steps-10000_rate-0.9_momentum-0.9.keras\", zipped=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"MyResNet\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"MyResNet\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rescaling           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>,    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,200</span> │ rescaling[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>,    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)        │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">125</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │     <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │ re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ conv2d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ re_lu_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ conv2d_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │ re_lu_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ conv2d_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ re_lu_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │     <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ max_pooling2d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ conv2d_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │ re_lu_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ conv2d_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatio…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ re_lu_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReLU</span>)     │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>) │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ add_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ re_lu_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePool…</span> │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)          │      <span style=\"color: #00af00; text-decoration-color: #00af00\">7,710</span> │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Softmax</span>)   │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ rescaling           │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m1\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mRescaling\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m125\u001b[0m,    │      \u001b[38;5;34m3,200\u001b[0m │ rescaling[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalization │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m125\u001b[0m,    │        \u001b[38;5;34m256\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu (\u001b[38;5;33mReLU\u001b[0m)        │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m125\u001b[0m, \u001b[38;5;34m125\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d       │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m36,928\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_1 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m36,928\u001b[0m │ re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ conv2d_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_2 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add (\u001b[38;5;33mAdd\u001b[0m)           │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_3 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m36,928\u001b[0m │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ conv2d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_4 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │     \u001b[38;5;34m36,928\u001b[0m │ re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │        \u001b[38;5;34m256\u001b[0m │ conv2d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_5 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_1 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_6 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_1     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m64\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ re_lu_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │     \u001b[38;5;34m73,856\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv2d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_7 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,584\u001b[0m │ re_lu_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv2d_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_8 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │      \u001b[38;5;34m8,320\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_2 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ conv2d_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_9 (\u001b[38;5;33mReLU\u001b[0m)      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_8 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,584\u001b[0m │ re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv2d_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_10 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_9 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m147,584\u001b[0m │ re_lu_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │        \u001b[38;5;34m512\u001b[0m │ conv2d_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_11 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_3 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ re_lu_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_12 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ max_pooling2d_2     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m128\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m295,168\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_13 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ re_lu_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_14 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │     \u001b[38;5;34m33,024\u001b[0m │ max_pooling2d_2[\u001b[38;5;34m…\u001b[0m │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_4 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ conv2d_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_15 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_16 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │    \u001b[38;5;34m590,080\u001b[0m │ re_lu_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ batch_normalizatio… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │      \u001b[38;5;34m1,024\u001b[0m │ conv2d_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mBatchNormalizatio…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_17 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ batch_normalizat… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ add_5 (\u001b[38;5;33mAdd\u001b[0m)         │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ re_lu_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ re_lu_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ re_lu_18 (\u001b[38;5;33mReLU\u001b[0m)     │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m15\u001b[0m, \u001b[38;5;34m256\u001b[0m) │          \u001b[38;5;34m0\u001b[0m │ add_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ global_average_poo… │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m256\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ re_lu_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "│ (\u001b[38;5;33mGlobalAveragePool…\u001b[0m │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m)          │      \u001b[38;5;34m7,710\u001b[0m │ global_average_p… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ softmax (\u001b[38;5;33mSoftmax\u001b[0m)   │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m30\u001b[0m)          │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,789,406</span> (10.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,789,406\u001b[0m (10.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,785,694</span> (10.63 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,785,694\u001b[0m (10.63 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,712</span> (14.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,712\u001b[0m (14.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def residual_block(inputs, filters: int, kernel_size = (3, 3)) -> keras.layers.Layer:\n",
    "    x = keras.layers.Conv2D(filters, kernel_size, padding=\"same\")(inputs)\n",
    "\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "\n",
    "    x = keras.layers.Conv2D(filters, kernel_size, padding=\"same\")(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "\n",
    "    if inputs.shape != x.shape:\n",
    "        inputs = keras.layers.Conv2D(filters, kernel_size=(1, 1), padding=\"same\")(inputs)\n",
    "\n",
    "    x = keras.layers.Add()([x, inputs])\n",
    "    x = keras.layers.ReLU()(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "\n",
    "def MyResNet(input_shape = (256, 256, 1), batch_size = 32, normalization_layer = None, ann_tail = False):\n",
    "    inputs = keras.Input(shape=input_shape, batch_size=batch_size)\n",
    "\n",
    "    # Normalization\n",
    "    if normalization_layer is None:\n",
    "        x = keras.layers.Rescaling(1.0/255.0, 0)(inputs)\n",
    "    else:\n",
    "        x = normalization_layer(inputs)\n",
    "\n",
    "    x = keras.layers.Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
    "    x = keras.layers.BatchNormalization()(x)\n",
    "    x = keras.layers.ReLU()(x)\n",
    "\n",
    "    # Residual blocks\n",
    "    x = keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = residual_block(x, filters=64)\n",
    "    x = residual_block(x, filters=64)\n",
    "\n",
    "    x = keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = residual_block(x, filters=128)\n",
    "    x = residual_block(x, filters=128)\n",
    "\n",
    "    x = keras.layers.MaxPool2D(pool_size=(2, 2))(x)\n",
    "    x = residual_block(x, filters=256)\n",
    "    x = residual_block(x, filters=256)\n",
    "\n",
    "    x = keras.layers.GlobalAvgPool2D(data_format=\"channels_last\")(x)\n",
    "\n",
    "    # Tail\n",
    "    if ann_tail:\n",
    "        x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = keras.layers.Dropout(0.5)(x)\n",
    "        x = keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "        x = keras.layers.Dropout(0.5)(x)\n",
    "\n",
    "    x = keras.layers.Dense(30)(x)\n",
    "    outputs = keras.layers.Softmax()(x)\n",
    "    return keras.Model(inputs=inputs, outputs=outputs, name=\"MyResNet\")\n",
    "\n",
    "MyResNet().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1   0.01  0.001]\n",
      "Epoch 1/75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 15:00:53.449432: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1733407256.426849   16900 service.cc:148] XLA service 0x7f64e800a0d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1733407256.427575   16900 service.cc:156]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-12-05 15:00:56.566373: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1733407256.861357   16900 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "2024-12-05 15:00:57.359527: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1904', 16 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2024-12-05 15:00:57.992478: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:397] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_2061', 12 bytes spill stores, 16 bytes spill loads\n",
      "\n",
      "2024-12-05 15:01:12.695409: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng58{k2=7,k12=1,k13=0,k14=1,k15=0,k17=2,k18=1,k23=0} for conv (f32[256,256,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,15,15]{3,2,1,0}, f32[128,256,15,15]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "2024-12-05 15:01:12.717016: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 2.988253761s\n",
      "Trying algorithm eng58{k2=7,k12=1,k13=0,k14=1,k15=0,k17=2,k18=1,k23=0} for conv (f32[256,256,3,3]{3,2,1,0}, u8[0]{0}) custom-call(f32[128,256,15,15]{3,2,1,0}, f32[128,256,15,15]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardFilter\", backend_config={\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"leakyrelu_alpha\":0,\"side_input_scale\":0},\"force_earliest_schedule\":false,\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[]} is taking a while...\n",
      "I0000 00:00:1733407275.945882   16900 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 233ms/step - categorical_accuracy: 0.0352 - loss: 4.1589 - val_categorical_accuracy: 0.0377 - val_loss: 3.3893\n",
      "Epoch 2/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 219ms/step - categorical_accuracy: 0.0358 - loss: 3.3960 - val_categorical_accuracy: 0.0377 - val_loss: 3.3890\n",
      "Epoch 3/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 219ms/step - categorical_accuracy: 0.0350 - loss: 3.3960 - val_categorical_accuracy: 0.0377 - val_loss: 3.3888\n",
      "Epoch 4/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 230ms/step - categorical_accuracy: 0.0355 - loss: 3.3956 - val_categorical_accuracy: 0.0377 - val_loss: 3.3893\n",
      "Epoch 5/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 223ms/step - categorical_accuracy: 0.0354 - loss: 3.3956 - val_categorical_accuracy: 0.0377 - val_loss: 3.3890\n",
      "Epoch 6/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 232ms/step - categorical_accuracy: 0.0353 - loss: 3.3956 - val_categorical_accuracy: 0.0377 - val_loss: 3.3893\n",
      "Epoch 7/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 224ms/step - categorical_accuracy: 0.0367 - loss: 3.3957 - val_categorical_accuracy: 0.0377 - val_loss: 3.3889\n",
      "Epoch 8/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 232ms/step - categorical_accuracy: 0.0353 - loss: 3.3960 - val_categorical_accuracy: 0.0363 - val_loss: 3.3892\n",
      "Epoch 9/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 234ms/step - categorical_accuracy: 0.0356 - loss: 3.3958 - val_categorical_accuracy: 0.0377 - val_loss: 3.3889\n",
      "Epoch 10/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 226ms/step - categorical_accuracy: 0.0361 - loss: 3.3958 - val_categorical_accuracy: 0.0363 - val_loss: 3.3891\n",
      "Epoch 11/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 224ms/step - categorical_accuracy: 0.0359 - loss: 3.3956 - val_categorical_accuracy: 0.0377 - val_loss: 3.3892\n",
      "Epoch 12/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 232ms/step - categorical_accuracy: 0.0354 - loss: 3.3957 - val_categorical_accuracy: 0.0363 - val_loss: 3.3888\n",
      "Epoch 13/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 230ms/step - categorical_accuracy: 0.0364 - loss: 3.3956 - val_categorical_accuracy: 0.0363 - val_loss: 3.3888\n",
      "Epoch 14/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 224ms/step - categorical_accuracy: 0.0370 - loss: 3.3955 - val_categorical_accuracy: 0.0377 - val_loss: 3.3888\n",
      "Epoch 15/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 231ms/step - categorical_accuracy: 0.0349 - loss: 3.3958 - val_categorical_accuracy: 0.0382 - val_loss: 3.3889\n",
      "Epoch 16/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 224ms/step - categorical_accuracy: 0.0359 - loss: 3.3958 - val_categorical_accuracy: 0.0363 - val_loss: 3.3891\n",
      "Epoch 17/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 231ms/step - categorical_accuracy: 0.0362 - loss: 3.3956 - val_categorical_accuracy: 0.0363 - val_loss: 3.3886\n",
      "Epoch 18/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 223ms/step - categorical_accuracy: 0.0348 - loss: 3.3959 - val_categorical_accuracy: 0.0363 - val_loss: 3.3890\n",
      "Epoch 19/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 231ms/step - categorical_accuracy: 0.0363 - loss: 3.3956 - val_categorical_accuracy: 0.0363 - val_loss: 3.3884\n",
      "Epoch 20/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 230ms/step - categorical_accuracy: 0.0370 - loss: 3.3957 - val_categorical_accuracy: 0.0377 - val_loss: 3.3891\n",
      "Epoch 21/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 222ms/step - categorical_accuracy: 0.0344 - loss: 3.3955 - val_categorical_accuracy: 0.0377 - val_loss: 3.3892\n",
      "Epoch 22/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 231ms/step - categorical_accuracy: 0.0363 - loss: 3.3960 - val_categorical_accuracy: 0.0377 - val_loss: 3.3889\n",
      "Epoch 23/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 223ms/step - categorical_accuracy: 0.0349 - loss: 3.3956 - val_categorical_accuracy: 0.0377 - val_loss: 3.3890\n",
      "Epoch 24/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 226ms/step - categorical_accuracy: 0.0351 - loss: 3.3959 - val_categorical_accuracy: 0.0377 - val_loss: 3.3888\n",
      "Epoch 25/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 222ms/step - categorical_accuracy: 0.0361 - loss: 3.3961 - val_categorical_accuracy: 0.0363 - val_loss: 3.3892\n",
      "Epoch 26/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 230ms/step - categorical_accuracy: 0.0364 - loss: 3.3957 - val_categorical_accuracy: 0.0363 - val_loss: 3.3889\n",
      "Epoch 27/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 221ms/step - categorical_accuracy: 0.0365 - loss: 3.3956 - val_categorical_accuracy: 0.0363 - val_loss: 3.3887\n",
      "Epoch 28/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 227ms/step - categorical_accuracy: 0.0342 - loss: 3.3958 - val_categorical_accuracy: 0.0363 - val_loss: 3.3890\n",
      "Epoch 29/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 228ms/step - categorical_accuracy: 0.0363 - loss: 3.3956 - val_categorical_accuracy: 0.0377 - val_loss: 3.3891\n",
      "Epoch 30/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 219ms/step - categorical_accuracy: 0.0361 - loss: 3.3955 - val_categorical_accuracy: 0.0377 - val_loss: 3.3887\n",
      "Epoch 31/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 228ms/step - categorical_accuracy: 0.0346 - loss: 3.3955 - val_categorical_accuracy: 0.0377 - val_loss: 3.3887\n",
      "Epoch 32/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 219ms/step - categorical_accuracy: 0.0352 - loss: 3.3958 - val_categorical_accuracy: 0.0363 - val_loss: 3.3890\n",
      "Epoch 33/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 228ms/step - categorical_accuracy: 0.0351 - loss: 3.3960 - val_categorical_accuracy: 0.0377 - val_loss: 3.3887\n",
      "Epoch 34/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 221ms/step - categorical_accuracy: 0.0340 - loss: 3.3955 - val_categorical_accuracy: 0.0377 - val_loss: 3.3891\n",
      "Epoch 1/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 242ms/step - categorical_accuracy: 0.2873 - loss: 2.8667 - val_categorical_accuracy: 0.3260 - val_loss: 2.8538\n",
      "Epoch 2/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 240ms/step - categorical_accuracy: 0.8664 - loss: 0.5532 - val_categorical_accuracy: 0.8513 - val_loss: 0.5779\n",
      "Epoch 3/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 233ms/step - categorical_accuracy: 0.9220 - loss: 0.3086 - val_categorical_accuracy: 0.7886 - val_loss: 0.6750\n",
      "Epoch 4/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 242ms/step - categorical_accuracy: 0.9444 - loss: 0.2236 - val_categorical_accuracy: 0.7332 - val_loss: 0.9274\n",
      "Epoch 5/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 242ms/step - categorical_accuracy: 0.9561 - loss: 0.1762 - val_categorical_accuracy: 0.8373 - val_loss: 0.5780\n",
      "Epoch 6/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 244ms/step - categorical_accuracy: 0.9646 - loss: 0.1432 - val_categorical_accuracy: 0.8444 - val_loss: 0.5283\n",
      "Epoch 7/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 238ms/step - categorical_accuracy: 0.9702 - loss: 0.1238 - val_categorical_accuracy: 0.8523 - val_loss: 0.4902\n",
      "Epoch 8/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 245ms/step - categorical_accuracy: 0.9783 - loss: 0.0953 - val_categorical_accuracy: 0.8956 - val_loss: 0.3644\n",
      "Epoch 9/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 243ms/step - categorical_accuracy: 0.9804 - loss: 0.0851 - val_categorical_accuracy: 0.8935 - val_loss: 0.3960\n",
      "Epoch 10/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m94s\u001b[0m 235ms/step - categorical_accuracy: 0.9845 - loss: 0.0709 - val_categorical_accuracy: 0.8108 - val_loss: 0.7069\n",
      "Epoch 11/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 246ms/step - categorical_accuracy: 0.9874 - loss: 0.0588 - val_categorical_accuracy: 0.8241 - val_loss: 0.6666\n",
      "Epoch 12/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 244ms/step - categorical_accuracy: 0.9893 - loss: 0.0517 - val_categorical_accuracy: 0.8385 - val_loss: 0.5734\n",
      "Epoch 13/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 246ms/step - categorical_accuracy: 0.9924 - loss: 0.0386 - val_categorical_accuracy: 0.7586 - val_loss: 0.9632\n",
      "Epoch 14/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 238ms/step - categorical_accuracy: 0.9948 - loss: 0.0307 - val_categorical_accuracy: 0.8658 - val_loss: 0.5047\n",
      "Epoch 15/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 244ms/step - categorical_accuracy: 0.9867 - loss: 0.0573 - val_categorical_accuracy: 0.9059 - val_loss: 0.3446\n",
      "Epoch 16/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 245ms/step - categorical_accuracy: 0.9965 - loss: 0.0226 - val_categorical_accuracy: 0.9169 - val_loss: 0.3021\n",
      "Epoch 17/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 246ms/step - categorical_accuracy: 0.9976 - loss: 0.0169 - val_categorical_accuracy: 0.9032 - val_loss: 0.3817\n",
      "Epoch 18/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 238ms/step - categorical_accuracy: 0.9991 - loss: 0.0088 - val_categorical_accuracy: 0.9341 - val_loss: 0.2582\n",
      "Epoch 19/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 245ms/step - categorical_accuracy: 0.9997 - loss: 0.0057 - val_categorical_accuracy: 0.8794 - val_loss: 0.4759\n",
      "Epoch 20/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 247ms/step - categorical_accuracy: 0.9997 - loss: 0.0045 - val_categorical_accuracy: 0.9312 - val_loss: 0.2749\n",
      "Epoch 21/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 246ms/step - categorical_accuracy: 1.0000 - loss: 0.0025 - val_categorical_accuracy: 0.9429 - val_loss: 0.2279\n",
      "Epoch 22/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 237ms/step - categorical_accuracy: 1.0000 - loss: 0.0023 - val_categorical_accuracy: 0.9413 - val_loss: 0.2308\n",
      "Epoch 23/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 246ms/step - categorical_accuracy: 1.0000 - loss: 0.0018 - val_categorical_accuracy: 0.9444 - val_loss: 0.2206\n",
      "Epoch 24/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 246ms/step - categorical_accuracy: 1.0000 - loss: 0.0014 - val_categorical_accuracy: 0.9459 - val_loss: 0.2186\n",
      "Epoch 25/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 247ms/step - categorical_accuracy: 1.0000 - loss: 0.0013 - val_categorical_accuracy: 0.9482 - val_loss: 0.2159\n",
      "Epoch 26/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 239ms/step - categorical_accuracy: 1.0000 - loss: 0.0011 - val_categorical_accuracy: 0.9467 - val_loss: 0.2183\n",
      "Epoch 27/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 243ms/step - categorical_accuracy: 1.0000 - loss: 0.0011 - val_categorical_accuracy: 0.9466 - val_loss: 0.2180\n",
      "Epoch 28/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 243ms/step - categorical_accuracy: 1.0000 - loss: 0.0010 - val_categorical_accuracy: 0.9423 - val_loss: 0.2343\n",
      "Epoch 29/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 243ms/step - categorical_accuracy: 0.9995 - loss: 0.0064 - val_categorical_accuracy: 0.9425 - val_loss: 0.2376\n",
      "Epoch 30/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 243ms/step - categorical_accuracy: 1.0000 - loss: 0.0012 - val_categorical_accuracy: 0.9475 - val_loss: 0.2191\n",
      "Epoch 31/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 240ms/step - categorical_accuracy: 0.9988 - loss: 0.0069 - val_categorical_accuracy: 0.9456 - val_loss: 0.2277\n",
      "Epoch 32/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 240ms/step - categorical_accuracy: 1.0000 - loss: 0.0011 - val_categorical_accuracy: 0.9357 - val_loss: 0.2610\n",
      "Epoch 33/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 241ms/step - categorical_accuracy: 0.9964 - loss: 0.0199 - val_categorical_accuracy: 0.9351 - val_loss: 0.2701\n",
      "Epoch 34/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 240ms/step - categorical_accuracy: 1.0000 - loss: 0.0019 - val_categorical_accuracy: 0.9412 - val_loss: 0.2381\n",
      "Epoch 35/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 239ms/step - categorical_accuracy: 1.0000 - loss: 0.0011 - val_categorical_accuracy: 0.9475 - val_loss: 0.2191\n",
      "Epoch 36/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 239ms/step - categorical_accuracy: 1.0000 - loss: 8.7614e-04 - val_categorical_accuracy: 0.9481 - val_loss: 0.2185\n",
      "Epoch 37/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 239ms/step - categorical_accuracy: 1.0000 - loss: 7.5880e-04 - val_categorical_accuracy: 0.9472 - val_loss: 0.2210\n",
      "Epoch 38/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 239ms/step - categorical_accuracy: 0.9999 - loss: 0.0015 - val_categorical_accuracy: 0.9475 - val_loss: 0.2251\n",
      "Epoch 39/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 239ms/step - categorical_accuracy: 1.0000 - loss: 0.0011 - val_categorical_accuracy: 0.9476 - val_loss: 0.2184\n",
      "Epoch 40/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 237ms/step - categorical_accuracy: 1.0000 - loss: 6.4209e-04 - val_categorical_accuracy: 0.9476 - val_loss: 0.2208\n",
      "Epoch 1/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 242ms/step - categorical_accuracy: 0.0923 - loss: 3.3302 - val_categorical_accuracy: 0.0761 - val_loss: 3.3348\n",
      "Epoch 2/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 234ms/step - categorical_accuracy: 0.2943 - loss: 2.5968 - val_categorical_accuracy: 0.2440 - val_loss: 2.7882\n",
      "Epoch 3/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 239ms/step - categorical_accuracy: 0.5526 - loss: 1.7889 - val_categorical_accuracy: 0.0653 - val_loss: 11.0262\n",
      "Epoch 4/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 241ms/step - categorical_accuracy: 0.7034 - loss: 1.2385 - val_categorical_accuracy: 0.4782 - val_loss: 1.8348\n",
      "Epoch 5/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 241ms/step - categorical_accuracy: 0.7884 - loss: 0.9050 - val_categorical_accuracy: 0.5665 - val_loss: 1.4465\n",
      "Epoch 6/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 240ms/step - categorical_accuracy: 0.8362 - loss: 0.7076 - val_categorical_accuracy: 0.5202 - val_loss: 1.6698\n",
      "Epoch 7/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 251ms/step - categorical_accuracy: 0.8592 - loss: 0.5906 - val_categorical_accuracy: 0.5506 - val_loss: 1.7260\n",
      "Epoch 8/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 257ms/step - categorical_accuracy: 0.8790 - loss: 0.5025 - val_categorical_accuracy: 0.2983 - val_loss: 3.2942\n",
      "Epoch 9/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 248ms/step - categorical_accuracy: 0.8926 - loss: 0.4469 - val_categorical_accuracy: 0.4387 - val_loss: 2.9614\n",
      "Epoch 10/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 248ms/step - categorical_accuracy: 0.9051 - loss: 0.3948 - val_categorical_accuracy: 0.7299 - val_loss: 0.9653\n",
      "Epoch 11/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 249ms/step - categorical_accuracy: 0.9120 - loss: 0.3625 - val_categorical_accuracy: 0.6552 - val_loss: 1.2712\n",
      "Epoch 12/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 247ms/step - categorical_accuracy: 0.9218 - loss: 0.3266 - val_categorical_accuracy: 0.7702 - val_loss: 0.7481\n",
      "Epoch 13/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 248ms/step - categorical_accuracy: 0.9267 - loss: 0.3015 - val_categorical_accuracy: 0.7921 - val_loss: 0.7195\n",
      "Epoch 14/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 248ms/step - categorical_accuracy: 0.9312 - loss: 0.2842 - val_categorical_accuracy: 0.7895 - val_loss: 0.6989\n",
      "Epoch 15/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m96s\u001b[0m 240ms/step - categorical_accuracy: 0.9371 - loss: 0.2638 - val_categorical_accuracy: 0.7664 - val_loss: 0.7644\n",
      "Epoch 16/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 240ms/step - categorical_accuracy: 0.9415 - loss: 0.2472 - val_categorical_accuracy: 0.8023 - val_loss: 0.6561\n",
      "Epoch 17/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 249ms/step - categorical_accuracy: 0.9457 - loss: 0.2306 - val_categorical_accuracy: 0.8398 - val_loss: 0.5427\n",
      "Epoch 18/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 249ms/step - categorical_accuracy: 0.9495 - loss: 0.2170 - val_categorical_accuracy: 0.7966 - val_loss: 0.6692\n",
      "Epoch 19/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m101s\u001b[0m 251ms/step - categorical_accuracy: 0.9526 - loss: 0.2050 - val_categorical_accuracy: 0.8501 - val_loss: 0.4928\n",
      "Epoch 20/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 249ms/step - categorical_accuracy: 0.9566 - loss: 0.1909 - val_categorical_accuracy: 0.8151 - val_loss: 0.6038\n",
      "Epoch 21/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 249ms/step - categorical_accuracy: 0.9599 - loss: 0.1824 - val_categorical_accuracy: 0.7951 - val_loss: 0.6852\n",
      "Epoch 22/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 250ms/step - categorical_accuracy: 0.9610 - loss: 0.1729 - val_categorical_accuracy: 0.8544 - val_loss: 0.4844\n",
      "Epoch 23/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 242ms/step - categorical_accuracy: 0.9659 - loss: 0.1599 - val_categorical_accuracy: 0.8107 - val_loss: 0.6562\n",
      "Epoch 24/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 251ms/step - categorical_accuracy: 0.9679 - loss: 0.1525 - val_categorical_accuracy: 0.7099 - val_loss: 1.0157\n",
      "Epoch 25/75\n",
      "\u001b[1m400/400\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 248ms/step - categorical_accuracy: 0.9677 - loss: 0.1478 - val_categorical_accuracy: 0.7611 - val_loss: 0.8236\n"
     ]
    }
   ],
   "source": [
    "log_dir = os.path.join(LOG_DIR, \"kaggle-speech-recognition\", MyResNet().name)\n",
    "models = []\n",
    "\n",
    "early_stopping = EarlyStopping(patience=15, restore_best_weights=True, start_from_epoch=10)\n",
    "normalization_layer = keras.layers.Normalization(axis=-1)\n",
    "feature_ds = ds_train.map(lambda x, y: x)\n",
    "normalization_layer.adapt(feature_ds)\n",
    "learning_rates = np.logspace(-3, -1, 3)[::-1]\n",
    "print(learning_rates)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    model = MyResNet(batch_size=batch_size, normalization_layer=normalization_layer)\n",
    "    lr_scheduler = ExponentialDecay(lr, decay_steps=10_000, decay_rate=0.9)\n",
    "    optimizer = SGD(learning_rate=lr_scheduler, momentum=0.9)\n",
    "    loss = CategoricalCrossentropy()\n",
    "    model.compile(optimizer=optimizer, loss=loss, metrics=[CategoricalAccuracy(name=\"categorical_accuracy\")])\n",
    "\n",
    "    model_log_dir = os.path.join(log_dir, f\"opt-{optimizer.name}_exp_decay_lr={lr}_steps-{10_000}_rate-{0.9}_momentum-{0.9}\")\n",
    "    tensorboard_cb = keras.callbacks.TensorBoard(log_dir=model_log_dir, histogram_freq=1)\n",
    "    history = model.fit(x=ds_train, validation_data=ds_valid, batch_size=batch_size, epochs=75,\n",
    "                callbacks=[tensorboard_cb, early_stopping])\n",
    "    models.append((model, history))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
